
@inproceedings{ WOS:000484938000021,
Author = {Apruzzese, Giovanni and Colajanni, Michele and Ferretti, Luca and
   Marchetti, Mirco},
Editor = {{Minarik, T and Alatalu, S and Biondi, S and Signoretti, M and Tolga, I and Visky, G}},
Title = {{Addressing Adversarial Attacks Against Security Systems Based on Machine
   Learning}},
Booktitle = {{2019 11TH INTERNATIONAL CONFERENCE ON CYBER CONFLICT (CYCON): SILENT
   BATTLE}},
Series = {{International Conference on Cyber Conflict}},
Year = {{2019}},
Pages = {{383-400}},
Note = {{11th Annual International Conference on Cyber Conflict (CyCon) - Silent
   Battle, Tallinn, ESTONIA, MAY 28-31, 2019}},
Organization = {{Inst Elect \& Elect Engineers; Microsoft; Guardtime; Thinklogical;
   EclecticIQ; NATO Cooperat Cyber Def Centre Excellence; Inst Elect \&
   Elect Engineers, Estonia Sect}},
Abstract = {{Machine-learning solutions are successfully adopted in multiple contexts
   but the application of these techniques to the cyber security domain is
   complex and still immature. Among the many open issues that affect
   security systems based on machine learning, we concentrate on
   adversarial attacks that aim to affect the detection and prediction
   capabilities of machine-learning models. We consider realistic types of
   poisoning and evasion attacks targeting security solutions devoted to
   malware, spam and network intrusion detection. We explore the possible
   damages that an attacker can cause to a cyber detector and present some
   existing and original defensive techniques in the context of intrusion
   detection systems. This paper contains several performance evaluations
   that are based on extensive experiments using large traffic datasets.
   The results highlight that modern adversarial attacks are highly
   effective against machine-learning classifiers for cyber detection, and
   that existing solutions require improvements in several directions. The
   paper paves the way for more robust machine-learning-based techniques
   that can be integrated into cyber security platforms.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Apruzzese, G (Corresponding Author), Univ Modena \& Reggio Emilia, Dept Engn Enzo Ferrari, Modena, Italy.
   Apruzzese, Giovanni; Colajanni, Michele; Ferretti, Luca; Marchetti, Mirco, Univ Modena \& Reggio Emilia, Dept Engn Enzo Ferrari, Modena, Italy.}},
ISSN = {{2325-5366}},
ISBN = {{978-9949-9904-5-0}},
Keywords = {{adversarial attacks; machine learning; deep learning; poisoning attacks;
   evasion attacks; intrusion detection}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods; Engineering, Electrical \&
   Electronic}},
Author-Email = {{giovanni.apruzzese@unimore.it
   michele.colajanni@unimore.it
   luca.ferretti@unimore.it
   mirco.marchetti@unimore.it}},
ResearcherID-Numbers = {{Apruzzese, Giovanni/AAQ-2764-2020}},
ORCID-Numbers = {{Apruzzese, Giovanni/0000-0002-6890-9611}},
Number-of-Cited-References = {{55}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{3}},
Doc-Delivery-Number = {{BN6AT}},
Unique-ID = {{WOS:000484938000021}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000501822200014,
Author = {Peng, Ye and Su, Jinshu and Shi, Xiangquan and Zhao, Baokang},
Editor = {{Wenzheng, L and Guomin, Z}},
Title = {{Evaluating Deep Learning Based Network Intrusion Detection System in
   Adversarial Environment}},
Booktitle = {{PROCEEDINGS OF 2019 IEEE 9TH INTERNATIONAL CONFERENCE ON ELECTRONICS
   INFORMATION AND EMERGENCY COMMUNICATION (ICEIEC 2019)}},
Series = {{IEEE International Conference on Electronics Information and Emergency
   Communication}},
Year = {{2019}},
Pages = {{61-66}},
Note = {{IEEE 9th International Conference on Electronics Information and
   Emergency Communication (ICEIEC), Beijing, PEOPLES R CHINA, JUL 12-14,
   2019}},
Organization = {{Inst Elect \& Elect Engineers; IEEE Beijing Sect}},
Abstract = {{Deep learning plays a vital role in network security field. Furthermore,
   the performance of deep learning based Network Intrusion Detection
   System (NIDS) is satisfactory and even better than the traditional
   methods. However, recent researches show that the accuracy of deep
   learning based image classification declines sharply when facing the
   adversaries. Regarding NIDS, there is no comprehensive evaluation of
   whether it will also be affected by attack models. In this paper, we
   propose a framework of Evaluationg Network Intrusion Detection System
   (ENIDS) to research the robustness of deep learning based NIDS in
   adversarial environment. More specifically, we train four target models
   (e.g., Deep Neural Networks, Support Vector Machine, Random Forest and
   Logistic Regression) over the benchmark dataset NSL-KDD. Furthermore,
   four advanced attack models (e.g., Projected Gradient Descent attack,
   Momentum Iterative Fast Gradient Sign Method, L-BFGS attack and SPSA
   attack) are used to generate adversarial samples. Finally, comprehensive
   and extensive experiment results show that the effectiveness of deep
   learning based NIDS is greatly undermined by the adversaries.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Shi, XQ (Corresponding Author), Natl Univ Def Technol, Coll Compute, Changsha 410073, Hunan, Peoples R China.
   Peng, Ye; Su, Jinshu; Shi, Xiangquan; Zhao, Baokang, Natl Univ Def Technol, Coll Compute, Changsha 410073, Hunan, Peoples R China.}},
ISSN = {{2377-8431}},
ISBN = {{978-1-7281-1190-2}},
Keywords = {{network and data security; network intrusion system; deep learning;
   security evaluation}},
Research-Areas = {{Computer Science; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Telecommunications}},
Author-Email = {{yepeng23@outlook.com}},
ResearcherID-Numbers = {{Su, Jinshu/M-1960-2014}},
ORCID-Numbers = {{Su, Jinshu/0000-0001-9273-616X}},
Funding-Acknowledgement = {{National Key Research and Development program {[}2017YFB0802300]}},
Funding-Text = {{The work is supported by National Key Research and Development program
   under Grant 2017YFB0802300.}},
Number-of-Cited-References = {{15}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BO1PF}},
Unique-ID = {{WOS:000501822200014}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000426895800127,
Author = {Viegas, Eduardo and Santin, Altair and Abreu, Vilmar and Oliveira, Luiz
   S.},
Book-Group-Author = {{IEEE}},
Title = {{Stream Learning and Anomaly-based Intrusion Detection in the Adversarial
   Settings}},
Booktitle = {{2017 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATIONS (ISCC)}},
Series = {{IEEE Symposium on Computers and Communications ISCC}},
Year = {{2017}},
Pages = {{773-778}},
Note = {{IEEE Symposium on Computers and Communications (ISCC), Heraklion,
   GREECE, JUL 03-07, 2017}},
Abstract = {{Despite existing many anomaly-based intrusion detection studies in the
   literature, they are not frequently adopted by the industry in
   production environments (products). Such a usage gap occurs mainly due
   to the difficulty to maintain the detection rate in acceptable level,
   given the occurrence of false alarms. In general, the literature does
   not consider the adversarial settings, when an opponent attempt to evade
   the detection system, thus possibly rendering the system unreliable over
   time. In this paper, we propose and evaluate a new approach to reliably
   perform real time stream learning for anomaly-based intrusion detection.
   We employ a class-specific stream outlier detector to automatically
   update the intrusion detection engine over the time, and a rejection
   mechanism, which makes it possible to obtain indications that an evasion
   attempt might being happening. Furthermore, the proposal is resilient to
   causative attacks, providing a secure intrusion detection mechanism even
   when the attacker can inject misclassified instances in the training
   dataset. The evaluation tests show that the proposed approach is
   resilient to exploratory attacks, allowing the system administrator to
   know when an evasion attempt might be occurring.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Viegas, E (Corresponding Author), Pontificia Univ Catolica Parana, Grad Program Comp Sci, Curitiba, Parana, Brazil.
   Viegas, Eduardo; Santin, Altair; Abreu, Vilmar, Pontificia Univ Catolica Parana, Grad Program Comp Sci, Curitiba, Parana, Brazil.
   Oliveira, Luiz S., Univ Fed Parana, Informat Dept, Curitiba, Parana, Brazil.}},
ISSN = {{1530-1346}},
ISBN = {{978-1-5386-1629-1}},
Keywords = {{Adversarial Settings; Outlier Detection; Stream Learning; Intrusion
   Detection}},
Keywords-Plus = {{SYSTEMS}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{eduardo.viegas@ppgia.pucpr.br
   santin@ppgia.pucpr.br
   vilmar.abreu@ppgia.pucpr.br
   luiz.oliveira@ufpr.br}},
ResearcherID-Numbers = {{Santin, Altair/B-2696-2013
   Viegas, Eduardo/AAT-8978-2020}},
ORCID-Numbers = {{Santin, Altair/0000-0002-2341-2177
   }},
Funding-Acknowledgement = {{Lab's University Research Office; Brazilian Coordination for the
   Improvement of Higher Education Personnel (CAPES)Coordenacao de
   Aperfeicoamento de Pessoal de Nivel Superior (CAPES)
   {[}99999.008512/2014-0]}},
Funding-Text = {{This work was partially sponsored by Intel Lab's University Research
   Office and the Brazilian Coordination for the Improvement of Higher
   Education Personnel (CAPES), grant 99999.008512/2014-0.}},
Number-of-Cited-References = {{19}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BJ6OR}},
Unique-ID = {{WOS:000426895800127}},
DA = {{2021-11-23}},
}

@article{ WOS:000541153400013,
Author = {Pawlicki, Marek and Choras, Michal and Kozik, Rafal},
Title = {{Defending network intrusion detection systems against adversarial
   evasion attacks}},
Journal = {{FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE}},
Year = {{2020}},
Volume = {{110}},
Pages = {{148-154}},
Month = {{SEP}},
Abstract = {{Intrusion Detection and the ability to detect attacks is a crucial
   aspect to ensure cybersecurity. However, what if an IDS (Intrusion
   Detection System) itself is attacked; in other words what defends the
   defender? In this work, the focus is on countering attacks on machine
   learning-based cyberattack detectors. In principle, we propose the
   adversarial machine learning detection solution. Indeed, contemporary
   machine learning algorithms have not been designed bearing in mind the
   adversarial nature of the environments they are deployed in. Thus,
   Machine Learning solutions are currently the target of a range of
   attacks. This paper evaluates the possibility of deteriorating the
   performance of a well-optimised intrusion detection algorithm at test
   time by crafting adversarial attacks with the four of the recently
   proposed methods and then offers a way to detect those attacks. The
   relevant background is provided for both artificial neural networks and
   four ways of crafting adversarial attacks. The new detection method is
   explained in detail, and the results of five different classifiers are
   compared. To the best of our knowledge, detecting adversarial attacks on
   artificial neural networks has not yet been widely researched in the
   context of intrusion detection systems. (C) 2020 Elsevier B.V. All
   rights reserved.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Choras, M (Corresponding Author), UTP Univ Sci \& Technol, Bydgoszcz, Poland.
   Pawlicki, Marek; Choras, Michal; Kozik, Rafal, ITTI Sp Zoo, Poznan, Poland.
   Pawlicki, Marek; Choras, Michal; Kozik, Rafal, UTP Univ Sci \& Technol, Bydgoszcz, Poland.}},
DOI = {{10.1016/j.future.2020.04.013}},
ISSN = {{0167-739X}},
EISSN = {{1872-7115}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods}},
Author-Email = {{marek.pawlicki@utp.edu.pl
   chorasm@utp.edu.pl}},
ResearcherID-Numbers = {{Pawlicki, Marek/AAG-3978-2019
   Pawlicki, Marek/ABC-3938-2021
   }},
ORCID-Numbers = {{Pawlicki, Marek/0000-0001-5881-6406
   Kozik, Rafal/0000-0001-7122-3306}},
Funding-Acknowledgement = {{SPARTA project from the European Union's Horizon 2020 research and
   innovation programme {[}830892]}},
Funding-Text = {{This work is funded under the SPARTA project, which has received funding
   from the European Union's Horizon 2020 research and innovation programme
   under grant agreement No 830892.}},
Number-of-Cited-References = {{45}},
Times-Cited = {{16}},
Usage-Count-Last-180-days = {{7}},
Usage-Count-Since-2013 = {{34}},
Journal-ISO = {{Futur. Gener. Comp. Syst.}},
Doc-Delivery-Number = {{LZ3UK}},
Unique-ID = {{WOS:000541153400013}},
DA = {{2021-11-23}},
}

@article{ WOS:000455145000089,
Author = {Song, Chongya and Pons, Alexander and Yen, Kang},
Title = {{AA-HMM: An Anti-Adversarial Hidden Markov Model for Network-Based
   Intrusion Detection}},
Journal = {{APPLIED SCIENCES-BASEL}},
Year = {{2018}},
Volume = {{8}},
Number = {{12}},
Month = {{DEC}},
Abstract = {{In the field of network intrusion, malware usually evades anomaly
   detection by disguising malicious behavior as legitimate access.
   Therefore, detecting these attacks from network traffic has become a
   challenge in this an adversarial setting. In this paper, an enhanced
   Hidden Markov Model, called the Anti-Adversarial Hidden Markov Model
   (AA-HMM), is proposed to effectively detect evasion pattern, using the
   Dynamic Window and Threshold techniques to achieve adaptive,
   anti-adversarial, and online-learning abilities. In addition, a concept
   called Pattern Entropy is defined and acts as the foundation of AA-HMM.
   We evaluate the effectiveness of our approach employing two well-known
   benchmark data sets, NSL-KDD and CTU-13, in terms of the common
   performance metrics and the algorithm's adaptation and anti-adversary
   abilities.}},
Publisher = {{MDPI}},
Address = {{ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Song, CY (Corresponding Author), Florida Int Univ, Dept Elect \& Comp Engn, Miami, FL 33174 USA.
   Song, Chongya; Pons, Alexander; Yen, Kang, Florida Int Univ, Dept Elect \& Comp Engn, Miami, FL 33174 USA.}},
DOI = {{10.3390/app8122421}},
Article-Number = {{2421}},
EISSN = {{2076-3417}},
Keywords = {{network intrusion detection; adversarial setting; Anti-Adversarial
   Hidden Markov Model (AA-HMM); evasion patterns; dynamic window (DW);
   threshold (TH); pattern entropy (PE); adaptability}},
Keywords-Plus = {{SYSTEMS}},
Research-Areas = {{Chemistry; Engineering; Materials Science; Physics}},
Web-of-Science-Categories  = {{Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied}},
Author-Email = {{ysong024@fiu.edu
   apons@fiu.edu
   yenk@fiu.edu}},
Funding-Acknowledgement = {{Florida Center for Cybersecurity {[}2016-1017]}},
Funding-Text = {{This research was funded by the Florida Center for Cybersecurity,
   2016-1017 FC2 Collaborative Seed Award Program.}},
Number-of-Cited-References = {{37}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{8}},
Journal-ISO = {{Appl. Sci.-Basel}},
Doc-Delivery-Number = {{HG7CG}},
Unique-ID = {{WOS:000455145000089}},
OA = {{gold}},
DA = {{2021-11-23}},
}

@article{ WOS:000540222200164,
Author = {Apruzzese, Giovanni and Andreolini, Mauro and Marchetti, Mirco and
   Colacino, Vincenzo Giuseppe and Russo, Giacomo},
Title = {{AppCon: Mitigating Evasion Attacks to ML Cyber Detectors}},
Journal = {{SYMMETRY-BASEL}},
Year = {{2020}},
Volume = {{12}},
Number = {{4}},
Month = {{APR}},
Abstract = {{Adversarial attacks represent a critical issue that prevents the
   reliable integration of machine learning methods into cyber defense
   systems. Past work has shown that even proficient detectors are highly
   affected just by small perturbations to malicious samples, and that
   existing countermeasures are immature. We address this problem by
   presenting AppCon, an original approach to harden intrusion detectors
   against adversarial evasion attacks. Our proposal leverages the
   integration of ensemble learning to realistic network environments, by
   combining layers of detectors devoted to monitor the behavior of the
   applications employed by the organization. Our proposal is validated
   through extensive experiments performed in heterogeneous network
   settings simulating botnet detection scenarios, and consider detectors
   based on distinct machine- and deep-learning algorithms. The results
   demonstrate the effectiveness of AppCon in mitigating the dangerous
   threat of adversarial attacks in over 75\% of the considered evasion
   attempts, while not being affected by the limitations of existing
   countermeasures, such as performance degradation in non-adversarial
   settings. For these reasons, our proposal represents a valuable
   contribution to the development of more secure cyber defense platforms.}},
Publisher = {{MDPI}},
Address = {{ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Apruzzese, G (Corresponding Author), Univ Modena \& Reggio Emilia, Dept Engn Enzo Ferrari, I-41125 Modena, Italy.
   Apruzzese, Giovanni; Andreolini, Mauro; Marchetti, Mirco; Colacino, Vincenzo Giuseppe; Russo, Giacomo, Univ Modena \& Reggio Emilia, Dept Engn Enzo Ferrari, I-41125 Modena, Italy.}},
DOI = {{10.3390/sym12040653}},
Article-Number = {{653}},
EISSN = {{2073-8994}},
Keywords = {{adversarial attacks; network intrusion detection; evasion attacks; cyber
   security; machine learning}},
Keywords-Plus = {{ADVERSARIAL; SECURITY; BOTNET}},
Research-Areas = {{Science \& Technology - Other Topics}},
Web-of-Science-Categories  = {{Multidisciplinary Sciences}},
Author-Email = {{giovanni.apruzzese@unimore.it
   mauro.andreolini@unimore.it
   mirco.marchetti@unimore.it
   vincenzogiuseppe.colacino@unimore.it
   giacomorusso@protonmail.com}},
ResearcherID-Numbers = {{Apruzzese, Giovanni/AAQ-2764-2020
   Marchetti, Mirco/K-6057-2015}},
ORCID-Numbers = {{Apruzzese, Giovanni/0000-0002-6890-9611
   Marchetti, Mirco/0000-0002-7408-6906}},
Number-of-Cited-References = {{71}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{3}},
Journal-ISO = {{Symmetry-Basel}},
Doc-Delivery-Number = {{LY0NY}},
Unique-ID = {{WOS:000540222200164}},
OA = {{gold, Green Published}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000403420500123,
Author = {McElwee, Steven},
Book-Group-Author = {{IEEE}},
Title = {{Active Learning Intrusion Detection using k-Means Clustering Selection}},
Booktitle = {{SOUTHEASTCON 2017}},
Series = {{IEEE SoutheastCon-Proceedings}},
Year = {{2017}},
Note = {{IEEE SoutheastCon Conference, Charlotte, NC, MAR 30-APR 02, 2017}},
Organization = {{IEEE}},
Abstract = {{Intrusion detection is an important method for identifying attacks and
   compromises of computer systems, but it is complicated by rapid changes
   in technology, the increasing interconnectedness of devices on the
   internet, the growing use of cyberattacks, and more sophisticated and
   automated attack methods and tools used by adversaries. The challenge of
   intrusion detection is further complicated because, as advances are made
   in the ability to detect attacks, similar advances are made by
   adversaries to thwart those detective measures. Although numerous
   machine learning algorithms and approaches have proven effective in
   detecting cyberattacks, these algorithms have limitations, especially in
   dealing with adversarial environments. This study addresses the problem
   that there is not an effective machine learning algorithm that minimizes
   human interaction to train and evolve the learner to adapt to changing
   cyberattacks and evasive tactics. This research concludes that selective
   sampling of unlabeled data for classification by a human expert can
   result in more efficient labeling for large datasets and demonstrates a
   more resilient approach to machine learning that utilizes active
   learning to interact with human subject matter experts and that adapts
   to changing data, thus addressing issues related to data tampering and
   evasion.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{McElwee, S (Corresponding Author), Nova Southeastern Univ, Coll Engn \& Comp, Ft Lauderdale, FL 33314 USA.
   McElwee, Steven, Nova Southeastern Univ, Coll Engn \& Comp, Ft Lauderdale, FL 33314 USA.}},
ISSN = {{1558-058X}},
ISBN = {{978-1-5386-1539-3}},
Keywords = {{machine learning; intrusion detection; random forest; active learning;
   k-means clustering; adversarial evasion; tampering; KDD-CUP 99}},
Keywords-Plus = {{NEURAL-NETWORKS}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods; Engineering, Electrical \&
   Electronic}},
Author-Email = {{sm2752@nova.edu}},
Number-of-Cited-References = {{23}},
Times-Cited = {{8}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BH8LM}},
Unique-ID = {{WOS:000403420500123}},
DA = {{2021-11-23}},
}

@article{ WOS:000546414500012,
Author = {Homoliak, Ivan and Malinka, Kamil and Hanacek, Petr},
Title = {{ASNM Datasets: A Collection of Network Attacks for Testing of
   Adversarial Classifiers and Intrusion Detectors}},
Journal = {{IEEE ACCESS}},
Year = {{2020}},
Volume = {{8}},
Pages = {{112427-112453}},
Abstract = {{In this paper, we present three datasets that have been built from
   network traffic traces using ASNM (Advanced Security Network Metrics)
   features, designed in our previous work. The first dataset was built
   using a state-of-the-art dataset CDX 2009 that was collected during a
   cyber defense exercise, while the remaining two datasets were collected
   by us in 2015 and 2018 using publicly available network services
   containing buffer overflow and other high severity vulnerabilities.
   These two datasets contain several adversarial obfuscation techniques
   that were applied onto malicious as well as legitimate traffic samples
   during ``the execution{''} of their TCP network connections. Adversarial
   obfuscation techniques were used for evading machine learning-based
   network intrusion detection classifiers. We show that the performance of
   such classifiers can be improved when partially augmenting their
   training data by samples obtained from obfuscation techniques. In
   detail, we utilized tunneling obfuscation in HTTP(S) protocol and
   non-payload-based obfuscations modifying various properties of network
   traffic by, e.g., TCP segmentation, re-transmissions, corrupting and
   reordering of packets, etc. To the best of our knowledge, this is the
   first collection of network traffic data that contains adversarial
   techniques and is intended for non-payload-based network intrusion
   detection and adversarial classification. Provided datasets enable
   testing of the evasion resistance of arbitrary machine learning-based
   classifiers.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Homoliak, I (Corresponding Author), Brno Univ Technol, Fac Informat Technol, Ctr Excellence IT4Innovat, Brno 61200, Czech Republic.
   Homoliak, Ivan; Malinka, Kamil; Hanacek, Petr, Brno Univ Technol, Fac Informat Technol, Ctr Excellence IT4Innovat, Brno 61200, Czech Republic.}},
DOI = {{10.1109/ACCESS.2020.3001768}},
ISSN = {{2169-3536}},
Keywords = {{Feature extraction; Protocols; Network intrusion detection; Servers;
   Detectors; Dataset; network intrusion detection; adversarial
   classification; evasions; ASNM features; buffer overflow;
   non-payload-based obfuscations; tunneling obfuscations}},
Keywords-Plus = {{SQUARE FEATURE-SELECTION; DETECTION SYSTEMS; DATA SET; OPTIMIZATION;
   CLASSIFICATION; ALGORITHMS; TAXONOMY; ENSEMBLE}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{ihomoliak@fit.vutbr.cz}},
ResearcherID-Numbers = {{Homoliak, Ivan/V-7525-2019
   }},
ORCID-Numbers = {{Homoliak, Ivan/0000-0002-0790-0875
   Hanacek, Petr/0000-0001-5507-0768
   Malinka, Kamil/0000-0002-9009-2193}},
Funding-Acknowledgement = {{Ministry of Education, Youth and Sports of the Czech Republic from the
   National Programme of Sustainability (NPU II); project IT4Innovations
   excellence in science {[}LQ1602]}},
Funding-Text = {{This work was supported by The Ministry of Education, Youth and Sports
   of the Czech Republic from the National Programme of Sustainability (NPU
   II); project IT4Innovations excellence in science-LQ1602.}},
Number-of-Cited-References = {{89}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{IEEE Access}},
Doc-Delivery-Number = {{MH0IN}},
Unique-ID = {{WOS:000546414500012}},
OA = {{Green Submitted, gold}},
DA = {{2021-11-23}},
}

@article{ WOS:000673624000027,
Author = {Han, Dongqi and Wang, Zhiliang and Zhong, Ying and Chen, Wenqi and Yang,
   Jiahai and Lu, Shuqiang and Shi, Xingang and Yin, Xia},
Title = {{Evaluating and Improving Adversarial Robustness of Machine
   Learning-Based Network Intrusion Detectors}},
Journal = {{IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS}},
Year = {{2021}},
Volume = {{39}},
Number = {{8}},
Pages = {{2632-2647}},
Month = {{AUG}},
Abstract = {{Machine learning (ML), especially deep learning (DL) techniques have
   been increasingly used in anomaly-based network intrusion detection
   systems (NIDS). However, ML/DL has shown to be extremely vulnerable to
   adversarial attacks, especially in such security-sensitive systems. Many
   adversarial attacks have been proposed to evaluate the robustness of
   ML-based NIDSs. Unfortunately, existing attacks mostly focused on
   feature-space and/or white-box attacks, which make impractical
   assumptions in real-world scenarios, leaving the study on practical
   gray/black-box attacks largely unexplored. To bridge this gap, we
   conduct the first systematic study of the gray/black-box traffic-space
   adversarial attacks to evaluate the robustness of ML-based NIDSs. Our
   work outperforms previous ones in the following aspects: (i) practical
   -the proposed attack can automatically mutate original traffic with
   extremely limited knowledge and affordable overhead while preserving its
   functionality; (ii) generic -the proposed attack is effective for
   evaluating the robustness of various NIDSs using diverse ML/DL models
   and non-payload-based features; (iii) explainable -we propose an
   explanation method for the fragile robustness of ML-based NIDSs. Based
   on this, we also propose a defense scheme against adversarial attacks to
   improve system robustness. We extensively evaluate the robustness of
   various NIDSs using diverse feature sets and ML/DL models. Experimental
   results show our attack is effective (e.g., >97\% evasion rate in half
   cases for Kitsune, a state-of-the-art NIDS) with affordable execution
   cost and the proposed defense method can effectively mitigate such
   attacks (evasion rate is reduced by >50\% in most cases).}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Wang, ZL (Corresponding Author), Tsinghua Univ, Inst Network Sci \& Cyberspace, Beijing 100084, Peoples R China.
   Han, Dongqi; Wang, Zhiliang; Zhong, Ying; Chen, Wenqi; Yang, Jiahai; Shi, Xingang, Tsinghua Univ, Inst Network Sci \& Cyberspace, Beijing 100084, Peoples R China.
   Lu, Shuqiang; Yin, Xia, Tsinghua Univ, Dept Comp Sci, Beijing 100084, Peoples R China.}},
DOI = {{10.1109/JSAC.2021.3087242}},
ISSN = {{0733-8716}},
EISSN = {{1558-0008}},
Keywords = {{Robustness; Feature extraction; Malware; Detectors; Deep learning;
   Adversarial machine learning; Upper bound; Network anomaly detection;
   network intrusion detection systems; adversarial machine learning;
   machine learning security; evasion attack}},
Keywords-Plus = {{SYSTEMS}},
Research-Areas = {{Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic; Telecommunications}},
Author-Email = {{handq19@mails.tsinghua.edu.cn
   wzl@cernet.edu.cn
   zhongy18@mails.tsinghua.edu.cn
   chenwq19@mails.tsinghua.edu.cn
   yang@cernet.edu.cn
   lusq18@mails.tsinghua.edu.cn
   shixg@cernet.edu.cn
   yxia@tsinghua.edu.cn}},
ORCID-Numbers = {{Han, Dongqi/0000-0002-0807-5934}},
Funding-Acknowledgement = {{National Key Research and Development Program of China
   {[}2018YFB1800200]}},
Funding-Text = {{This work was supported in part by the National Key Research and
   Development Program of China under Grant 2018YFB1800200.}},
Number-of-Cited-References = {{60}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{8}},
Usage-Count-Since-2013 = {{8}},
Journal-ISO = {{IEEE J. Sel. Areas Commun.}},
Doc-Delivery-Number = {{TJ6YF}},
Unique-ID = {{WOS:000673624000027}},
OA = {{Green Submitted}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000662226500002,
Author = {Peng, Ye and Fu, Guobin and Luo, Yingguang and Hu, Jia and Li, Bin and
   Yan, Qifei},
Editor = {{Wenzheng, L}},
Title = {{Detecting Adversarial Examples for Network Intrusion Detection System
   with GAN}},
Booktitle = {{PROCEEDINGS OF 2020 IEEE 11TH INTERNATIONAL CONFERENCE ON SOFTWARE
   ENGINEERING AND SERVICE SCIENCE (ICSESS 2020)}},
Series = {{International Conference on Software Engineering and Service Science}},
Year = {{2020}},
Pages = {{6-10}},
Note = {{11th IEEE International Conference on Software Engineering and Service
   Science (IEEE ICSESS), Beijing, PEOPLES R CHINA, OCT 16-18, 2020}},
Organization = {{Inst Elect \& Elect Engineers; IEEE Beijing Sect}},
Abstract = {{With the increasing scale of network, attacks against network emerge one
   after another, and security problems become increasingly prominent.
   Network intrusion detection system is a widely used and effective
   security means at present. In addition, with the development of machine
   learning technology, various intelligent intrusion detection algorithms
   also start to sprout. By flexibly combining these intelligent methods
   with intrusion detection technology, the comprehensive performance of
   intrusion detection can be improved, but the vulnerability of machine
   learning model in the adversarial environment can not be ignored. In
   this paper, we study the defense problem of network intrusion detection
   system against adversarial samples. More specifically, we design a
   defense algorithm for NIDS against adversarial samples by using
   bidirectional generative adversarial network. The generator learns the
   data distribution of normal samples during training, which is an
   implicit model reflecting the normal data distribution. After training,
   the adversarial sample detection module calculates the reconstruction
   error and the discriminator matching error of sample. Then, the
   adversarial samples are removed, which improves the robustness and
   accuracy of NIDS in the adversarial environment.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Fu, GB (Corresponding Author), Natl Univ Def Technol, Acad Informat \& Commun, Wuhan 430010, Peoples R China.
   Peng, Ye; Fu, Guobin; Luo, Yingguang; Hu, Jia; Li, Bin; Yan, Qifei, Natl Univ Def Technol, Acad Informat \& Commun, Wuhan 430010, Peoples R China.}},
ISSN = {{2327-0594}},
ISBN = {{978-1-7281-6579-0}},
Keywords = {{network and data security; network intrusion system; machine learning;
   adversarial sample; defense technology}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Software Engineering}},
Author-Email = {{pengye17@nudt.edu.cn
   13397190100@163.com}},
Number-of-Cited-References = {{23}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{4}},
Usage-Count-Since-2013 = {{4}},
Doc-Delivery-Number = {{BR6NO}},
Unique-ID = {{WOS:000662226500002}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000606970303035,
Author = {Abou Khamis, Rana and Shafiq, M. Omair and Matrawy, Ashraf},
Book-Group-Author = {{IEEE}},
Title = {{Investigating Resistance of Deep Learning-based IDS against Adversaries
   using min-max Optimization}},
Booktitle = {{ICC 2020 - 2020 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS (ICC)}},
Series = {{IEEE International Conference on Communications}},
Year = {{2020}},
Note = {{IEEE International Conference on Communications (IEEE ICC) / Workshop on
   NOMA for 5G and Beyond, ELECTR NETWORK, JUN 07-11, 2020}},
Organization = {{IEEE; Huawei; ZTE; Qualcomm}},
Abstract = {{With the growth of adversarial attacks against machine learning models,
   several concerns have emerged about potential vulnerabilities in
   designing deep neural network-based intrusion detection systems (IDS).
   In this paper, we study the resilience of deep learning-based intrusion
   detection systems against adversarial attacks. We apply the min-max (or
   saddle-point) approach to train intrusion detection systems against
   adversarial attack samples in UNSW-NB 15 dataset. We have the max
   approach for generating adversarial samples that achieves maximum loss
   and attack deep neural networks. On the other side, we utilize the
   existing min approach {[}1] {[}2] as a defense strategy to optimize
   intrusion detection systems that minimize the loss of the incorporated
   adversarial samples during the adversarial training. We study and
   measure the effectiveness of the adversarial attack methods as well as
   the resistance of the adversarially trained models against such attacks.
   We find that the adversarial attack methods that were designed in binary
   domains can be used in continuous domains and exhibit different
   misclassification levels. We finally show that principal component
   analysis (PCA) based feature reduction can boost the robustness in
   intrusion detection system (IDS) using a deep neural network (DNN).}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Abou Khamis, R (Corresponding Author), Carleton Univ, Sch Informat Technol, Ottawa, ON, Canada.
   Abou Khamis, Rana; Shafiq, M. Omair; Matrawy, Ashraf, Carleton Univ, Sch Informat Technol, Ottawa, ON, Canada.}},
ISSN = {{1550-3607}},
ISBN = {{978-1-7281-5089-5}},
Keywords = {{Deep Learning-based Intrusion Detection; adversarial samples;
   adversarial learning}},
Research-Areas = {{Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic; Telecommunications}},
Author-Email = {{rana.aboukhamis@carleton.ca
   omair.shafiq@carleton.ca
   ashraf.matrawy@carleton.ca}},
Funding-Acknowledgement = {{Natural Sciences and Engineering Research Council of Canada (NSERC)
   through the NSERC Discovery Grant programNatural Sciences and
   Engineering Research Council of Canada (NSERC)}},
Funding-Text = {{This work was supported in part by the Natural Sciences and Engineering
   Research Council of Canada (NSERC) through the NSERC Discovery Grant
   program.}},
Number-of-Cited-References = {{16}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BQ5PR}},
Unique-ID = {{WOS:000606970303035}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000685214600015,
Author = {Aiken, James and Scott-Hayward, Sandra},
Editor = {{Homer, L and Tutschku, K and Granelli, F and Sekiya, Y and Tacca, M and Bhamare, D and Parzyjegla, H}},
Title = {{Investigating Adversarial Attacks against Network Intrusion Detection
   Systems in SDNs}},
Booktitle = {{2019 IEEE CONFERENCE ON NETWORK FUNCTION VIRTUALIZATION AND SOFTWARE
   DEFINED NETWORKS (IEEE NFV-SDN)}},
Year = {{2019}},
Note = {{IEEE Conference on Network Function Virtualization and Software Defined
   Networks (NFV-SDN), Dallas, TX, NOV 12-14, 2019}},
Organization = {{IEEE; IEEE Commun Soc; Intel; Fujitsu; Blekinge Inst Technol; European
   Telecommunicat Stand Inst; MEF Forum}},
Abstract = {{Machine-learning based network intrusion detection systems (ML-NIDS) are
   increasingly popular in the fight against network attacks. In
   particular, promising detection results have been demonstrated in
   conjunction with Software-Defined Net-works (SDN), in which the
   logically centralized control plane provides access to data from across
   the network. However, research into adversarial attacks against machine
   learning classifiers has highlighted vulnerabilities in a number of
   fields. These vulnerabilities raise concerns about the implementation of
   similar classifiers in anomaly-based NIDSs within SDNs. In this work, we
   investigate the viability of adversarial attacks against classifiers in
   this field. We implement an anomaly-based NIDS, Neptune, as a target
   platform that utilises a number of different machine learning
   classifiers and traffic flow features. We develop an adversarial test
   tool, Hydra, to evaluate the impact of adversarial evasion classifier
   attacks against Neptune with the goal of lowering the detection rate of
   malicious network traffic. The results demonstrate that with the
   perturbation of a few features, the detection accuracy of a specific SYN
   flood Distributed Denial of Service (DDoS) attack by Neptune decreases
   from 100\% to 0\% across a number of classifiers. Based on these
   results, recommendations are made as to how to increase the robustness
   of classifiers against the demonstrated attacks.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Aiken, J (Corresponding Author), Queens Univ Belfast, Ctr Secure Informat Technol, Belfast BT3 9DT, Antrim, North Ireland.
   Aiken, James; Scott-Hayward, Sandra, Queens Univ Belfast, Ctr Secure Informat Technol, Belfast BT3 9DT, Antrim, North Ireland.}},
ISBN = {{978-1-7281-4545-7}},
Keywords = {{Network Security; Software-Defined Networks; Intrusion Detection
   Systems; Machine Learning; Adversarial Attacks}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Hardware \& Architecture; Computer Science,
   Information Systems; Engineering, Electrical \& Electronic;
   Telecommunications}},
Author-Email = {{jaiken06@qub.ac.uk
   s.scott-hayward@qub.ac.uk}},
Number-of-Cited-References = {{27}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BS0XZ}},
Unique-ID = {{WOS:000685214600015}},
DA = {{2021-11-23}},
}

@article{ WOS:000673834000001,
Author = {Randhawa, Rizwan Hamid and Aslam, Nauman and Alauthman, Mohammad and
   Rafiq, Husnain and Comeau, Frank},
Title = {{Security Hardening of Botnet Detectors Using Generative Adversarial
   Networks}},
Journal = {{IEEE ACCESS}},
Year = {{2021}},
Volume = {{9}},
Pages = {{78276-78292}},
Abstract = {{Machine learning (ML) based botnet detectors are no exception to
   traditional ML models when it comes to adversarial evasion attacks. The
   datasets used to train these models have also scarcity and imbalance
   issues. We propose a new technique named Botshot, based on generative
   adversarial networks (GANs) for addressing these issues and proactively
   making botnet detectors aware of adversarial evasions. Botshot is
   cost-effective as compared to the network emulation for botnet traffic
   data generation rendering the dedicated hardware resources unnecessary.
   First, we use the extended set of network flow and time-based features
   for three publicly available botnet datasets. Second, we utilize two
   GANs (vanilla, conditional) for generating realistic botnet traffic. We
   evaluate the generator performance using classifier two-sample test
   (C2ST) with 10-fold 70-30 train-test split and propose the use of
   `recall' in contrast to `accuracy' for proactively learning adversarial
   evasions. We then augment the train set with the generated data and test
   using the unchanged test set. Last, we compare our results with
   benchmark oversampling methods with augmentation of additional botnet
   traffic data in terms of average accuracy, precision, recall and F1
   score over six different ML classifiers. The empirical results
   demonstrate the effectiveness of the GAN-based oversampling for learning
   in advance the adversarial evasion attacks on botnet detectors.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Randhawa, RH (Corresponding Author), Northumbria Univ, Dept Comp \& Informat Syst, Newcastle Upon Tyne NE1 8ST, Tyne \& Wear, England.
   Randhawa, Rizwan Hamid; Aslam, Nauman; Rafiq, Husnain, Northumbria Univ, Dept Comp \& Informat Syst, Newcastle Upon Tyne NE1 8ST, Tyne \& Wear, England.
   Alauthman, Mohammad, Univ Petra, Dept Informat Secur, Amman 11196, Jordan.
   Comeau, Frank, St Francis Xavier Univ, Dept Engn, Antigonish, NS B2G 0B7, Canada.}},
DOI = {{10.1109/ACCESS.2021.3083421}},
ISSN = {{2169-3536}},
Keywords = {{Botnet; Generative adversarial networks; Detectors; Training;
   Generators; Biological system modeling; Feature extraction; Botnet
   detection; GANs; adversarial evasion attacks; unbalanced datasets}},
Keywords-Plus = {{INTRUSION DETECTION; SYSTEMS}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{rizwan.randhawa@northumbria.ac.uk}},
ResearcherID-Numbers = {{Alauthman, Mohammad/Y-2770-2019
   }},
ORCID-Numbers = {{Alauthman, Mohammad/0000-0003-0319-1968
   Randhawa, Rizwan Hamid/0000-0003-1563-5239}},
Funding-Acknowledgement = {{Northumbria University Research and Development Fund (RDF)}},
Funding-Text = {{This work was supported by Northumbria University Research and
   Development Fund (RDF).}},
Number-of-Cited-References = {{54}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{5}},
Usage-Count-Since-2013 = {{5}},
Journal-ISO = {{IEEE Access}},
Doc-Delivery-Number = {{TK0AZ}},
Unique-ID = {{WOS:000673834000001}},
OA = {{Green Accepted, gold}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000705054100085,
Author = {Chaitou, Hassan and Robert, Thomas and Leneutre, Jean and Pautet,
   Laurent},
Book-Group-Author = {{IEEE}},
Title = {{Assessing adversarial training effect on IDSs and GANs}},
Booktitle = {{PROCEEDINGS OF THE 2021 IEEE INTERNATIONAL CONFERENCE ON CYBER SECURITY
   AND RESILIENCE (IEEE CSR)}},
Year = {{2021}},
Pages = {{543-550}},
Note = {{IEEE International Conference on Cyber Security and Resilience (IEEE
   CSR), ELECTR NETWORK, JUL 26-28, 2021}},
Organization = {{IEEE; IEEE Syst, Man, \& Cybernet Soc; LOGOS Res \& Innovat; IEEE
   Transact Emerging Top Comp; Journal Cybersecur \& Privacy; MDF, Sensors
   Journal}},
Abstract = {{Deep neural network-based Intrusion Detection Systems (IDSs) are gaining
   popularity to improve anomaly detection accuracy and robustness. Yet,
   Deep neural network (DNN) models have been shown to be vulnerable to
   adversarial attacks. An attacker can use a generator, here a Generative
   Adversarial Network, to alter an attack so that the IDS model
   misclassify it as normal network traffic. There is a race between
   adversarial attacks and mechanisms to make robust IDSs, like Adversarial
   Training. To our knowledge, no study thoroughly assesses how attack
   generators or IDS training is sensitive to parameters controlling
   resources spent during training. Such results provide insights on how
   much to spend on IDS training. This paper presents the outcome of this
   assessment for GANs vs adversarial training. Interestingly, it shows
   that GANs' evasion capabilities are either very good or poor, with
   almost no average cases. Resources impact the likelihood of obtaining an
   efficient generator.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Chaitou, H (Corresponding Author), Inst Polytech Paris, Telecom Paris, LTCI, Paris, France.
   Chaitou, Hassan; Robert, Thomas; Leneutre, Jean; Pautet, Laurent, Inst Polytech Paris, Telecom Paris, LTCI, Paris, France.}},
DOI = {{10.1109/CSR51186.2021.9527949}},
ISBN = {{978-1-6654-0285-9}},
Keywords = {{Adversarial machine learning; GAN; Intrusion Detection System;
   Sensitivity analysis}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications}},
Author-Email = {{hassan.chaitou@telecom-paris.fr
   thomas.robert@telecom-paris.fr
   jean.leneutre@telecom-paris.fr
   laurent.pautet@telecom-paris.fr}},
Number-of-Cited-References = {{15}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BS2OZ}},
Unique-ID = {{WOS:000705054100085}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000508399700066,
Author = {Li, Bo and Vorobeychik, Yevgeniy},
Editor = {{Lebanon, G and Vishwanathan, SVN}},
Title = {{Scalable Optimization of Randomized Operational Decisions in Adversarial
   Classification Settings}},
Booktitle = {{ARTIFICIAL INTELLIGENCE AND STATISTICS, VOL 38}},
Series = {{JMLR Workshop and Conference Proceedings}},
Year = {{2015}},
Volume = {{38}},
Pages = {{599-607}},
Note = {{18th International Conference on Artificial Intelligence and Statistics
   (AISTATS), San Diego, CA, MAY 09-12, 2015}},
Abstract = {{When learning, such as classification, is used in adversarial settings,
   such as intrusion detection, intelligent adversaries will attempt to
   evade the resulting policies. The literature on adversarial machine
   learning aims to develop learning algorithms which are robust to such
   adversarial evasion, but exhibits two significant limitations: a)
   failure to account for operational constraints and b) a restriction that
   decisions are deterministic. To overcome these limitations, we introduce
   a conceptual separation between learning, used to infer attacker
   preferences, and operational decisions, which account for adversarial
   evasion, enforce operational constraints, and naturally admit
   randomization. Our approach gives rise to an intractably large linear
   program. To overcome scalability limitations, we introduce a novel
   method for estimating a compact parity basis representation for the
   operational decision function. Additionally, we develop an iterative
   constraint generation approach which embeds adversary's best response
   calculation, to arrive at a scalable algorithm for computing
   near-optimal randomized operational decisions. Extensive experiments
   demonstrate the efficacy of our approach.}},
Publisher = {{MICROTOME PUBLISHING}},
Address = {{31 GIBBS ST, BROOKLINE, MA 02446 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Li, B (Corresponding Author), Vanderbilt Univ, Elect Engn \& Comp Sci, 221 Kirkland Hall, Nashville, TN 37235 USA.
   Li, Bo; Vorobeychik, Yevgeniy, Vanderbilt Univ, Elect Engn \& Comp Sci, 221 Kirkland Hall, Nashville, TN 37235 USA.}},
ISSN = {{1938-7288}},
Research-Areas = {{Computer Science; Mathematics}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Statistics \& Probability}},
Author-Email = {{bo.li.2@vanderbilt.edu
   yevgeniy.vorobeychik@vanderbilt.edu}},
Funding-Acknowledgement = {{National Science FoundationNational Science Foundation (NSF)
   {[}CNS-1238959]; Air Force Research Laboratory {[}FA8750-14-2-0180];
   Sandia National LaboratoriesUnited States Department of Energy (DOE)}},
Funding-Text = {{This work was supported in part by the National Science Foundation under
   Award CNS-1238959, by the Air Force Research Laboratory under Award
   FA8750-14-2-0180, and by Sandia National Laboratories.}},
Number-of-Cited-References = {{20}},
Times-Cited = {{10}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BO2SX}},
Unique-ID = {{WOS:000508399700066}},
DA = {{2021-11-23}},
}

@article{ WOS:000527035200001,
Author = {Xi, Bowei},
Title = {{Adversarial machine learning for cybersecurity and computer vision:
   Current developments and challenges}},
Journal = {{WILEY INTERDISCIPLINARY REVIEWS-COMPUTATIONAL STATISTICS}},
Year = {{2020}},
Volume = {{12}},
Number = {{5}},
Month = {{SEP}},
Abstract = {{We provide a comprehensive overview of adversarial machine learning
   focusing on two application domains, that is, cybersecurity and computer
   vision. Research in adversarial machine learning addresses a significant
   threat to the wide application of machine learning techniques-they are
   vulnerable to carefully crafted attacks from malicious adversaries. For
   example, deep neural networks fail to correctly classify adversarial
   images, which are generated by adding imperceptible perturbations to
   clean images. We first discuss three main categories of attacks against
   machine learning techniques-poisoning attacks, evasion attacks, and
   privacy attacks. Then the corresponding defense approaches are
   introduced along with the weakness and limitations of the existing
   defense approaches. We notice adversarial samples in cybersecurity and
   computer vision are fundamentally different. While adversarial samples
   in cybersecurity often have different properties/distributions compared
   with training data, adversarial images in computer vision are created
   with minor input perturbations. This further complicates the development
   of robust learning techniques, because a robust learning technique must
   withstand different types of attacks.
   This article is categorized under:
   Statistical Learning and Exploratory Methods of the Data Sciences >
   Clustering and Classification
   Statistical Learning and Exploratory Methods of the Data Sciences > Deep
   Learning
   Statistical and Graphical Methods of Data Analysis > Robust Methods}},
Publisher = {{WILEY}},
Address = {{111 RIVER ST, HOBOKEN 07030-5774, NJ USA}},
Type = {{Review}},
Language = {{English}},
Affiliation = {{Xi, BW (Corresponding Author), Purdue Univ, Dept Stat, W Lafayette, IN 47907 USA.
   Xi, Bowei, Purdue Univ, Dept Stat, W Lafayette, IN 47907 USA.}},
DOI = {{10.1002/wics.1511}},
Early Access Date = {{APR 2020}},
Article-Number = {{e1511}},
ISSN = {{1939-0068}},
Keywords = {{adversarial machine learning; cybersecurity; deep learning; evasion
   attack; poisoning attack}},
Keywords-Plus = {{INTRUSION DETECTION; ATTACKS; SECURITY; PATTERNS; PRIVACY; MODELS; NOISE}},
Research-Areas = {{Mathematics}},
Web-of-Science-Categories  = {{Statistics \& Probability}},
Author-Email = {{xbw@purdue.edu}},
Funding-Acknowledgement = {{Army Research Office {[}W911NF-17-1-0356]}},
Funding-Text = {{Army Research Office, Grant/Award Number: W911NF-17-1-0356}},
Number-of-Cited-References = {{125}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{4}},
Usage-Count-Since-2013 = {{14}},
Journal-ISO = {{Wiley Interdiscip. Rev.-Comput. Stat.}},
Doc-Delivery-Number = {{ND2QA}},
Unique-ID = {{WOS:000527035200001}},
OA = {{Green Submitted}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000664076200014,
Author = {Pacheco, Yulexis and Sun, Weiqing},
Editor = {{Mori, P and Lenzini, G and Furnell, S}},
Title = {{Adversarial Machine Learning: A Comparative Study on Contemporary
   Intrusion Detection Datasets}},
Booktitle = {{ICISSP: PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON INFORMATION
   SYSTEMS SECURITY AND PRIVACY}},
Year = {{2021}},
Pages = {{160-171}},
Note = {{7th International Conference on Information Systems Security and Privacy
   (ICISSP), ELECTR NETWORK, FEB 11-13, 2021}},
Abstract = {{Studies have shown the vulnerability of machine learning algorithms
   against adversarial samples in image classification problems in deep
   neural networks. However, there is a need for performing comprehensive
   studies of adversarial machine learning in the intrusion detection
   domain, where current research has been mainly conducted on the widely
   available KDD'99 and NSL-KDD datasets. In this study, we evaluate the
   vulnerability of contemporary datasets (in particular, UNSW-NB15 and
   Bot-IoT datasets) that represent the modern network environment against
   popular adversarial deep learning attack methods, and assess various
   machine learning classifiers' robustness against the generated
   adversarial samples. Our study shows the feasibility of the attacks for
   both datasets where adversarial samples successfully decreased the
   overall detection performance.}},
Publisher = {{SCITEPRESS}},
Address = {{AV D MANUELL, 27A 2 ESQ, SETUBAL, 2910-595, PORTUGAL}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Pacheco, Y (Corresponding Author), Univ Toledo, Coll Engn, 2801 W Bancroft St, Toledo, OH 43606 USA.
   Pacheco, Yulexis; Sun, Weiqing, Univ Toledo, Coll Engn, 2801 W Bancroft St, Toledo, OH 43606 USA.}},
DOI = {{10.5220/0010253501600171}},
ISBN = {{978-989-758-491-6}},
Keywords = {{Adversarial Machine Learning; Deep Learning; Deep Neural Networks;
   Intrusion Detection Datasets}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems}},
Number-of-Cited-References = {{25}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{5}},
Usage-Count-Since-2013 = {{5}},
Doc-Delivery-Number = {{BR6TS}},
Unique-ID = {{WOS:000664076200014}},
OA = {{hybrid}},
DA = {{2021-11-23}},
}

@article{ WOS:000597226700002,
Author = {Apruzzese, Giovanni and Andreolini, Mauro and Marchetti, Mirco and
   Venturi, Andrea and Colajanni, Michele},
Title = {{Deep Reinforcement Adversarial Learning Against Botnet Evasion Attacks}},
Journal = {{IEEE TRANSACTIONS ON NETWORK AND SERVICE MANAGEMENT}},
Year = {{2020}},
Volume = {{17}},
Number = {{4}},
Pages = {{1975-1987}},
Month = {{DEC}},
Abstract = {{As cybersecurity detectors increasingly rely on machine learning
   mechanisms, attacks to these defenses escalate as well. Supervised
   classifiers are prone to adversarial evasion, and existing
   countermeasures suffer from many limitations. Most solutions degrade
   performance in the absence of adversarial perturbations; they are unable
   to face novel attack variants; they are applicable only to specific
   machine learning algorithms. We propose the first framework that can
   protect botnet detectors from adversarial attacks through deep
   reinforcement learning mechanisms. It automatically generates realistic
   attack samples that can evade detection, and it uses these samples to
   produce an augmented training set for producing hardened detectors. In
   such a way, we obtain more resilient detectors that can work even
   against unforeseen evasion attacks with the great merit of not
   penalizing their performance in the absence of specific attacks. We
   validate our proposal through an extensive experimental campaign that
   considers multiple machine learning algorithms and public datasets. The
   results highlight the improvements of the proposed solution over the
   state-of-the-art. Our method paves the way to novel and more robust
   cybersecurity detectors based on machine learning applied to network
   traffic analytics.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Apruzzese, G (Corresponding Author), Univ Liechtenstein, Hilti Chair Data \& Applicat Secur, FL-9490 Vaduz, Liechtenstein.
   Apruzzese, Giovanni, Univ Liechtenstein, Hilti Chair Data \& Applicat Secur, FL-9490 Vaduz, Liechtenstein.
   Andreolini, Mauro, Univ Modena \& Reggio Emilia, Dept Phys Comp Sci \& Math, I-41121 Modena, Italy.
   Marchetti, Mirco; Venturi, Andrea, Univ Modena \& Reggio Emilia, Dept Engn Enzo Ferrari, I-41121 Modena, Italy.
   Colajanni, Michele, Univ Bologna, Dept Informat Sci \& Engn, I-40126 Bologna, Italy.}},
DOI = {{10.1109/TNSM.2020.3031843}},
ISSN = {{1932-4537}},
Keywords = {{Detectors; Botnet; Training; Computer security; Machine learning;
   Feature extraction; Perturbation methods; Adversarial attack; machine
   learning; network intrusion detection; deep reinforcement learning;
   botnet}},
Keywords-Plus = {{INTRUSION; GENERATION}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems}},
Author-Email = {{giovanni.apruzzese@unimore.it
   mauro.andreolini@unimore.it
   mirco.marchetti@unimore.it
   andrea.venturi@unimore.it
   michele.colajanni@unimore.it}},
ResearcherID-Numbers = {{Venturi, Andrea/AAE-4145-2021
   Apruzzese, Giovanni/AAQ-2764-2020
   Marchetti, Mirco/K-6057-2015
   }},
ORCID-Numbers = {{Venturi, Andrea/0000-0003-3822-968X
   Apruzzese, Giovanni/0000-0002-6890-9611
   Marchetti, Mirco/0000-0002-7408-6906
   Colajanni, Michele/0000-0002-9499-1559}},
Number-of-Cited-References = {{73}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{7}},
Usage-Count-Since-2013 = {{12}},
Journal-ISO = {{IEEE Trans. Netw. Serv. Manag.}},
Doc-Delivery-Number = {{PC8ED}},
Unique-ID = {{WOS:000597226700002}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000473544500005,
Author = {Yang, Fan and Chen, Zhiyuan and Gangopadhyay, Aryya},
Book-Group-Author = {{ACM}},
Title = {{Using Randomness to Improve Robustness of Tree-based Models Against
   Evasion Attacks}},
Booktitle = {{PROCEEDINGS OF THE ACM INTERNATIONAL WORKSHOP ON SECURITY AND PRIVACY
   ANALYTICS (IWSPA `19)}},
Year = {{2019}},
Pages = {{25-35}},
Note = {{5th ACM International Workshop on Security and Privacy Analytics
   (IWSPA), Richardson, TX, MAR 27, 2019}},
Organization = {{Assoc Comp Machinery; ACM SIGSAC}},
Abstract = {{Machine learning models have been widely used in security applications.
   However, it is well-known that adversaries can adapt their attacks to
   evade detection. There has been some work on making machine learning
   models more robust to such attacks. However, one simple but promising
   approach called randomization is underexplored. In addition, most
   existing works focus on models with differentiable error functions while
   tree-based models do not have such error functions but are quite popular
   because they are easy to interpret. This paper proposes a novel
   randomization-based approach to improve robustness of tree-based models
   against evasion attacks. The proposed approach incorporates
   randomization into both model training time and model application time
   (meaning when the model is used to detect attacks). We also apply this
   approach to random forest, an existing ML method which already has
   incorporated randomness at training time but still often fails to
   generate robust models. We proposed a novel weighted-random-forest
   method to generate more robust models and a clustering method to add
   randomness at model application time. Experiments on intrusion detection
   and spam filtering data show that our approach further improves
   robustness of random-forest method.}},
Publisher = {{ASSOC COMPUTING MACHINERY}},
Address = {{1515 BROADWAY, NEW YORK, NY 10036-9998 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Yang, F (Corresponding Author), Univ Maryland Baltimore Cty, Baltimore, MD 21228 USA.
   Yang, Fan; Chen, Zhiyuan; Gangopadhyay, Aryya, Univ Maryland Baltimore Cty, Baltimore, MD 21228 USA.}},
DOI = {{10.1145/3309182.3309186}},
ISBN = {{978-1-4503-6178-1}},
Keywords = {{Evasion attacks; Machine Learning; Adversarial Learning; Intrusion
   Detection; Spam Filtering}},
Keywords-Plus = {{ADVERSARIAL; CLASSIFIERS}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods}},
Author-Email = {{fyang1@umbc.edu
   zhchen@umbc.edu
   gangopad@umbc.edu}},
Number-of-Cited-References = {{50}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BN0TY}},
Unique-ID = {{WOS:000473544500005}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000582697300040,
Author = {Xia, Song and Qiu, Meikang and Jiang, Hao},
Book-Group-Author = {{IEEE}},
Title = {{An adversarial reinforcement learning based system for cyber security}},
Booktitle = {{4TH IEEE INTERNATIONAL CONFERENCE ON SMART CLOUD (SMARTCLOUD 2019) / 3RD
   INTERNATIONAL SYMPOSIUM ON REINFORCEMENT LEARNING (ISRL 2019)}},
Year = {{2019}},
Pages = {{227-230}},
Note = {{4th IEEE International Conference on Smart Cloud (IEEE SmartCloud) / 3rd
   IEEE International Symposium on Reinforcement Learning (IEEE ISRL),
   Waseda Univ, Tokyo, JAPAN, DEC 10-12, 2019}},
Organization = {{IEEE; IEEE SmartCloud ISRL Comm; IEEE Comp Soc; IEEE TCSC; IEEE STC
   Smart Comp; Columbia Univ; N Amer Chinese Talents Assoc; Longxiang High
   Tech}},
Abstract = {{In this paper, we proposed a reinforcement learning based system for
   defending the network users from malicious network traffics. By training
   two reinforcement learning agents: network attack generation agent and
   network defense agent, and based on the environment of deep neural
   networks, this system not only aims to outperforme the traditional
   machine learning algorithm (such as CNNs and LSTM), but also can to
   detect the adversarial example, which is the one of the biggest
   challenges for current machine learning based intrusion detection
   system.}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Xia, S (Corresponding Author), Wuhan Univ, Coll Elect \& Informat, Wuhan, Hubei, Peoples R China.
   Xia, Song; Jiang, Hao, Wuhan Univ, Coll Elect \& Informat, Wuhan, Hubei, Peoples R China.
   Qiu, Meikang, Texas A\&M Univ Commerce, Dept Comp Sci, Commerce, TX USA.}},
DOI = {{10.1109/SmartCloud.2019.00046}},
ISBN = {{978-1-7281-5505-0}},
Keywords = {{adversarial reinforcement learning; adversarial samples; intrusion
   detection system; deep neural network}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory \& Methods}},
Author-Email = {{songxia@whu.edu.cn
   meikang.qiu@tamuc.cdu
   jh@whu.edu.cn}},
Funding-Acknowledgement = {{Advanced network and Intelligent Information Service Institute of Wuhan
   University, Zhongshan City {[}2017F1FC0001]; Intelligent frontend
   recognition technology based on deep learning and its application in
   industry {[}2019AG012]}},
Funding-Text = {{This work is supported by the Advanced network and Intelligent
   Information Service Institute of Wuhan University, Zhongshan City
   (No.2017F1FC0001) and the Intelligent frontend recognition technology
   based on deep learning and its application in industry (No.2019AG012).}},
Number-of-Cited-References = {{13}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{6}},
Usage-Count-Since-2013 = {{11}},
Doc-Delivery-Number = {{BQ2XO}},
Unique-ID = {{WOS:000582697300040}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000672800000071,
Author = {Perales Gomez, Angel Luis and Fernandez Maimo, Lorenzo and Celdran,
   Alberto Huertas and Garcia Clemente, Felix J. and Cleary, Frances},
Editor = {{Shakshuki, E and Yasar, A}},
Title = {{Crafting Adversarial Samples for Anomaly Detectors in Industrial Control
   Systems}},
Booktitle = {{12TH INTERNATIONAL CONFERENCE ON AMBIENT SYSTEMS, NETWORKS AND
   TECHNOLOGIES (ANT) / THE 4TH INTERNATIONAL CONFERENCE ON EMERGING DATA
   AND INDUSTRY 4.0 (EDI40) / AFFILIATED WORKSHOPS}},
Series = {{Procedia Computer Science}},
Year = {{2021}},
Volume = {{184}},
Pages = {{573-580}},
Note = {{12th International Conference on Ambient Systems, Networks and
   Technologies (ANT) / 4th International Conference on Emerging Data and
   Industry 4.0 (EDI40), Warsaw, POLAND, MAR 23-26, 2021}},
Abstract = {{The increasing adoption of the Industry 4.0 paradigm encompasses
   digitally interconnected factories which enables many advantages.
   However, it is still necessary to dedicate effort towards investigating
   protection mechanisms against cyberattacks in these scenarios. Despite
   the power demonstrated by Anomaly Detection-based Intrusion Detection
   Systems in industrial scenarios, their vulnerabilities to adversarial
   attacks, especially to evasion attacks, make Machine Learning and Deep
   Learning models ineffective for real scenarios. These type of attacks
   craft samples misclassified by the Intrusion Detection System and
   potentially reach industrial devices, causing potentially damaging
   impacts to factory workers and industry resources. Adversarial attacks
   linked to industrial scenarios are currently in early stages of
   development, hence most of them have the capability to craft samples
   misclassified by the IDS but not reach industrial devices. In this work,
   we present a new adversarial attack named Selective and Iterative
   Gradient Sign Method that overcomes the limitation of the adversarial
   attacks present in the literature. To complement this work we also
   detail a study of how the detection rate of an Intrusion Detection
   System is degraded and the time required by each technique to generate
   adversarial samples. The experiments were carried out using a dataset
   named Electra, collected from an Electric Traction Substation, and
   showed that adversarial attacks evaluated crafted samples misclassified
   by the IDS. However, only the method we proposed generated samples that
   can be understood by intermediate network devices and, therefore, reach
   their destination. Our experiment outputs demonstrate a lower period of
   time to achieve and craft adversarial samples using out our iterative
   based process method as opposed to other current iterative methods
   currently available. (C) 2021 The Authors. Published by Elsevier B.V.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Gomez, ALP (Corresponding Author), Univ Murcia, Dept Ingn \& Tecnol Comp, Murcia 30100, Spain.
   Perales Gomez, Angel Luis; Fernandez Maimo, Lorenzo; Garcia Clemente, Felix J., Univ Murcia, Dept Ingn \& Tecnol Comp, Murcia 30100, Spain.
   Celdran, Alberto Huertas, Univ Zurich UZH, Dept Informat IfI, Commun Syst Grp CSG, CH-8050 Zurich, Switzerland.
   Celdran, Alberto Huertas; Cleary, Frances, Waterford Inst Technol, Telecommun Software \& Syst Grp, Waterford X91 P20H, Ireland.}},
DOI = {{10.1016/j.procs.2021.03.072}},
ISSN = {{1877-0509}},
Keywords = {{anomaly detection; adversarial attacks; deep learning; industrial
   control systems}},
Research-Areas = {{Computer Science; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods; Telecommunications}},
Author-Email = {{angelluis.perales@um.es}},
Funding-Acknowledgement = {{Spanish Ministry of Science, Innovation and Universities, State Research
   Agency, FEDER funds {[}RTI2018-095855-B-I00]; Swiss Federal Office for
   Defence Procurement {[}CYD-C-2020003]; Government of Ireland, through
   the IRC post-doc fellowship {[}GOIPD/2018/466]}},
Funding-Text = {{This work has been funded by Spanish Ministry of Science, Innovation and
   Universities, State Research Agency, FEDER funds, under Grant
   RTI2018-095855-B-I00, the Swiss Federal Office for Defence Procurement
   (armasuisse) (project code and CYD-C-2020003) and the Government of
   Ireland, through the IRC post-doc fellowship (grant code
   GOIPD/2018/466).}},
Number-of-Cited-References = {{18}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BR8RS}},
Unique-ID = {{WOS:000672800000071}},
OA = {{gold}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000556140800019,
Author = {Abusnaina, Ahmed and Nyang, DaeHun and Yuksel, Murat and Mohaisen, Aziz},
Book-Group-Author = {{Assoc Comp Machinery}},
Title = {{Examining the Security of DDoS Detection Systems in Software Defined
   Networks}},
Booktitle = {{CONEXT'19 COMPANION: PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON
   EMERGING NETWORKING EXPERIMENTS AND TECHNOLOGIES}},
Year = {{2019}},
Pages = {{49-50}},
Note = {{15th ACM International Conference on Emerging Networking EXperiments and
   Technologies (CoNEXT), Orlando, LA, DEC 09-12, 2019}},
Organization = {{Assoc Comp Machinery; ACM SIGCOMM}},
Abstract = {{With the rapid development of Software-Defined Networking (SDN)
   advocating a centralized view of networks, efficient and reliable
   Distributed Denial of Service (DDoS) defenses are necessary to protect
   the centralized SDN controller. In this work, we explore the robustness
   of DL-based DDoS defenses in SDN against adversarial learning attacks.
   First, we investigate generic off-the-shelf adversarial attacks to test
   the robustness of DDoS defenses in SDN. Then, we propose Flow-Merge for
   realistic adversarial flows while achieving a high evasion rate. The
   evaluation shows that the proposed Flow-Merge is able to force the
   DL-based DDoS defenses to misclassify 100\% of benign flows as
   malicious.}},
Publisher = {{ASSOC COMPUTING MACHINERY}},
Address = {{1515 BROADWAY, NEW YORK, NY 10036-9998 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Abusnaina, A (Corresponding Author), Univ Cent Florida, Orlando, FL 32816 USA.
   Abusnaina, Ahmed; Yuksel, Murat; Mohaisen, Aziz, Univ Cent Florida, Orlando, FL 32816 USA.
   Nyang, DaeHun, Inha Univ, Incheon, South Korea.}},
DOI = {{10.1145/3360468.3368174}},
ISBN = {{978-1-4503-7006-6}},
Keywords = {{Distributed Denial of Service; Intrusion Detection; Deep Learning;
   Adversarial Attacks}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods}},
Author-Email = {{ahmed.abusnaina@knights.ucf.edu
   nyang@inha.ac.kr
   Murat.Yuksel@ucf.edu
   mohaisen@ucf.edu}},
ResearcherID-Numbers = {{Mohaisen, Aziz/ABD-6425-2021}},
Funding-Acknowledgement = {{NVIDIA GPU Grant {[}NRF-2016K1A1A2912757]; NSFNational Science
   Foundation (NSF) {[}1647189, 1814086, 1643207]}},
Funding-Text = {{This work is supported in part by NVIDIA GPU Grant,
   NRF-2016K1A1A2912757, and NSF awards 1647189, 1814086, and 1643207.}},
Number-of-Cited-References = {{7}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BP5LB}},
Unique-ID = {{WOS:000556140800019}},
OA = {{Bronze}},
DA = {{2021-11-23}},
}

@article{ WOS:000552755500009,
Author = {Yin, Chuanlong and Zhu, Yuefei and Liu, Shengli and Fei, Jinlong and
   Zhang, Hetong},
Title = {{Enhancing network intrusion detection classifiers using supervised
   adversarial training}},
Journal = {{JOURNAL OF SUPERCOMPUTING}},
Year = {{2020}},
Volume = {{76}},
Number = {{9}},
Pages = {{6690-6719}},
Month = {{SEP}},
Abstract = {{The performance of classifiers has a direct impact on the effectiveness
   of intrusion detection system. Thus, most researchers aim to improve the
   detection performance of classifiers. However, classifiers can only get
   limited useful information from the limited number of labeled training
   samples, which usually affects the generalization of classifiers. In
   order to enhance the network intrusion detection classifiers, we resort
   to adversarial training, and a novel supervised learning framework using
   generative adversarial network for improving the performance of the
   classifier is proposed in this paper. The generative model in our
   framework is utilized to continuously generate other complementary
   labeled samples for adversarial training and assist the classifier for
   classification, while the classifier in our framework is used to
   identify different categories. Meanwhile, the loss function is deduced
   again, and several empirical training strategies are proposed to improve
   the stabilization of the supervised learning framework. Experimental
   results prove that the classifier via adversarial training improves the
   performance indicators of intrusion detection. The proposed framework
   provides a feasible method to enhance the performance and generalization
   of the classifier.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Yin, CL (Corresponding Author), State Key Lab Math Engn \& Adv Comp, Zhengzhou 450001, Peoples R China.
   Yin, Chuanlong; Zhu, Yuefei; Liu, Shengli; Fei, Jinlong; Zhang, Hetong, State Key Lab Math Engn \& Adv Comp, Zhengzhou 450001, Peoples R China.}},
DOI = {{10.1007/s11227-019-03092-1}},
ISSN = {{0920-8542}},
EISSN = {{1573-0484}},
Keywords = {{Intrusion detection; Generative adversarial networks; Artificial neural
   network; Adversarial training; Machine learning}},
Keywords-Plus = {{DETECTION SYSTEM; MODEL}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Hardware \& Architecture; Computer Science, Theory \&
   Methods; Engineering, Electrical \& Electronic}},
Author-Email = {{dragonyincl@163.com
   zyf0136@sina.com
   475737@qq.com
   feijinlong@126.com
   hetongzhang@live.cn}},
ResearcherID-Numbers = {{Yin, Chuanlong/AAK-1543-2021}},
ORCID-Numbers = {{Yin, Chuanlong/0000-0003-0735-9019}},
Number-of-Cited-References = {{45}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{11}},
Journal-ISO = {{J. Supercomput.}},
Doc-Delivery-Number = {{MQ2VO}},
Unique-ID = {{WOS:000552755500009}},
DA = {{2021-11-23}},
}

@article{ WOS:000701874800010,
Author = {Alhajjar, Elie and Maxwell, Paul and Bastian, Nathaniel},
Title = {{Adversarial machine learning in Network Intrusion Detection Systems}},
Journal = {{EXPERT SYSTEMS WITH APPLICATIONS}},
Year = {{2021}},
Volume = {{186}},
Month = {{DEC 30}},
Abstract = {{Adversarial examples are inputs to a machine learning system
   intentionally crafted by an attacker to fool the model into producing an
   incorrect output. These examples have achieved a great deal of success
   in several domains such as image recognition, speech recognition and
   spam detection. In this paper, we study the nature of the adversarial
   problem in Network Intrusion Detection Systems (NIDS). We focus on the
   attack perspective, which includes techniques to generate adversarial
   examples capable of evading a variety of machine learning models. More
   specifically, we explore the use of evolutionary computation (particle
   swarm optimization and genetic algorithm) and deep learning (generative
   adversarial networks) as tools for adversarial example generation. To
   assess the performance of these algorithms in evading a NIDS, we apply
   them to two publicly available data sets, namely the NSL-KDD and
   UNSW-NB15, and we contrast them to a baseline perturbation method: Monte
   Carlo simulation. The results show that our adversarial example
   generation techniques cause high misclassification rates in eleven
   different machine learning models, along with a voting classifier. Our
   work highlights the vulnerability of machine learning based NIDS in the
   face of adversarial perturbation.}},
Publisher = {{PERGAMON-ELSEVIER SCIENCE LTD}},
Address = {{THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Alhajjar, E (Corresponding Author), US Mil Acad, Army Cyber Inst, West Point, NY 10996 USA.
   Alhajjar, Elie; Maxwell, Paul; Bastian, Nathaniel, US Mil Acad, Army Cyber Inst, West Point, NY 10996 USA.}},
DOI = {{10.1016/j.eswa.2021.115782}},
Article-Number = {{115782}},
ISSN = {{0957-4174}},
EISSN = {{1873-6793}},
Keywords = {{Network Intrusion Detection Systems; Adversarial machine learning;
   Evolutionary computation; Deep learning; Monte Carlo simulation}},
Keywords-Plus = {{BUSINESS; SECURITY}},
Research-Areas = {{Computer Science; Engineering; Operations Research \& Management Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic; Operations Research \& Management Science}},
Author-Email = {{elie.alhajjar@westpoint.edu
   paul.maxwell@westpoint.edu
   nathaniel.bastian@westpoint.edu}},
ORCID-Numbers = {{Maxwell, Paul/0000-0001-9055-9534
   Alhajjar, Elie/0000-0002-7500-1214
   Bastian, Nathaniel/0000-0001-9957-2778}},
Funding-Acknowledgement = {{U.S. Army Combat Capabilities Development Command (DEVCOM) Army Research
   Laboratory (ARL) Faculty and Cadet Collaborative Research Program
   through the Mathematical Sciences Center, Department of Mathematical
   Sciences, U.S. Military Academy, West Point, NY; National Security
   Agency Laboratory for Advanced Cybersecurity Research {[}USMA21035];
   U.S. Army DEVCOM C5ISR Center {[}USMA21056]; U.S. Army DEVCOM ARL
   {[}USMA21050]}},
Funding-Text = {{This work was partially funded by the U.S. Army Combat Capabilities
   Development Command (DEVCOM) Army Research Laboratory (ARL) Faculty and
   Cadet Collaborative Research Program through the Mathematical Sciences
   Center, Department of Mathematical Sciences, U.S. Military Academy, West
   Point, NY. This work was also supported in part by the National Security
   Agency Laboratory for Advanced Cybersecurity Research under Interagency
   Agreement No. USMA21035, the U.S. Army DEVCOM C5ISR Center under
   Interagency Agreement No. USMA21056, and the U.S. Army DEVCOM ARL under
   Interagency Agreement No. USMA21050. The authors would like to thank the
   U.S. Army Engineer Research and Development Center for use of their
   compute resources in the course of this work.}},
Number-of-Cited-References = {{55}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{14}},
Usage-Count-Since-2013 = {{14}},
Journal-ISO = {{Expert Syst. Appl.}},
Doc-Delivery-Number = {{UZ0AD}},
Unique-ID = {{WOS:000701874800010}},
OA = {{Green Submitted}},
DA = {{2021-11-23}},
}

@article{ WOS:000682801700003,
Author = {Apruzzese, Giovanni and Andreolini, Mauro and Colajanni, Michele and
   Marchetti, Mirco},
Title = {{Hardening Random Forest Cyber Detectors Against Adversarial Attacks}},
Journal = {{IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTATIONAL INTELLIGENCE}},
Year = {{2020}},
Volume = {{4}},
Number = {{4}},
Pages = {{427-439}},
Month = {{AUG}},
Abstract = {{Machine learning algorithms are effective in several applications, but
   they are not as much successful when applied to intrusion detection in
   cyber security. Due to the high sensitivity to their training data,
   cyber detectors based on machine learning are vulnerable to targeted
   adversarial attacks that involve the perturbation of initial samples.
   Existing defenses assume unrealistic scenarios; their results are
   underwhelming in non-adversarial settings; or they can be applied only
   to machine learning algorithms that perform poorly for cyber security.
   We present an original methodology for countering adversarial
   perturbations targeting intrusion detection systems based on random
   forests. As a practical application, we integrate the proposed defense
   method in a cyber detector analyzing network traffic. The experimental
   results on millions of labelled network flows show that the new detector
   has a twofold value: it outperforms state-of-the-art detectors that are
   subject to adversarial attacks; it exhibits robust results both in
   adversarial and non-adversarial scenarios.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Apruzzese, G (Corresponding Author), Univ Modena \& Reggio Emilia, Dept Engn Enzo Ferrari, I-41121 Modena, Italy.
   Apruzzese, Giovanni; Andreolini, Mauro; Colajanni, Michele; Marchetti, Mirco, Univ Modena \& Reggio Emilia, Dept Engn Enzo Ferrari, I-41121 Modena, Italy.}},
DOI = {{10.1109/TETCI.2019.2961157}},
ISSN = {{2471-285X}},
Keywords = {{Adversarial samples; machine learning; random forest; intrusion
   detection; flow inspection; botnet}},
Keywords-Plus = {{BOTNET DETECTION; SECURITY}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{giovanni.apruzzese@unimore.it
   mauro.andreolini@unimore.it
   michele.colajanni@unimore.it
   mirco.marchetti@unimore.it}},
ResearcherID-Numbers = {{Marchetti, Mirco/K-6057-2015}},
ORCID-Numbers = {{Colajanni, Michele/0000-0002-9499-1559
   Marchetti, Mirco/0000-0002-7408-6906}},
Number-of-Cited-References = {{52}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{5}},
Usage-Count-Since-2013 = {{6}},
Journal-ISO = {{IEEE Trans. Emerg. Top. Comput. Intell.}},
Doc-Delivery-Number = {{TX0SN}},
Unique-ID = {{WOS:000682801700003}},
OA = {{Green Submitted}},
DA = {{2021-11-23}},
}

@article{ WOS:000617525400021,
Author = {Venturi, Andrea and Apruzzese, Giovanni and Andreolini, Mauro and
   Colajanni, Michele and Marchetti, Mirco},
Title = {{DReLAB - Deep REinforcement Learning Adversarial Botnet: A benchmark
   dataset for adversarial attacks against botnet Intrusion Detection
   Systems}},
Journal = {{DATA IN BRIEF}},
Year = {{2021}},
Volume = {{34}},
Month = {{FEB}},
Abstract = {{We present the first dataset that aims to serve as a benchmark to
   validate the resilience of botnet detectors against adversarial attacks.
   This dataset includes realistic adversarial samples that are generated
   by leveraging two widely used Deep Reinforcement Learning (DRL)
   techniques. These adversarial samples are proved to evade state of the
   art detectors based on Machine- and Deep-Learning algorithms. The
   initial corpus of malicious samples consists of network flows belonging
   to different botnet families presented in three public datasets
   containing real enterprise network traffic. We use these datasets to
   devise detectors capable of achieving state-of-the-art performance. We
   then train two DRL agents, based on Double Deep Q-Network and Deep
   Sarsa, to generate realistic adversarial samples: the goal is achieving
   misclassifications by performing small modifications to the initial
   malicious samples. These alterations involve the features that can be
   more realistically altered by an expert attacker, and do not compromise
   the underlying malicious logic of the original samples. Our dataset
   represents an important contribution to the cybersecurity research
   community as it is the first including thousands of automatically
   generated adversarial samples that are able to thwart state of the art
   classifiers with a high evasion rate. The adversarial samples are
   grouped by malware variant and provided in a CSV file format.
   Researchers can validate their defensive proposals by testing their
   detectors against the adversarial samples of the proposed dataset.
   Moreover, the analysis of these samples can pave the way to a deeper
   comprehension of adversarial attacks and to some sort of explainability
   of machine learning defensive algorithms. They can also support the
   definition of novel effective defensive techniques. (C) 2020 The
   Authors. Published by Elsevier Inc.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article; Data Paper}},
Language = {{English}},
Affiliation = {{Venturi, A (Corresponding Author), Univ Modena \& Reggio Emilia, Dept Engn Enzo Ferrari, Modena, Italy.
   Venturi, Andrea; Marchetti, Mirco, Univ Modena \& Reggio Emilia, Dept Engn Enzo Ferrari, Modena, Italy.
   Apruzzese, Giovanni, Univ Liechtenstein, Hilti Chair Data \& Applicat Secur, Vaduz, Liechtenstein.
   Andreolini, Mauro, Univ Modena \& Reggio Emilia, Dept Phys Comp Sci \& Math, Modena, Italy.
   Colajanni, Michele, Univ Bologna, Dept Informat Sci \& Engn, Bologna, Italy.}},
DOI = {{10.1016/j.dib.2020.106631}},
Article-Number = {{106631}},
ISSN = {{2352-3409}},
Keywords = {{Cyber security; Adversarial attacks; Deep reinforcement learning;
   Intrusion detection system; Botnet}},
Research-Areas = {{Science \& Technology - Other Topics}},
Web-of-Science-Categories  = {{Multidisciplinary Sciences}},
Author-Email = {{andrea.venturi@unimore.it}},
ResearcherID-Numbers = {{Venturi, Andrea/AAE-4145-2021
   Apruzzese, Giovanni/AAQ-2764-2020
   Marchetti, Mirco/K-6057-2015}},
ORCID-Numbers = {{Venturi, Andrea/0000-0003-3822-968X
   Apruzzese, Giovanni/0000-0002-6890-9611
   Marchetti, Mirco/0000-0002-7408-6906}},
Funding-Acknowledgement = {{EU Horizon 2020 ASGARD project}},
Funding-Text = {{This research was funded by the EU Horizon 2020 ASGARD project.}},
Number-of-Cited-References = {{13}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{5}},
Usage-Count-Since-2013 = {{14}},
Journal-ISO = {{Data Brief}},
Doc-Delivery-Number = {{QG3YQ}},
Unique-ID = {{WOS:000617525400021}},
OA = {{Green Published, gold}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000427969500130,
Author = {Li, Shu and Li, Yun},
Editor = {{Li, T and Lopez, LM and Li, Y}},
Title = {{Complex-based optimization strategy for evasion attack}},
Booktitle = {{2017 12TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND KNOWLEDGE
   ENGINEERING (IEEE ISKE)}},
Year = {{2017}},
Note = {{12th International Conference on Intelligent Systems and Knowledge
   Engineering (IEEE ISKE), NanJing, PEOPLES R CHINA, NOV 24-26, 2017}},
Organization = {{IEEE; IEEE Syst; IEEE Comp Soc}},
Abstract = {{Machine learning has been widely used in security related applications,
   such as spam filter, network intrusion detection. In machine learning
   process, the test set and the training set usually have the same
   probability distribution and through the information of learning the
   training set, the malicious samples in the machine learning algorithm
   can usually be correctly classified. However, the classification
   algorithm has neglected the classification under adversarial
   environment, so instead they will modify the features of test data in
   order to spoof the classifier so as to escape its detection.
   In this paper, we will consider to modify the feature value of the test
   samples in accordance with attack algorithm proposed by Battista Biggio
   and further improve the algorithm. As each feature has a range of
   independent constraints, so the algorithm should be transformed into a
   constrained optimization problem. This is done in order to make the
   original sample modify the smaller distance so as to escape the
   detection of the classifier, while also improve the convergence rate
   during the generation of adversarial samples.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Li, S (Corresponding Author), Nanjing Univ Posts \& Telecommun, Sch Comp Sci, Nanjing, Jiangsu, Peoples R China.
   Li, Shu; Li, Yun, Nanjing Univ Posts \& Telecommun, Sch Comp Sci, Nanjing, Jiangsu, Peoples R China.}},
ISBN = {{978-1-5386-1829-5}},
Keywords = {{component; adversarial machine learning; evasion attacks; constrained
   optimization}},
Keywords-Plus = {{CONSTRAINED OPTIMIZATION; MINIMIZATION}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic}},
Author-Email = {{1215042921@njupt.edu.cn
   liyun@njupt.edu.cn}},
Funding-Acknowledgement = {{National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}NSFC 61603197]; Natural Science Foundation
   of Jiangsu ProvinceNatural Science Foundation of Jiangsu Province
   {[}BK20140885]; NUPTSF {[}NY214127]}},
Funding-Text = {{This research was partially supported by National Natural Science
   Foundation of China (NSFC 61603197), Natural Science Foundation of
   Jiangsu Province(BK20140885), NUPTSF (NY214127)}},
Number-of-Cited-References = {{14}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BJ8CJ}},
Unique-ID = {{WOS:000427969500130}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000459819200093,
Author = {Yang, Kaichen and Liu, Jianqing and Zhang, Chi and Fang, Yuguang},
Book-Group-Author = {{IEEE}},
Title = {{Adversarial Examples Against the Deep Learning Based Network Intrusion
   Detection Systems}},
Booktitle = {{2018 IEEE MILITARY COMMUNICATIONS CONFERENCE (MILCOM 2018)}},
Series = {{IEEE Military Communications Conference}},
Year = {{2018}},
Pages = {{559-564}},
Note = {{IEEE Military Communications Conference (MILCOM), Los Angeles, CA, OCT
   29-31, 2018}},
Organization = {{IEEE; AFCEA; IEEE Commun Soc}},
Abstract = {{Deep learning begins to be widely applied in security applications, but
   the vulnerability of deep learning in front of adversarial examples
   raises people's concern. In this paper, we study the practicality of
   adversarial example in the domain of network intrusion detection systems
   (NIDS). Specifically, we investigate how adversarial examples affect the
   performance of deep neural network (DNN) trained to detect abnormal
   behaviors in the black-box model. We demonstrate that adversary can
   generate effective adversarial examples against DNN classifier trained
   for NIDS even when the internal information of the target model is
   isolated from the adversary. In our experiment we first train a DNN
   model for NIDS system using NSL-KDD database and achieve a performance
   matching the state-of-art literature, then we show how can an adversary
   generate adversary examples to mislead the model without knowing the
   internal information.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Yang, KC (Corresponding Author), Univ Florida, Dept Elect \& Comp Engn, Gainesville, FL 32611 USA.
   Yang, Kaichen; Liu, Jianqing; Fang, Yuguang, Univ Florida, Dept Elect \& Comp Engn, Gainesville, FL 32611 USA.
   Zhang, Chi, Univ Sci \& Technol China, Key Lab Electromagnet Space Informat, Hefei, Anhui, Peoples R China.}},
ISSN = {{2155-7578}},
ISBN = {{978-1-5386-7185-6}},
Keywords = {{deep learning; intrusion detection; security}},
Research-Areas = {{Telecommunications}},
Web-of-Science-Categories  = {{Telecommunications}},
Author-Email = {{ykcdxt@ufl.edu
   jianqingliu@ufl.edu
   chizhang@ustc.edu.cn
   fang@ece.ufl.edu}},
ResearcherID-Numbers = {{Fang, Yuguang/A-7484-2009
   }},
ORCID-Numbers = {{Fang, Yuguang/0000-0002-1079-3871
   Liu, Jianqing/0000-0001-7568-015X}},
Funding-Acknowledgement = {{US National Science FoundationNational Science Foundation (NSF)
   {[}IIS-1722791]; National Key Research and Development Program of China
   {[}2017YFB0802202]; Natural Science Foundation of ChinaNational Natural
   Science Foundation of China (NSFC) {[}61702474, 61871362]}},
Funding-Text = {{This work was partiall supported by the US National Science Foundation
   under grant IIS-1722791. The work of C. Zhang was supported by the
   National Key Research and Development Program of China under Grant
   2017YFB0802202, and by the Natural Science Foundation of China under
   Grants 61702474 and 61871362.}},
Number-of-Cited-References = {{28}},
Times-Cited = {{14}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{5}},
Doc-Delivery-Number = {{BM1HT}},
Unique-ID = {{WOS:000459819200093}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000701532600042,
Author = {Wang, Jianyu and Pan, Jianli and AlQerm, Ismail and Liu, Yuanni},
Book-Group-Author = {{IEEE}},
Title = {{Def-IDS: An Ensemble Defense Mechanism Against Adversarial Attacks for
   Deep Learning-based Network Intrusion Detection}},
Booktitle = {{30TH INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATIONS AND NETWORKS
   (ICCCN 2021)}},
Series = {{IEEE International Conference on Computer Communications and Networks}},
Year = {{2021}},
Note = {{30th International Conference on Computer Communications and Networks
   (ICCCN), ELECTR NETWORK, JUL 19-22, 2021}},
Organization = {{IEEE; IEEE Commun Soc}},
Abstract = {{Network intrusion detection plays an important role in the Internet of
   Things systems for protecting devices from security breaches. Facing
   challenges of the rapidly increasing amount of diverse network traffic,
   recent research has employed end-to-end deep learning-based intrusion
   detectors for automatic feature extraction and high detection accuracy.
   However, deep learning has been proved vulnerable to adversarial attacks
   that may cause misclassification by imposing imperceptible perturbation
   on input samples. Though such vulnerability is widely discussed in the
   image processing domain, very few studies have investigated its
   perniciousness against network intrusion detection systems (NIDS) and
   proposed corresponding defense strategies. In this paper, we try to fill
   this gap by proposing Def-IDS, an ensemble defense mechanism specially
   designed for NIDS, against both known and unknown adversarial attacks.
   It is a two-module training framework that integrates multi-class
   generative adversarial networks and multi-source adversarial retraining
   to improve model robustness, while the detection accuracy on unperturbed
   samples is maintained. We evaluate the mechanism over CSE-CIC-IDS2018
   dataset and compare its performance with the other three defense
   methods. The results demonstrate that Def-IDS is able to detect various
   adversarial attacks with better precision, recall, F1 score, and
   accuracy.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Wang, JY (Corresponding Author), Univ Missouri, Dept Comp Sci, St Louis, MO 63121 USA.
   Wang, Jianyu; Pan, Jianli; AlQerm, Ismail, Univ Missouri, Dept Comp Sci, St Louis, MO 63121 USA.
   Liu, Yuanni, Chongqing Univ Posts \& Telecommun, Inst Future Network Technol, Chongqing, Peoples R China.}},
DOI = {{10.1109/ICCCN52240.2021.9522215}},
ISSN = {{1095-2055}},
ISBN = {{978-0-7381-1330-2}},
Keywords = {{Network intrusion detection; adversarial attacks; deep learning}},
Keywords-Plus = {{THINGS}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Hardware \& Architecture}},
Author-Email = {{jwgxc@umsl.edu
   pan@umsl.edu
   alqermi@umsl.edu
   liuyn@cqupt.edu.cn}},
Funding-Acknowledgement = {{National Science Foundation (NSF) CNS core grantNational Science
   Foundation (NSF) {[}1909520]}},
Funding-Text = {{The work is supported in part by National Science Foundation (NSF) CNS
   core grant No. 1909520.}},
Number-of-Cited-References = {{25}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BS2HZ}},
Unique-ID = {{WOS:000701532600042}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000444872700020,
Author = {Kwon, Hyun and Yoon, Hyunsoo and Choi, Daeseon},
Editor = {{Kim, H and Kim, DC}},
Title = {{Friend-Safe Adversarial Examples in an Evasion Attack on a Deep Neural
   Network}},
Booktitle = {{INFORMATION SECURITY AND CRYPTOLOGY - ICISC 2017}},
Series = {{Lecture Notes in Computer Science}},
Year = {{2018}},
Volume = {{10779}},
Pages = {{351-367}},
Note = {{20th International Conference on Information Security and Cryptology
   (ICISC), Korea Inst Informat Secur \& Cryptol, Seoul, SOUTH KOREA, NOV
   29-DEC 01, 2017}},
Organization = {{Natl Secur Res Inst}},
Abstract = {{Deep neural networks (DNNs) perform effectively in machine learning
   tasks such as image recognition, intrusion detection, and pattern
   analysis. Recently proposed adversarial examples-slightly modified data
   that lead to incorrect classification-are a severe threat to the
   security of DNNs. However, in some situations, adversarial examples
   might be useful, i.e., for deceiving an enemy classifier on a
   battlefield. In that case, friendly classifiers should not be deceived.
   In this paper, we propose adversarial examples that are friend-safe,
   which means that friendly machines can classify the adversarial example
   correctly. To make such examples, the transformation is carried out to
   minimize the friend's wrong classification and the adversary's correct
   classification. We suggest two configurations of the scheme: targeted
   and untargeted class attacks. In experiments using the MNIST dataset,
   the proposed method shows a 100\% attack success rate and 100\% friendly
   accuracy with little distortion (2.18 and 1.53 for each configuration,
   respectively). Finally, we propose a mixed battlefield application and a
   new covert channel scheme.}},
Publisher = {{SPRINGER INTERNATIONAL PUBLISHING AG}},
Address = {{GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Choi, D (Corresponding Author), Kongju Natl Univ, Gongju Si, South Korea.
   Kwon, Hyun; Yoon, Hyunsoo, Korea Adv Inst Sci \& Technol, Daejeon, South Korea.
   Choi, Daeseon, Kongju Natl Univ, Gongju Si, South Korea.}},
DOI = {{10.1007/978-3-319-78556-1\_20}},
ISSN = {{0302-9743}},
EISSN = {{1611-3349}},
ISBN = {{978-3-319-78556-1; 978-3-319-78555-4}},
Keywords = {{Adversarial example; Covert channel; Deep neural network; Evasion attack}},
Keywords-Plus = {{SECURITY}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Theory \&
   Methods}},
Author-Email = {{khkh@kaist.ac.kr
   hyoon@kaist.ac.kr
   sunchoi@kongju.ac.kr}},
ResearcherID-Numbers = {{Kwon, Hyun/M-1140-2018}},
ORCID-Numbers = {{Kwon, Hyun/0000-0003-1169-9892}},
Funding-Acknowledgement = {{Institute for Information \& communications Technology Promotion (IITP)
   - Korea government (MSIT) {[}2017-0-00380, 2016-0-00173]}},
Funding-Text = {{This work was supported by Institute for Information \& communications
   Technology Promotion (IITP) grant funded by the Korea government (MSIT)
   (No. 2017-0-00380, Development of next generation user authentication
   and No. 2016-0-00173, Security Technologies for Financial Fraud
   Prevention on Fintech).}},
Number-of-Cited-References = {{27}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BK9QW}},
Unique-ID = {{WOS:000444872700020}},
DA = {{2021-11-23}},
}

@article{ WOS:000440542000001,
Author = {Wang, Zheng},
Title = {{Deep Learning-Based Intrusion Detection with Adversaries}},
Journal = {{IEEE ACCESS}},
Year = {{2018}},
Volume = {{6}},
Pages = {{38367-38384}},
Abstract = {{Deep neural networks have demonstrated their effectiveness in most
   machine learning tasks, with intrusion detection included.
   Unfortunately, recent research found that deep neural networks are
   vulnerable to adversarial examples in the image classification domain,
   i.e., they leave some opportunities for an attacker to fool the networks
   into misclassification by introducing imperceptible changes to the
   original pixels in an image. The vulnerability raises some concerns in
   applying deep neural networks in security-critical areas, such as
   intrusion detection. In this paper, we investigate the performances of
   the state-of-the-art attack algorithms against deep learning-based
   intrusion detection on the NSL-KDD data set. The vulnerabilities of
   neural networks employed by the intrusion detection systems are
   experimentally validated. The roles of individual features in generating
   adversarial examples are explored. Based on our findings, the
   feasibility and applicability of the attack methodologies are discussed.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Wang, Z (Corresponding Author), NIST, Informat Technol Lab, Gaithersburg, MD 20899 USA.
   Wang, Zheng, NIST, Informat Technol Lab, Gaithersburg, MD 20899 USA.}},
DOI = {{10.1109/ACCESS.2018.2854599}},
ISSN = {{2169-3536}},
Keywords = {{Intrusion detection; neural networks; classification algorithms; data
   security}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{zhengwang98@gmail.com}},
ResearcherID-Numbers = {{Wang, Zheng/AAC-8336-2021}},
Number-of-Cited-References = {{13}},
Times-Cited = {{59}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{17}},
Journal-ISO = {{IEEE Access}},
Doc-Delivery-Number = {{GP0ZL}},
Unique-ID = {{WOS:000440542000001}},
OA = {{gold}},
DA = {{2021-11-23}},
}

@article{ WOS:000551868700001,
Author = {Zhang, Sicong and Xie, Xiaoyao and Xu, Yang},
Title = {{A Brute-Force Black-Box Method to Attack Machine Learning-Based Systems
   in Cybersecurity}},
Journal = {{IEEE ACCESS}},
Year = {{2020}},
Volume = {{8}},
Pages = {{128250-128263}},
Abstract = {{Machine learning algorithms are widely utilized in cybersecurity.
   However, recent studies show that machine learning algorithms are
   vulnerable to adversarial examples. This poses new threats to the
   security-critical applications in cybersecurity. Currently, there is
   still a short of study on adversarial examples in the domain of
   cybersecurity. In this paper, we propose a new method known as the
   brute-force attack method to better evaluate the robustness of the
   machine learning classifiers in cybersecurity against adversarial
   examples. The proposed method, which works in a black-box way and covers
   some shortages of the existing adversarial attack methods based on
   generative adversarial networks, is simple to implement and only needs
   the output of the target classifiers to generate adversarial examples.
   To have a comprehensive evaluation of the attack performance of the
   proposed method, we use our method to generate adversarial examples
   against the common machine learning based security systems in
   cybersecurity including host intrusion detection systems, Android
   malware detection systems, and network intrusion detection systems. We
   compare the attack performance of the proposed method against these
   security systems with that of state-of-the-art adversarial attack
   methods based on generative adversarial networks. The preliminary
   experimental results show that the proposed method, which is more
   efficient in computation and outperforms the state-of-the-art attack
   methods based on generative adversarial networks, can be used to
   evaluate the robustness of various machine learning based systems in
   cybersecurity against adversarial examples.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Zhang, SC (Corresponding Author), Guizhou Univ, Sch Comp Sci \& Technol, Guiyang 550025, Peoples R China.
   Zhang, Sicong, Guizhou Univ, Sch Comp Sci \& Technol, Guiyang 550025, Peoples R China.
   Xie, Xiaoyao; Xu, Yang, Guizhou Normal Univ, Key Lab Informat \& Comp Sci Guizhou Prov, Guiyang 550001, Peoples R China.}},
DOI = {{10.1109/ACCESS.2020.3008433}},
ISSN = {{2169-3536}},
Keywords = {{Adversarial examples; machine learning; deep learning; intrusion
   detection; malware detection; neural networks; black-box method}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{351625648@qq.com}},
Funding-Acknowledgement = {{National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}U1831131]; Central Government Guides Local
   Science and Technology Development Special Funds {[}{[}2018]4008];
   Technology Cooperation Key Project of Guizhou Province, China
   {[}{[}2015]7763]; Science and Technology Planned Project of Guizhou
   Province, China {[}{[}2020]2Y013]}},
Funding-Text = {{This work was supported in part by the National Natural Science
   Foundation of China under Grant U1831131, in part by the Central
   Government Guides Local Science and Technology Development Special Funds
   under Grant {[}2018]4008, in part by the Technology Cooperation Key
   Project of Guizhou Province, China Grant {[}2015]7763, and in part by
   the Science and Technology Planned Project of Guizhou Province, China
   under Grant {[}2020]2Y013.}},
Number-of-Cited-References = {{37}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{6}},
Journal-ISO = {{IEEE Access}},
Doc-Delivery-Number = {{MO9XK}},
Unique-ID = {{WOS:000551868700001}},
OA = {{gold}},
DA = {{2021-11-23}},
}

@article{ WOS:000675207800018,
Author = {Farivar, Faezeh and Haghighi, Mohammad Sayad and Jolfaei, Alireza and
   Wen, Sheng},
Title = {{Covert Attacks Through Adversarial Learning: Study of Lane Keeping
   Attacks on the Safety of Autonomous Vehicles}},
Journal = {{IEEE-ASME TRANSACTIONS ON MECHATRONICS}},
Year = {{2021}},
Volume = {{26}},
Number = {{3}},
Pages = {{1350-1357}},
Month = {{JUN}},
Abstract = {{Road management systems are to improve in terms of integrity, mobility,
   sustainability, and safety by the adoption of artificial intelligence
   and Internet of Things services. This article introduces the concept of
   covert attacks on autonomous vehicles which can jeopardize the safety of
   passengers. Covert attacks are designed to manipulate outputs of cyber
   physical systems through network channels in a way that while the
   changes are not easily perceptible by human beings, systems are
   negatively affected in the long run. We argue that future smart vehicles
   are vulnerable to viruses which can use adversarial learning methods to
   adapt themselves to hosts and remain stealth for a long period. As a
   case study, we design a covert attack on the lane keeping system of
   autonomous vehicles. In the scenario, an intelligent adversary
   manipulates sensor readings (lane position, curvature, etc.) in order to
   deceive the controller to drive the vehicle closer to the boundaries.
   The virus/attacker interactively learns the host vehicle behaviors in
   terms of lateral deviation and maneuverability and tries to increase the
   errors to the extent that remains unnoticeable to the driver. This
   process is carried out through actor-critic learning based on the
   Newton--Raphson method. We additionally design an intrusion detection
   system for such covert attacks. We use the GPS data and offline maps to
   reconstruct road curves and match them against readings. A simulation
   testbed is developed based on the map of Nurburgring-Grand Prix track to
   evaluate our models. Results confirm the validity and effectiveness of
   the proposed models.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Haghighi, MS (Corresponding Author), Univ Tehran, Coll Engn, Sch Elect \& Comp Engn, Tehran 1439957131, Iran.
   Farivar, Faezeh, Islamic Azad Univ, Dept Comp \& Mechatron Engn, Sci \& Res Branch, Tehran 1477893855, Iran.
   Farivar, Faezeh, Inst Res Fundamental Sci IPM, Sch Comp Sci, Tehran 193955746, Iran.
   Haghighi, Mohammad Sayad, Univ Tehran, Coll Engn, Sch Elect \& Comp Engn, Tehran 1439957131, Iran.
   Jolfaei, Alireza, Macquarie Univ, Dept Comp, Sydney, NSW 2109, Australia.
   Wen, Sheng, Swinburne Univ Technol, Sch Software \& Elect Engn, Hawthorn, Vic 3122, Australia.}},
DOI = {{10.1109/TMECH.2021.3064816}},
ISSN = {{1083-4435}},
EISSN = {{1941-014X}},
Keywords = {{Autonomous vehicles; Roads; Automobiles; Security; Safety; Vehicles;
   Mechatronics; Adversarial machine learning; covert attack;
   cyber-physical systems (CPSs); fault diagnosis and prognosis;
   intelligent control; Internet of Things (IoT) in industry; lane keeping
   (LK); security; unmanned autonomous systems; vehicle safety}},
Keywords-Plus = {{AD HOC; SECURITY ISSUES; COMPENSATION; SYSTEM}},
Research-Areas = {{Automation \& Control Systems; Engineering}},
Web-of-Science-Categories  = {{Automation \& Control Systems; Engineering, Manufacturing; Engineering,
   Electrical \& Electronic; Engineering, Mechanical}},
Author-Email = {{f.farivar@srbiau.ac.ir
   sayad@ut.ac.ir
   alireza.jolfaei@mq.edu.au
   swen@swin.edu.au}},
ORCID-Numbers = {{Jolfaei, Alireza/0000-0001-7818-459X}},
Number-of-Cited-References = {{32}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{2}},
Journal-ISO = {{IEEE-ASME Trans. Mechatron.}},
Doc-Delivery-Number = {{TL9XM}},
Unique-ID = {{WOS:000675207800018}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000469020900045,
Author = {Apruzzese, Giovanni and Colajanni, Michele},
Book-Group-Author = {{IEEE}},
Title = {{Evading botnet detectors based on flows and Random Forest with
   adversarial samples}},
Booktitle = {{2018 IEEE 17TH INTERNATIONAL SYMPOSIUM ON NETWORK COMPUTING AND
   APPLICATIONS (NCA)}},
Year = {{2018}},
Note = {{17th IEEE International Symposium on Network Computing and Applications
   (NCA), Cambridge, MA, NOV 01-03, 2018}},
Organization = {{IEEE; IEEE Tech Comm Distributed Proc; Akamai Technologies Inc; Int Res
   Inst Auton Network Comp; IEEE Comp Soc}},
Abstract = {{Machine learning is increasingly adopted for a wide array of
   applications, due to its promising results and autonomous capabilities.
   However, recent research efforts have shown that, especially within the
   image processing field, these novel techniques are susceptible to
   adversarial perturbations. In this paper, we present an analysis that
   highlights and evaluates experimentally the fragility of network
   intrusion detection systems based on machine learning algorithms against
   adversarial attacks. In particular, our study involves a random forest
   classifier that utilizes network flows to distinguish between botnet and
   benign samples. Our results, derived from experiments performed on a
   public real dataset of labelled network flows, show that attackers can
   easily evade such defensive mechanisms by applying slight and targeted
   modifications to the network activity generated by their controlled
   bots. These findings pave the way for future techniques that aim to
   strengthen the performance of machine learning-based network intrusion
   detection systems.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Apruzzese, G (Corresponding Author), Univ Modena \& Reggio Emilia, Dept Engn Enzo Ferrari, Modena, Italy.
   Apruzzese, Giovanni; Colajanni, Michele, Univ Modena \& Reggio Emilia, Dept Engn Enzo Ferrari, Modena, Italy.}},
ISBN = {{978-1-5386-7659-2}},
Keywords = {{Adversarial samples; machine learning; random forest; intrusion
   detection; flow inspection; botnet}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Theory \&
   Methods; Engineering, Electrical \& Electronic}},
Author-Email = {{giovanni.apruzzese@unimore.it
   michele.colajanni@unimore.it}},
ResearcherID-Numbers = {{Apruzzese, Giovanni/AAQ-2764-2020}},
ORCID-Numbers = {{Apruzzese, Giovanni/0000-0002-6890-9611}},
Number-of-Cited-References = {{23}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BM8EN}},
Unique-ID = {{WOS:000469020900045}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000533371800003,
Author = {Abusnaina, Ahmed and Khormali, Aminollah and Nyang, DaeHun and Yuksel,
   Murat and Mohaisen, Aziz},
Book-Group-Author = {{IEEE}},
Title = {{Examining the Robustness of Learning-Based DDoS Detection in Software
   Defined Networks}},
Booktitle = {{2019 IEEE CONFERENCE ON DEPENDABLE AND SECURE COMPUTING (DSC)}},
Year = {{2019}},
Pages = {{17-24}},
Note = {{3rd IEEE Conference on Dependable and Secure Computing (DSC), Hangzhou,
   PEOPLES R CHINA, NOV 18-20, 2019}},
Organization = {{IEEE}},
Abstract = {{With the rapid development of Software-Defined Networking (SDN)
   advocating a centralized view of networks, efficient and reliable
   Distributed Denial of Service (DDoS) defenses are necessary to protect
   the centralized SDN controller. Recently, an amalgamation of work has
   realized such defenses using Deep Learning (DL) based algorithms.
   Although DL-based algorithms are generally prone to adversarial learning
   attacks, the extent to which those attacks are applicable to DDoS
   defenses in SDN is unexamined. In this work, we explore the robustness
   of DL-based DDoS defenses in SDN against adversarial learning attacks.
   First, we investigate generic off-the-shelf adversarial attacks to test
   the robustness of DDoS defenses in SDN, and demonstrate that while they
   lead to misclassification, these attacks do not preserve the
   characteristics of flows. As a result, we propose Flow-Merge for
   realistic adversarial flows while achieving a high evasion rate, with
   both targeted and untargeted misclassification attacks. The proposed
   Flow-Merge is able to force the DL-based DDoS defenses to misclassify
   100\% of benign flows as malicious, while preserving original
   characteristics of flows. Using state-of-the-art defenses, we show that
   the adversarial flows generated using Flow-Merge are difficult to
   detect, with only 49.31\% detection rate when using adversarial
   training.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Abusnaina, A (Corresponding Author), Univ Cent Florida, Orlando, FL 32816 USA.
   Abusnaina, Ahmed; Khormali, Aminollah; Yuksel, Murat; Mohaisen, Aziz, Univ Cent Florida, Orlando, FL 32816 USA.
   Nyang, DaeHun, Inha Univ, Incheon, South Korea.}},
ISBN = {{978-1-7281-2319-6}},
Keywords = {{Intrusion Detection Systems; Deep Learning; Adversarial Machine
   Learning; Software Defined Networking}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods; Engineering, Electrical \&
   Electronic}},
ResearcherID-Numbers = {{Mohaisen, Aziz/ABD-6425-2021}},
Funding-Acknowledgement = {{NVIDIA GPU Grant {[}NRF-2016K1A1A2912757];  {[}1647189];  {[}1814086]; 
   {[}1643207]}},
Funding-Text = {{This work is supported in part by NRF-2016K1A1A2912757 and NVIDIA GPU
   Grant, and NSF awards 1647189, 1814086, and 1643207.}},
Number-of-Cited-References = {{27}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BO9YY}},
Unique-ID = {{WOS:000533371800003}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000492150100014,
Author = {Usama, Muhammad and Asim, Muhammad and Latif, Siddique and Qadir, Junaid
   and Ala-Al-Fuqaha},
Book-Group-Author = {{IEEE}},
Title = {{Generative Adversarial Networks For Launching and Thwarting Adversarial
   Attacks on Network Intrusion Detection Systems}},
Booktitle = {{2019 15TH INTERNATIONAL WIRELESS COMMUNICATIONS \& MOBILE COMPUTING
   CONFERENCE (IWCMC)}},
Series = {{International Wireless Communications and Mobile Computing Conference}},
Year = {{2019}},
Pages = {{78-83}},
Note = {{15th IEEE International Wireless Communications and Mobile Computing
   Conference (IEEE IWCMC), Tangier, MOROCCO, JUN 24-28, 2019}},
Organization = {{IEEE; IEEE Morocco Sect; Mohammed V Univ Rabat}},
Abstract = {{Intrusion detection systems (IDSs) are an essential cog of the network
   security suite that can defend the network from malicious intrusions and
   anomalous traffic. Many machine learning (ML)-based IDSs have been
   proposed in the literature for the detection of malicious network
   traffic. However, recent works have shown that ML models are vulnerable
   to adversarial perturbations through which an adversary can cause IDSs
   to malfunction by introducing a small impracticable perturbation in the
   network traffic. In this paper, we propose an adversarial ML attack
   using generative adversarial networks (GANs) that can successfully evade
   an ML-based IDS. We also show that GANs can be used to inoculate the IDS
   and make it more robust to adversarial perturbations.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Usama, M (Corresponding Author), Informat Technol Univ, Punjab, Pakistan.
   Usama, Muhammad; Asim, Muhammad; Qadir, Junaid, Informat Technol Univ, Punjab, Pakistan.
   Latif, Siddique, Univ Southern Queensland, Toowoomba, Qld, Australia.
   Ala-Al-Fuqaha, Hamad Bin Khalifa Univ, Doha, Qatar.}},
ISSN = {{2376-6492}},
ISBN = {{978-1-5386-7747-6}},
Keywords = {{Adversarial machine learning; GAN; IDS}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Hardware \& Architecture; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{muhammad.usama@itu.edu.pk
   muhammad.asim@itu.edu.pk
   siddique.latif@usq.edu.au
   junaid.qadir@itu.edu.pk
   aalfuqaha@hbku.edu.qa}},
ResearcherID-Numbers = {{Qadir, Junaid/Q-6329-2019
   Latif, Siddique/X-2811-2019
   }},
ORCID-Numbers = {{Qadir, Junaid/0000-0001-9466-2475
   Latif, Siddique/0000-0001-5662-4777
   Al-Fuqaha, Ala/0000-0002-0903-1204}},
Number-of-Cited-References = {{17}},
Times-Cited = {{14}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{6}},
Doc-Delivery-Number = {{BO0MP}},
Unique-ID = {{WOS:000492150100014}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000668970503154,
Author = {Fei, Yixiao and Wang, Lei and He, Ruan and Lu, Jialiang},
Book-Group-Author = {{IEEE}},
Title = {{ECEM - Generating Adversarial Logs under Black-box Setting in Web
   Security}},
Booktitle = {{2020 IEEE GLOBAL COMMUNICATIONS CONFERENCE (GLOBECOM)}},
Series = {{IEEE Global Communications Conference}},
Year = {{2020}},
Note = {{IEEE Global Communications Conference (GLOBECOM) on Advanced Technology
   for 5G Plus, ELECTR NETWORK, DEC 07-11, 2020}},
Organization = {{IEEE; IEEE Commun Soc; Chunghwa Telecom; Foxconn; Huawei; Mediatek; 6G
   Off; Askey; Ericsson; FET Qualcomm; Taiwan Mobile; Auden Techno Corp;
   Keysight Technologies; Telecom Technol Ctr; NI}},
Abstract = {{Researchers are making efforts on detection and prevention in web
   security by deploying machine learning models, but such models are
   vulnerable to adversarial examples. We introduce Exploratory Character
   Edit Method (ECEM), requiring only detection labels to generate
   adversarial logs in web security. It is applicable to real-world
   black-box detection models, such as an IDS (Intrusion Detection System).
   Experiments on an open data set show that our adversarial attack
   outperforms two textual adversarial attacks in following points: (1) The
   success rate of attack is higher; (2) The quality of adversarial
   examples are higher (larger similarity and smaller distance); (3) The
   generation process requires fewer iterations; We further show the
   consequences of causative attacks by injecting adversarial logs into the
   training data set and a possible defensive mechanism with adversarial
   training.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Fei, YX (Corresponding Author), Shanghai Jiao Tong Univ, SJTU ParisTech Elite Inst Technol, Shanghai 200240, Peoples R China.
   Fei, Yixiao; Wang, Lei; Lu, Jialiang, Shanghai Jiao Tong Univ, SJTU ParisTech Elite Inst Technol, Shanghai 200240, Peoples R China.
   He, Ruan, Tencent, Shenzhen 518000, Peoples R China.}},
DOI = {{10.1109/GLOBECOM42002.2020.9347996}},
ISSN = {{2334-0983}},
EISSN = {{2576-6813}},
ISBN = {{978-1-7281-8298-8}},
Keywords = {{adversarial example; machine learning; black-box; web security;
   intrusion detection}},
Research-Areas = {{Computer Science; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Telecommunications}},
Author-Email = {{targaryen@sjtu.edu.cn
   thorray@sjtu.edu.cn
   ruanhe@tencent.com
   jialiang.lu@sjtu.edu.cn}},
Number-of-Cited-References = {{34}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BR7QI}},
Unique-ID = {{WOS:000668970503154}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000319456700047,
Author = {Hai Thanh Nguyen and Franke, Katrin},
Editor = {{Abraham, A and Zomaya, A and Wadhai, V and Yager, R and Muda, AK and Koeppen, M}},
Title = {{Adaptive Intrusion Detection System via Online Machine Learning}},
Booktitle = {{2012 12TH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS (HIS)}},
Year = {{2012}},
Pages = {{271-277}},
Note = {{12th International Conference on Hybrid Intelligent Systems (HIS),
   MITCOE, Pune, INDIA, DEC 04-07, 2012}},
Organization = {{MIR Labs; IEEE; IEEE Syst, Man \& Cybernet Soc Spain; IEEE Syst, Man \&
   Cybernet Soc CzechoSlovakia}},
Abstract = {{Adaptation of Intrusion Detection Systems (IDSs) in the heterogeneous
   and adversarial network environments is crucial. We design an adaptive
   IDS that has 10\% higher accuracy than the best of four different
   baseline IDSs. Rather than creating a new `super' IDS, we combine the
   outputs of the IDSs by using the online learning framework proposed by
   Bousquet and Warmuth {[}1]. The combination framework allows to
   dynamically determine the best IDSs performed in different segments of a
   dataset. Moreover, to increase the accuracy and reliability of the
   intrusion detection results, the fusion between outputs of the four IDSs
   is taken into account by a new expanded framework. We conduct the
   experiments on two different datasets for benchmarking Web Application
   Firewalls: the ECML-PKDD 2007 HTTP dataset and the CISIC HTTP 2010.
   Experimental results show the high adaptability of the proposed IDS.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Nguyen, HT (Corresponding Author), Gjovik Univ Coll, NISlab, Dept Comp Sci \& Media Technol, POB 191, N-2802 Gjovik, Norway.
   Hai Thanh Nguyen; Franke, Katrin, Gjovik Univ Coll, NISlab, Dept Comp Sci \& Media Technol, N-2802 Gjovik, Norway.}},
ISBN = {{978-1-4673-5115-7; 978-1-4673-5116-4}},
Keywords = {{intrusion detection; Web attack detection; online machine learning;
   adversarial learning; adaptability}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Information
   Systems}},
Author-Email = {{hai.nguyen@hig.no
   katrin.franke@hig.no}},
Number-of-Cited-References = {{18}},
Times-Cited = {{5}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BFE53}},
Unique-ID = {{WOS:000319456700047}},
DA = {{2021-11-23}},
}

@article{ WOS:000335629300017,
Author = {Pastrana, Sergio and Orfila, Agustin and Tapiador, Juan E. and
   Penis-Lopez, Pedro},
Title = {{Randomized Anagram revisited}},
Journal = {{JOURNAL OF NETWORK AND COMPUTER APPLICATIONS}},
Year = {{2014}},
Volume = {{41}},
Pages = {{182-196}},
Month = {{MAY}},
Abstract = {{When compared to signature-based Intrusion Detection Systems (IDS),
   anomaly detectors present the potential advantage of detecting
   previously unseen attacks, which makes them an attractive solution
   against zero-day exploits and other attacks for which a signature is
   unavailable. Most anomaly detectors rely on machine learning algorithms
   to derive a model of normality that is later used to detect suspicious
   events. Such algorithms, however, are generally susceptible to evasion
   by means of carefully constructed attacks that are not recognized as
   anomalous. Different strategies to thwart evasion have been proposed
   over the last years, including the use of randomization to make somewhat
   uncertain how each packet will be processed. In this paper we analyze
   the strength of the randomization strategy suggested for Anagram, a
   well-known anomaly detector based on n-gram models. We show that an
   adversary who can interact with the system for a short period of time
   with inputs of his choosing will be able to recover the secret mask used
   to process packets. We describe and discuss an efficient algorithm to do
   this and report our experiences with a prototype implementation.
   Furthermore, we show that the specific form of randomization suggested
   for Anagram is a double-edged sword, as knowledge of the mask makes
   evasion easier than in the nonrandomized case. We finally discuss a
   simple countermeasure to prevent our attacks. (C) 2014 Elsevier Ltd. All
   rights reserved.}},
Publisher = {{ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD}},
Address = {{24-28 OVAL RD, LONDON NW1 7DX, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Pastrana, S (Corresponding Author), Univ Carlos III Madrid, Dept Comp Sci, Comp Secur COSEC Lab, Avda Univ 30, Madrid 28911, Spain.
   Pastrana, Sergio; Orfila, Agustin; Tapiador, Juan E.; Penis-Lopez, Pedro, Univ Carlos III Madrid, Dept Comp Sci, Comp Secur COSEC Lab, Madrid 28911, Spain.}},
DOI = {{10.1016/j.jnca.2013.11.006}},
ISSN = {{1084-8045}},
Keywords = {{Intrusion detection systems; Anomaly detection; Evasion attacks;
   Adversarial classification}},
Keywords-Plus = {{INTRUSION DETECTION; ATTACKS; SYSTEM}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Hardware \& Architecture; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering}},
Author-Email = {{spastran@inf.uc3m.es
   adiaz@inf.uc3m.es
   jestevez@inf.uc3m.es
   pperis@inf.uc3m.es}},
ResearcherID-Numbers = {{Peris-Lopez, Pedro/AAB-1090-2019
   Tapiador, Juan/G-2304-2016}},
ORCID-Numbers = {{Peris-Lopez, Pedro/0000-0001-6943-0760
   PASTRANA, SERGIO/0000-0003-1036-6359
   Tapiador, Juan/0000-0002-4573-3967}},
Number-of-Cited-References = {{42}},
Times-Cited = {{9}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{6}},
Journal-ISO = {{J. Netw. Comput. Appl.}},
Doc-Delivery-Number = {{AG7WK}},
Unique-ID = {{WOS:000335629300017}},
OA = {{Green Accepted}},
DA = {{2021-11-23}},
}

@article{ WOS:000447358700026,
Author = {Kwon, Hyun and Kim, Yongchul and Park, Ki-Woong and Yoon, Hyunsoo and
   Choi, Daeseon},
Title = {{Friend-safe evasion attack: An adversarial example that is correctly
   recognized by a friendly classifier}},
Journal = {{COMPUTERS \& SECURITY}},
Year = {{2018}},
Volume = {{78}},
Pages = {{380-397}},
Month = {{SEP}},
Abstract = {{Deep neural networks (DNNs) have been applied in several useful
   services, such as image recognition, intrusion detection, and pattern
   analysis of machine learning tasks. Recently proposed adversarial
   examples-slightly modified data that lead to incorrect classification
   are a severe threat to the security of DNNs. In some situations,
   however, an adversarial example might be useful, such as when deceiving
   an enemy classifier on the battlefield. In such a scenario, it is
   necessary that a friendly classifier not be deceived. In this paper, we
   propose a friend-safe adversarial example, meaning that the friendly
   machine can classify the adversarial example correctly. To produce such
   examples, a transformation is carried out to minimize the probability of
   incorrect classification by the friend and that of correct
   classification by the adversary. We suggest two configurations for the
   scheme: targeted and untargeted class attacks. We performed experiments
   with this scheme using the MNIST and CIFAR10 datasets. Our proposed
   method shows a 100\% attack success rate and 100\% friend accuracy with
   only a small distortion: 2.18 and 1.54 for the two respective MNIST
   configurations, and 49.02 and 27.61 for the two respective CIFAR10
   configurations. Additionally, we propose a new covert channel scheme and
   a mixed battlefield application for consideration in further
   applications. (C) 2018 Elsevier Ltd. All rights reserved.}},
Publisher = {{ELSEVIER ADVANCED TECHNOLOGY}},
Address = {{OXFORD FULFILLMENT CENTRE THE BOULEVARD, LANGFORD LANE, KIDLINGTON,
   OXFORD OX5 1GB, OXON, ENGLAND}},
Type = {{Review}},
Language = {{English}},
Affiliation = {{Choi, D (Corresponding Author), Kongju Natl Univ, Dept Med Informat, Gongju Si 32588, South Korea.
   Kwon, Hyun; Yoon, Hyunsoo, Korea Adv Inst Sci \& Technol, Sch Comp, Daejeon 34141, South Korea.
   Kim, Yongchul, Korea Mil Acad, Dept Elect Engn, Seoul 01819, South Korea.
   Park, Ki-Woong, Sejong Univ, Dept Comp \& Informat Secur, Seoul 05006, South Korea.
   Choi, Daeseon, Kongju Natl Univ, Dept Med Informat, Gongju Si 32588, South Korea.}},
DOI = {{10.1016/j.cose.2018.07.015}},
ISSN = {{0167-4048}},
EISSN = {{1872-6208}},
Keywords = {{Deep Neural Network; Evasion Attack; Adversarial Example; Covert
   Channel; Machine Learning}},
Keywords-Plus = {{DEEP NEURAL-NETWORKS; SECURITY}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems}},
Author-Email = {{khkh@kaist.ac.kr
   kyc6454@kma.ac.kr
   woongbak@sejong.ac.kr
   hyoon@kaist.ac.kr
   sunchoi@kongju.ac.kr}},
ResearcherID-Numbers = {{Kwon, Hyun/M-1140-2018
   Yoon, Hyunsoo/C-2000-2011
   }},
ORCID-Numbers = {{Kwon, Hyun/0000-0003-1169-9892
   Park, Ki-Woong/0000-0002-3377-223X}},
Funding-Acknowledgement = {{National Research Foundation of Korea (NRF) - Korean government (MSIT)
   {[}2016R1A4A1011761, 2017R1A2B4006026]; Institute for Information \&
   Communications Technology Promotion (IITP) - Korean government (MSIT)
   {[}2016-0-00173]}},
Funding-Text = {{We thank the editors and the anonymous reviewers, who gave us very
   helpful comments that improved this paper. This work was supported by
   National Research Foundation of Korea (NRF) grants funded by the Korean
   government (MSIT) (2016R1A4A1011761 and 2017R1A2B4006026) and an
   Institute for Information \& Communications Technology Promotion (IITP)
   grant funded by the Korean government (MSIT) (No. 2016-0-00173, Security
   Technologies for Financial Fraud Prevention on Fintech).}},
Number-of-Cited-References = {{42}},
Times-Cited = {{9}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{17}},
Journal-ISO = {{Comput. Secur.}},
Doc-Delivery-Number = {{GW9WU}},
Unique-ID = {{WOS:000447358700026}},
DA = {{2021-11-23}},
}

@article{ WOS:000672545900001,
Author = {Wang, Yixiang and Lv, Shaohua and Liu, Jiqiang and Chang, Xiaolin and
   Wang, Jinqiang},
Title = {{On the combination of data augmentation method and gated convolution
   model for building effective and robust intrusion detection}},
Journal = {{CYBERSECURITY}},
Year = {{2020}},
Volume = {{3}},
Number = {{1}},
Month = {{DEC 15}},
Abstract = {{Deep learning (DL) has exhibited its exceptional performance in fields
   like intrusion detection. Various augmentation methods have been
   proposed to improve data quality and eventually to enhance the
   performance of DL models. However, the classic augmentation methods
   cannot be applied to those DL models which exploit the system-call
   sequences to detect intrusion. Previously, the seq2seq model has been
   explored to augment system-call sequences. Following this work, we
   propose a gated convolutional neural network (GCNN) model to thoroughly
   extract the potential information of augmented sequences. Also, in order
   to enhance the model's robustness, we adopt adversarial training to
   reduce the impact of adversarial examples on the model. Adversarial
   examples used in adversarial training are generated by the proposed
   adversarial sequence generation algorithm. The experimental results on
   different verified models show that GCNN model can better obtain the
   potential information of the augmented data and achieve the best
   performance. Furthermore, GCNN with adversarial training can enhance
   robustness significantly.}},
Publisher = {{SPRINGERNATURE}},
Address = {{CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Chang, XL (Corresponding Author), Beijing Jiaotong Univ, Beijing Key Lab Secur \& Privacy Intelligent Trans, 3 Shangyuancun, Beijing 100044, Peoples R China.
   Wang, Yixiang; Lv, Shaohua; Liu, Jiqiang; Chang, Xiaolin, Beijing Jiaotong Univ, Beijing Key Lab Secur \& Privacy Intelligent Trans, 3 Shangyuancun, Beijing 100044, Peoples R China.
   Wang, Jinqiang, Beijing Jiaotong Univ, Beijing Key Lab Traff Data Anal \& Min, 3 Shangyuancun, Beijing 100044, Peoples R China.}},
DOI = {{10.1186/s42400-020-00063-5}},
Article-Number = {{23}},
EISSN = {{2523-3246}},
Keywords = {{Data augmentation; Intrusion detection system; Machine learning
   algorithms; System call}},
Keywords-Plus = {{NETWORK}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering}},
Author-Email = {{xlchang@bjtu.edu.cn}},
Funding-Acknowledgement = {{Fundamental Research Funds for the Central Universities of
   ChinaFundamental Research Funds for the Central Universities
   {[}2019YJS049]}},
Funding-Text = {{This work was supported in part by the Fundamental Research Funds for
   the Central Universities of China under Grants 2019YJS049.}},
Number-of-Cited-References = {{40}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{Cybersecurity}},
Doc-Delivery-Number = {{TI1ME}},
Unique-ID = {{WOS:000672545900001}},
OA = {{gold}},
DA = {{2021-11-23}},
}

@article{ WOS:000673518500056,
Author = {Shu, Jiangang and Zhou, Lei and Zhang, Weizhe and Du, Xiaojiang and
   Guizani, Mohsen},
Title = {{Collaborative Intrusion Detection for VANETs: A Deep Learning-Based
   Distributed SDN Approach}},
Journal = {{IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS}},
Year = {{2021}},
Volume = {{22}},
Number = {{7}},
Pages = {{4519-4530}},
Month = {{JUL}},
Abstract = {{Vehicular Ad hoc Network (VANET) is an enabling technology to provide a
   variety of convenient services in intelligent transportation systems,
   and yet vulnerable to various intrusion attacks. Intrusion detection
   systems (IDSs) can mitigate the security threats by detecting abnormal
   network behaviours. However, existing IDS solutions are limited to
   detect abnormal network behaviors under local sub-networks rather than
   the entire VANET. To address this problem, we utilize deep learning with
   generative adversarial networks and explore distributed SDN to design a
   collaborative intrusion detection system (CIDS) for VANETs, which
   enables multiple SDN controllers jointly train a global intrusion
   detection model for the entire network without directly exchanging their
   sub-network flows. We prove the correctness of our CIDS in both IID
   (Independent Identically Distribution) and non-IID situations, and also
   evaluate its performance through both theoretical analysis and
   experimental evaluation on a real-world dataset. Detailed experimental
   results validate that our CIDS is efficient and effective in intrusion
   detection for VANETs.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Zhang, WZ (Corresponding Author), Harbin Inst Technol, Sch Comp Sci \& Technol, Shenzhen 518000, Peoples R China.
   Shu, Jiangang; Zhang, Weizhe, Cyberspace Secur Res Ctr, Peng Cheng Lab, Shenzhen 518000, Peoples R China.
   Zhou, Lei; Zhang, Weizhe, Harbin Inst Technol, Sch Comp Sci \& Technol, Shenzhen 518000, Peoples R China.
   Du, Xiaojiang, Temple Univ, Dept Comp \& Informat Sci, Philadelphia, PA 19122 USA.
   Guizani, Mohsen, Qatar Univ, Dept Comp Sci \& Engn, Doha, Qatar.}},
DOI = {{10.1109/TITS.2020.3027390}},
ISSN = {{1524-9050}},
EISSN = {{1558-0016}},
Keywords = {{Collaborative intrusion detection; intelligent transportation;
   distributed SDN; deep learning; generative adversarial networks}},
Keywords-Plus = {{SOFTWARE-DEFINED NETWORKING; DETECTION FRAMEWORK; SYSTEMS}},
Research-Areas = {{Engineering; Transportation}},
Web-of-Science-Categories  = {{Engineering, Civil; Engineering, Electrical \& Electronic;
   Transportation Science \& Technology}},
Author-Email = {{shujg@pcl.ac.cn
   19S151089@stu.hit.edu.cn
   wzzhang@hit.edu.cn
   dxj@ieee.org
   mguizani@ieee.org}},
ORCID-Numbers = {{Guizani, Mohsen/0000-0002-8972-8094}},
Funding-Acknowledgement = {{Key-Area Research and Development Program of Guangdong Province
   {[}2019B010136001]; Natural Science Foundation of ChinaNational Natural
   Science Foundation of China (NSFC) {[}61732022, 61672195]; Peng Cheng
   Laboratory Project of Guangdong Province {[}PCL2018KP004, PCL2018KP005]}},
Funding-Text = {{This work was supported in part by the Key-Area Research and Development
   Program of Guangdong Province under Grant 2019B010136001, in part by the
   Natural Science Foundation of China under Grant 61732022 and Grant
   61672195, and in part by the Peng Cheng Laboratory Project of Guangdong
   Province under Grant PCL2018KP004 and Grant PCL2018KP005.}},
Number-of-Cited-References = {{36}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{4}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{IEEE Trans. Intell. Transp. Syst.}},
Doc-Delivery-Number = {{TJ5JU}},
Unique-ID = {{WOS:000673518500056}},
DA = {{2021-11-23}},
}

@article{ WOS:000652592500405,
Author = {Zhang, Wen-an and Miao, Yinfeng and Wu, Qi and Yu, Li and Shi, Xiufang},
Title = {{Intrusion Detection of Industrial Control System Based on Double-layer
   One-class Support Vector Machine}},
Journal = {{IFAC PAPERSONLINE}},
Year = {{2020}},
Volume = {{53}},
Number = {{2}},
Pages = {{2513-2518}},
Note = {{21st IFAC World Congress on Automatic Control - Meeting Societal
   Challenges, ELECTR NETWORK, JUL 11-17, 2020}},
Organization = {{Int Federat Automat Control; Siemens; Bayer; ABB; MathWorks; Phoenix
   Contact; Ifak Technol; Berlin Heart; Elsevier; De Gruyter; Tele Medi
   GmbH}},
Abstract = {{In this paper, the stealthy attack detection in industrial control
   system (ICS) is studied, and a new detection method is proposed from the
   perspective of signal analysis. The method consists of a double-layer
   one-class support vector machine model (DL-OCSVM), where the first-layer
   model is the standard OCSVM, and the second-layer model is obtained by
   incremental learning based on the former. The wavelet decomposition is
   used to extract the physical characteristics of the ICS. The KKT
   condition and the adjacent classification interval are adopted to reduce
   the training samples, improving the learning rate and system
   scalability. In addition, the designed boundary samples are employed for
   incremental learning, avoiding overfitting and reducing false positives
   rate (FPR). The experimental results show that the proposed method has
   high detection rate and low FPR for stealthy attacks, and is more
   suitable for precision machining process. Copyright (C) 2020 The
   Authors.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Zhang, WA (Corresponding Author), Zhejiang Univ Technol, Coll Informat Engn, Hangzhou 310023, Peoples R China.
   Zhang, Wen-an; Miao, Yinfeng; Wu, Qi; Yu, Li; Shi, Xiufang, Zhejiang Univ Technol, Coll Informat Engn, Hangzhou 310023, Peoples R China.}},
DOI = {{10.1016/j.ifacol.2020.12.226}},
ISSN = {{2405-8963}},
Keywords = {{Industrial control systems(ICSs); intrusion detection; machine learning;
   one-class support vector machine (OCSVM)}},
Research-Areas = {{Automation \& Control Systems}},
Web-of-Science-Categories  = {{Automation \& Control Systems}},
Funding-Acknowledgement = {{National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}61822311]}},
Funding-Text = {{The work was supported by the National Natural Science Foundation of
   China under Grant No. 61822311}},
Number-of-Cited-References = {{12}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{IFAC PAPERSONLINE}},
Doc-Delivery-Number = {{SF2LK}},
Unique-ID = {{WOS:000652592500405}},
OA = {{gold}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000455620700008,
Author = {Warzynski, Arkadiusz and Kolaczek, Grzegorz},
Editor = {{Yildirim, T and Manolopoulos, Y and Angelov, P and Iliadis, L}},
Title = {{Intrusion detection systems vulnerability on adversarial examples}},
Booktitle = {{2018 INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA)}},
Year = {{2018}},
Note = {{IEEE (SMC) International Conference on Innovations in Intelligent
   Systems and Applications (INISTA), Thessaloniki, GREECE, JUL 03-05, 2018}},
Organization = {{Aristotle Univ Thessaloniki; Democritus Univ Thrace; IEEE Systems \&
   Cybernet Soc; IEEE; Yildiz Techn Univ}},
Abstract = {{Intrusion detection systems define an important and dynamic research
   area for cybersecurity. The role of Intrusion Detection System within
   security architecture is to improve a security level by identification
   of all malicious and also suspicious events that could be observed in
   computer or network system. One of the more specific research areas
   related to intrusion detection is anomaly detection. Anomaly-based
   intrusion detection in networks refers to the problem of finding
   untypical events in the observed network traffic that do not conform to
   the expected normal patterns. It is assumed that everything that is
   untypical/anomalous could be dangerous and related to some security
   events. To detect anomalies many security systems implements a
   classification or clustering algorithms. However, recent research proved
   that machine learning models might misclassify adversarial events, e.g.
   observations which were created by applying intentionally non-random
   perturbations to the dataset. Such weakness could increase of false
   negative rate which implies undetected attacks. This fact can lead to
   one of the most dangerous vulnerabilities of intrusion detection
   systems. The goal of the research performed was verification of the
   anomaly detection systems ability to resist this type of attack. This
   paper presents the preliminary results of tests taken to investigate
   existence of attack vector, which can use adversarial examples to
   conceal a real attack from being detected by intrusion detection
   systems.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Warzynski, A (Corresponding Author), Wroclaw Univ Sci \& Technol, Fac Comp Sci \& Management, 27 Wybrzeze Wyspianskiego St, PL-50370 Wroclaw, Poland.
   Warzynski, Arkadiusz; Kolaczek, Grzegorz, Wroclaw Univ Sci \& Technol, Fac Comp Sci \& Management, 27 Wybrzeze Wyspianskiego St, PL-50370 Wroclaw, Poland.}},
ISBN = {{978-1-5386-5150-6}},
Keywords = {{Anomaly detection; Adversarial examples; intrusion detection systems}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods; Engineering, Electrical \& Electronic}},
Number-of-Cited-References = {{14}},
Times-Cited = {{14}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BL7TW}},
Unique-ID = {{WOS:000455620700008}},
DA = {{2021-11-23}},
}

@article{ WOS:000473120600009,
Author = {Caminero, Guillermo and Lopez-Martin, Manuel and Carro, Belen},
Title = {{Adversarial environment reinforcement learning algorithm for intrusion
   detection}},
Journal = {{COMPUTER NETWORKS}},
Year = {{2019}},
Volume = {{159}},
Pages = {{96-109}},
Month = {{AUG 4}},
Abstract = {{Intrusion detection is a crucial service in today's data networks, and
   the search for new fast and robust algorithms that are capable of
   detecting and classifying dangerous traffic is essential to deal with
   changing threats and increasing detection difficulty. In this work, we
   present a new intrusion detection algorithm with an excellent prediction
   performance. The prediction is based on a classifier which is a simple
   and extremely fast neural network. The classifier implements a policy
   function that is trained with a novel reinforcement learning model,
   where the behavior of the environment is adjusted in parallel with the
   learning process.
   Intrusion detection frameworks are based on a supervised learning
   paradigm that uses a training dataset composed of network features and
   associated intrusion labels. In this work, we integrate this paradigm
   with a reinforcement learning algorithm that is normally based on
   interaction with a live environment (not a pre-recorded dataset). To
   perform the integration, the live environment is replaced by a simulated
   one.
   The principle of this approach is to provide the simulated environment
   with an intelligent behavior by, first, generating new samples by
   randomly extracting them from the training dataset, generating rewards
   that depend on the goodness of the classifier's predictions, and,
   second, by further adjusting this initial behavior with an adversarial
   objective in which the environment will actively try to increase the
   difficulty of the prediction made by the classifier. In this way, the
   simulated environment acts as a second agent in an adversarial
   configuration against the original agent (the classifier). We prove that
   this architecture increases the final performance of the classifier.
   This work presents the first application of adversarial reinforcement
   learning for intrusion detection, and provides a novel technique that
   incorporates the environment's behavior into the learning process of a
   modified reinforcement learning algorithm.
   We prove that the proposed algorithm is adequate for a supervised
   learning problem based on a labeled dataset. We validate its performance
   by comparing it with other well-known machine learning models for two
   datasets. The proposed model outperforms the other models in the
   weighted Accuracy (>0.8) and F1 (>0.79) metrics, and especially excels
   in the results for the under-represented labels. (C) 2019 Elsevier B.V.
   All rights reserved.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Lopez-Martin, M (Corresponding Author), Univ Valladolid, Dept TSyCelT, ETSIT, Paseo Belen 15, E-47011 Valladolid, Spain.
   Caminero, Guillermo; Lopez-Martin, Manuel; Carro, Belen, Univ Valladolid, Dept TSyCelT, ETSIT, Paseo Belen 15, E-47011 Valladolid, Spain.}},
DOI = {{10.1016/j.comnet.2019.05.013}},
ISSN = {{1389-1286}},
EISSN = {{1872-7069}},
Keywords = {{Intrusion detection; Reinforcement learning; Adversarial learning}},
Keywords-Plus = {{ENABLING TECHNOLOGIES; INTERNET; THINGS}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Hardware \& Architecture; Computer Science,
   Information Systems; Engineering, Electrical \& Electronic;
   Telecommunications}},
Author-Email = {{gcaminerof@gmail.com
   mlopezm@ieee.org
   belcar@tel.uva.es}},
ResearcherID-Numbers = {{Lopez-Martin, Manuel/AAO-5602-2020
   Carro, Belen/L-7094-2014}},
ORCID-Numbers = {{Lopez-Martin, Manuel/0000-0003-3550-560X
   Carro, Belen/0000-0001-7051-8479}},
Number-of-Cited-References = {{42}},
Times-Cited = {{30}},
Usage-Count-Last-180-days = {{8}},
Usage-Count-Since-2013 = {{31}},
Journal-ISO = {{Comput. Netw.}},
Doc-Delivery-Number = {{IF5KV}},
Unique-ID = {{WOS:000473120600009}},
DA = {{2021-11-23}},
}

@article{ WOS:000684011900014,
Author = {Anthi, Eirini and Williams, Lowri and Rhode, Matilda and Burnap, Pete
   and Wedgbury, Adam},
Title = {{Adversarial attacks on machine learning cybersecurity defences in
   Industrial Control Systems}},
Journal = {{JOURNAL OF INFORMATION SECURITY AND APPLICATIONS}},
Year = {{2021}},
Volume = {{58}},
Month = {{MAY}},
Abstract = {{The proliferation and application of machine learning-based Intrusion
   Detection Systems (IDS) have allowed for more flexibility and efficiency
   in the automated detection of cyber attacks in Industrial Control
   Systems (ICS). However, the introduction of such IDSs has also created
   an additional attack vector; the learning models may also be subject to
   cyber attacks, otherwise referred to as Adversarial Machine Learning
   (AML). Such attacks may have severe consequences in ICS systems, as
   adversaries could potentially bypass the IDS. This could lead to delayed
   attack detection which may result in infrastructure damages, financial
   loss, and even loss of life. This paper explores how adversarial
   learning can be used to target supervised models by generating
   adversarial samples using the Jacobian-based Saliency Map attack and
   exploring classification behaviours. The analysis also includes the
   exploration of how such samples can support the robustness of supervised
   models using adversarial training. An authentic power system dataset was
   used to support the experiments presented herein. Overall, the
   classification performance of two widely used classifiers, Random Forest
   and J48, decreased by 6 and 11 percentage points when adversarial
   samples were present. Their performances improved following adversarial
   training, demonstrating their robustness towards such attacks.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Anthi, E (Corresponding Author), Cardiff Univ, Sch Comp Sci \& Informat, Cardiff, Wales.
   Anthi, Eirini; Williams, Lowri; Rhode, Matilda; Burnap, Pete, Cardiff Univ, Sch Comp Sci \& Informat, Cardiff, Wales.
   Wedgbury, Adam, Airbus, Newport, Shrops, England.}},
DOI = {{10.1016/j.jisa.2020.102717}},
Article-Number = {{102717}},
ISSN = {{2214-2126}},
EISSN = {{2214-2134}},
Keywords = {{Industrial Control Systems; Supervised machine learning; Adversarial
   Machine Learning; Attack detection; Intrusion Detection System}},
Keywords-Plus = {{CYBER-ATTACKS; DISTURBANCES}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems}},
Author-Email = {{anthies@cardiff.ac.uk}},
Funding-Acknowledgement = {{Airbus Endeavr, grant ``SCADA Cybersecurity Lifecycle 2''; Engineering
   and Physical Sciences Research Council (EPSRC)UK Research \& Innovation
   (UKRI)Engineering \& Physical Sciences Research Council (EPSRC); grant
   ``New Industrial Systems: Chatty Factories'' {[}REF EP/R021031/1]}},
Funding-Text = {{This project was part-funded by: Airbus Endeavr, grant ``SCADA
   Cybersecurity Lifecycle 2''; and the Engineering and Physical Sciences
   Research Council (EPSRC), grant ``New Industrial Systems: Chatty
   Factories'', REF EP/R021031/1.}},
Number-of-Cited-References = {{55}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{4}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{J. Inf. Secur. Appl.}},
Doc-Delivery-Number = {{TY8EF}},
Unique-ID = {{WOS:000684011900014}},
OA = {{Green Accepted, Green Submitted, hybrid}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000568591200029,
Author = {Apruzzese, Giovanni and Colajanni, Michele and Marchetti, Mirco},
Editor = {{GkoulalasDivanis, A and Marchetti, M and Avresky, DR}},
Title = {{Evaluating the effectiveness of Adversarial Attacks against Botnet
   Detectors}},
Booktitle = {{2019 IEEE 18TH INTERNATIONAL SYMPOSIUM ON NETWORK COMPUTING AND
   APPLICATIONS (NCA)}},
Year = {{2019}},
Pages = {{193-200}},
Note = {{18th IEEE International Symposium on Network Computing and Applications
   (IEEE NCA), Cambridge, MA, SEP 26-28, 2019}},
Organization = {{IEEE; IEEE Comp Soc Tech Comm Distributed Proc}},
Abstract = {{Classifiers based on Machine Learning are vulnerable to adversarial
   attacks, which involve the creation of malicious samples that are not
   classified correctly. While this phenomenon has been extensively studied
   within the image processing domain, comprehensive analyses are scarce in
   the cybersecurity field. This is a critical problem because
   cyber-detectors are being increasingly integrated with machine learning
   methods, making them suitable targets for skilled attackers leveraging
   adversarial samples to evade detection. In this paper, we propose a
   thorough analysis of realistic adversarial attacks performed against
   network intrusion detection systems that focus on identifying botnet
   traffic through machine learning classifiers. Our large campaign of
   experiments involves the most recent public datasets, representing
   multiple realistic network scenarios. Moreover, we evaluate the impact
   of these attacks against state-of-the-art detectors relying on different
   machine learning algorithms, providing a clear overview of this problem.
   The results outline the fragility of these methods. Our study represent
   a stepping stone for devising suitable countermeasures to the menace of
   adversarial attacks against cyber-detectors.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Apruzzese, G (Corresponding Author), Univ Modena \& Reggio Emilia, Dept Engn Enzo Ferrari, Modena, Italy.
   Apruzzese, Giovanni; Colajanni, Michele; Marchetti, Mirco, Univ Modena \& Reggio Emilia, Dept Engn Enzo Ferrari, Modena, Italy.}},
ISBN = {{978-1-7281-2522-0}},
Keywords = {{Adversarial samples; machine learning; intrusion detection; flow
   inspection; botnet}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Theory \&
   Methods; Engineering, Electrical \& Electronic}},
Author-Email = {{giovanni.apruzzese@unimore.it
   michele.colajanni@unimore.it
   mirco.marchetti@unimore.it}},
ResearcherID-Numbers = {{Apruzzese, Giovanni/AAQ-2764-2020
   Marchetti, Mirco/K-6057-2015}},
ORCID-Numbers = {{Apruzzese, Giovanni/0000-0002-6890-9611
   Colajanni, Michele/0000-0002-9499-1559
   Marchetti, Mirco/0000-0002-7408-6906}},
Number-of-Cited-References = {{35}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BP8ZK}},
Unique-ID = {{WOS:000568591200029}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000482058200176,
Author = {Zizzo, Giulio and Hankin, Chris and Maffeis, Sergio and Jones, Kevin},
Book-Group-Author = {{ACM}},
Title = {{INVITED: Adversarial Machine Learning Beyond the Image Domain}},
Booktitle = {{PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE
   (DAC)}},
Year = {{2019}},
Note = {{56th ACM/EDAC/IEEE Design Automation Conference (DAC), Las Vegas, NV,
   JUN 02-06, 2019}},
Organization = {{ACM; EDAC; IEEE}},
Abstract = {{Machine learning systems have had enormous success in a wide range of
   fields from computer vision, natural language processing, and anomaly
   detection. However, such systems are vulnerable to attackers who can
   cause deliberate misclassification by introducing small perturbations.
   With machine learning systems being proposed for cyber attack detection
   such attackers are cause for serious concern. Despite this the vast
   majority of adversarial machine learning security research is focused on
   the image domain. This work gives a brief overview of adversarial
   machine learning and machine learning used in cyber attack detection and
   suggests key differences between the traditional image domain of
   adversarial machine learning and the cyber domain. Finally we show an
   adversarial machine learning attack on an industrial control system.}},
Publisher = {{ASSOC COMPUTING MACHINERY}},
Address = {{1515 BROADWAY, NEW YORK, NY 10036-9998 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Zizzo, G (Corresponding Author), Imperial Coll London, Dept Comp, Inst Secur Sci \& Technol, London, England.
   Zizzo, Giulio; Hankin, Chris, Imperial Coll London, Dept Comp, Inst Secur Sci \& Technol, London, England.
   Maffeis, Sergio, Imperial Coll London, Dept Comp, London, England.
   Jones, Kevin, Airbus, Cyber Secur Innovat, Leiden, Netherlands.}},
DOI = {{10.1145/3316781.3323470}},
ISBN = {{978-1-4503-6725-7}},
Keywords = {{neural networks; adversarial machine learning; intrusion detection}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Software Engineering; Computer Science, Theory \&
   Methods}},
Author-Email = {{g.zizzo17@imperial.ac.uk
   c.hankin@imperial.ac.uk
   sergio.maffeis@imperial.ac.uk
   kevin.jones@airbus.com}},
ORCID-Numbers = {{Hankin, Chris/0000-0001-9149-8577}},
Funding-Acknowledgement = {{Industrial CASE studentship; UK Engineering and Physical Science
   Research Council (EPSRC)UK Research \& Innovation (UKRI)Engineering \&
   Physical Sciences Research Council (EPSRC); Airbus}},
Funding-Text = {{This work was partially funded by an Industrial CASE studentship jointly
   between the UK Engineering and Physical Science Research Council (EPSRC)
   and Airbus. The authors also thank NVIDIA for their donation of a GPU in
   support of this work.}},
Number-of-Cited-References = {{17}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{11}},
Doc-Delivery-Number = {{BN4JZ}},
Unique-ID = {{WOS:000482058200176}},
OA = {{Green Accepted}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000454683600037,
Author = {Seo, Eunbi and Song, Hyun Min and Kim, Huy Kang},
Editor = {{McLaughlin, K and Ghorbani, A and Sezer, S and Lu, R and Chen, L and Deng, RH and Miller, P and Marsh, S and Nurse, J}},
Title = {{GIDS: GAN based Intrusion Detection System for In-Vehicle Network}},
Booktitle = {{2018 16TH ANNUAL CONFERENCE ON PRIVACY, SECURITY AND TRUST (PST)}},
Series = {{Annual Conference on Privacy Security and Trust-PST}},
Year = {{2018}},
Pages = {{286-291}},
Note = {{16th Annual Conference on Privacy, Security and Trust (PST), Belfast,
   NORTH IRELAND, AUG 28-30, 2018}},
Organization = {{IEEE; Proofpoint; Invest NI; NCSC; CSIT; Allstate; Titan IC; Carson
   McDowell; RITICS; RISE; Hays Recruitment}},
Abstract = {{A Controller Area Network (CAN) bus in the vehicles is an efficient
   standard bus enabling communication between all Electronic Control Units
   (ECU). However, CAN bus is not enough to protect itself because of lack
   of security features. To detect suspicious network connections
   effectively, the intrusion detection system (IDS) is strongly required.
   Unlike the traditional IDS for Internet, there are small number of known
   attack signatures for vehicle networks. Also, IDS for vehicle requires
   high accuracy because any false-positive error can seriously affect the
   safety of the driver. To solve this problem, we propose a novel IDS
   model for in-vehicle networks, GIDS (GAN based Intrusion Detection
   System) using deep-learning model, Generative Adversarial Nets. GIDS can
   learn to detect unknown attacks using only normal data. As experiment
   result, GIDS shows high detection accuracy for four unknown attacks.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Seo, E (Corresponding Author), Korea Univ, Seoul, South Korea.
   Seo, Eunbi; Song, Hyun Min; Kim, Huy Kang, Korea Univ, Seoul, South Korea.}},
ISSN = {{1712-364X}},
ISBN = {{978-1-5386-7493-2}},
Keywords = {{Generative Adversarial Nets; Intrusion detection System; Controller Area
   Network; in-vehicle security}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Theory \&
   Methods; Engineering, Electrical \& Electronic}},
Author-Email = {{eunbi@korea.ac.kr
   signos@korea.ac.kr
   cenda@korea.ac.kr}},
ResearcherID-Numbers = {{Kim, Huy Kang/R-5779-2016}},
ORCID-Numbers = {{Kim, Huy Kang/0000-0002-0760-8807}},
Funding-Acknowledgement = {{Institute for Information \& communications Technology Promotion(IITP) -
   Korea government(MSIT) {[}R7117-16-0161]}},
Funding-Text = {{This work was supported by Institute for Information \& communications
   Technology Promotion(IITP) grant funded by the Korea government(MSIT)
   (No. R7117-16-0161, Anomaly Detection Framework for Autonomous Vehicles)}},
Number-of-Cited-References = {{9}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{5}},
Doc-Delivery-Number = {{BL6SM}},
Unique-ID = {{WOS:000454683600037}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000428054302090,
Author = {Viegas, Eduardo and Santin, Altair and Neves, Nuno and Bessani, Alysson
   and Abreu, Vilmar},
Book-Group-Author = {{IEEE}},
Title = {{A Resilient Stream Learning Intrusion Detection Mechanism for Real-time
   Analysis of Network Traffic}},
Booktitle = {{GLOBECOM 2017 - 2017 IEEE GLOBAL COMMUNICATIONS CONFERENCE}},
Series = {{IEEE Global Communications Conference}},
Year = {{2017}},
Note = {{IEEE Global Telecommunications Conference (GLOBECOM), YourSingapore,
   Singapore, SINGAPORE, DEC 04-08, 2017}},
Organization = {{IEEE; Intel; Natl Instruments; Huawei; Keysight Technologies Inc;
   Nanyang Technol Univ, Sch Elect \& Elect Engn; Rohde \& Schwarz}},
Abstract = {{The number of novel attacks observed in networked systems increases
   every day. Due to the large amount of generated data over the network,
   its storage for further analysis may not be feasible. Moreover, current
   attacks are becoming more sophisticated, as the attackers are attempting
   to evade traditional intrusion detection mechanisms by perverting their
   properties. This paper presents a novel real-time (ongoing) network
   traffic measurement approach that supports resilient analysis for stream
   learning intrusion detection. The network data is grouped at runtime
   according to its characteristics, while each network traffic flow is
   discretized at regular time intervals. Each network flow is classified
   by a multi-view stream learning classifiers pool, defining the network
   flow class through a majority voting approach. The proposal is able to
   provide resiliency to the classifiers even for the detection of unknown
   attacks. The evaluation tests for the average operation point (25 views)
   provides an increase in the system resilience to adversarial attacks of
   22 \% when compared to traditional approaches. Moreover, in the
   scalability experiments with a 10-node (single core each) cluster
   testbed, the network flow measurement solution (1 view) reached 1.38
   Gbps throughput, while the proposed resilient stream learning intrusion
   detection with 25 views reached a throughput of 1.19 Gbps.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Viegas, E (Corresponding Author), Pontificia Univ Catolica Parana, Grad Program Comp Sci, Curitiba, Parana, Brazil.
   Viegas, E (Corresponding Author), Univ Lisbon, Fac Ciencias, LaSIGE, Lisbon, Portugal.
   Viegas, Eduardo; Santin, Altair; Abreu, Vilmar, Pontificia Univ Catolica Parana, Grad Program Comp Sci, Curitiba, Parana, Brazil.
   Viegas, Eduardo; Neves, Nuno; Bessani, Alysson, Univ Lisbon, Fac Ciencias, LaSIGE, Lisbon, Portugal.}},
ISSN = {{2334-0983}},
ISBN = {{978-1-5090-5019-2}},
Keywords = {{Stream processing; adversarial machine learning; stream learning;
   intrusion detection}},
Research-Areas = {{Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic; Telecommunications}},
Author-Email = {{eduardo.viegas@ppgia.pucpr.br
   santin@ppgia.pucpr.br
   nfneves@ciencias.ulisboa.pt
   anbessani@ciencias.ulisboa.pt
   vilmar.abreu@ppgia.pucpr.br}},
ResearcherID-Numbers = {{Viegas, Eduardo/AAT-8978-2020
   Santin, Altair/B-2696-2013
   }},
ORCID-Numbers = {{Santin, Altair/0000-0002-2341-2177
   Bessani, Alysson/0000-0002-8386-1628}},
Funding-Acknowledgement = {{Coordination for the Improvement of Higher Education Personnel
   (CAPES)Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior
   (CAPES) {[}99999.008512/2014-0]; FCT through project LaSIGE
   {[}UID/CEC/00408/2013]; FCT through project Resilient Supervision and
   Control in Smart Grids; European CommissionEuropean CommissionEuropean
   Commission Joint Research Centre {[}700692]}},
Funding-Text = {{This work was partially sponsored by Coordination for the Improvement of
   Higher Education Personnel (CAPES), grant 99999.008512/2014-0, by FCT
   through projects LaSIGE (UID/CEC/00408/2013) and Resilient Supervision
   and Control in Smart Grids, and by the European Commission through the
   H2020 grant agreement 700692 (DiSIEM).}},
Number-of-Cited-References = {{14}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BJ8DL}},
Unique-ID = {{WOS:000428054302090}},
DA = {{2021-11-23}},
}

@article{ WOS:000691826200015,
Author = {Chen, Junjun and Wu, Di and Zhao, Ying and Sharma, Nabin and
   Blumenstein, Michael and Yu, Shui},
Title = {{Fooling intrusion detection systems using adversarially autoencoder}},
Journal = {{DIGITAL COMMUNICATIONS AND NETWORKS}},
Year = {{2021}},
Volume = {{7}},
Number = {{3}},
Pages = {{453-460}},
Month = {{AUG}},
Abstract = {{Due to the increasing cyber-attacks, various Intrusion Detection Systems
   (IDSs) have been proposed to identify network anomalies. Most existing
   machine learning-based IDSs learn patterns from the features extracted
   from network traffic flows, and the deep learning-based approaches can
   learn data distribution features from the raw data to differentiate
   normal and anomalous network flows. Although having been used in the
   real world widely, the above methods are vulnerable to some types of
   attacks. In this paper, we propose a novel attack framework,
   Anti-Intrusion Detection AutoEncoder (AIDAE), to generate features to
   disable the IDS. In the proposed framework, an encoder transforms
   features into a latent space, and multiple decoders reconstruct the
   continuous and discrete features, respectively. Additionally, a
   generative adversarial network is used to learn the flexible prior
   distribution of the latent space. The correlation between continuous and
   discrete features can be kept by using the proposed training scheme.
   Experiments conducted on NSL-KDD, UNSW-NB15, and CICIDS2017 datasets
   show that the generated features indeed degrade the detection
   performance of existing IDSs dramatically.}},
Publisher = {{KEAI PUBLISHING LTD}},
Address = {{16 DONGHUANGCHENGGEN NORTH ST, BEIJING, DONGHENG DISTRICT 100717,
   PEOPLES R CHINA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Zhao, Y (Corresponding Author), Beijing Univ Chem Technol, Coll Informat Sci \& Technol, Beijing 100029, Peoples R China.
   Chen, Junjun; Zhao, Ying, Beijing Univ Chem Technol, Coll Informat Sci \& Technol, Beijing 100029, Peoples R China.
   Wu, Di; Sharma, Nabin; Yu, Shui, Univ Technol Sydney, Sch Comp Sci, Ultimo 2007, Australia.
   Wu, Di; Blumenstein, Michael, Univ Technol Sydney, Ctr Artificial Intelligence, Ultimo 2007, Australia.}},
DOI = {{10.1016/j.dcan.2020.11.001}},
ISSN = {{2468-5925}},
EISSN = {{2352-8648}},
Keywords = {{Intrusion detection; Cyber attacks; Autoencoder; Generative adversarial
   networks}},
Keywords-Plus = {{FEATURE-SELECTION; CLASSIFICATION; ATTACKS; THREATS}},
Research-Areas = {{Telecommunications}},
Web-of-Science-Categories  = {{Telecommunications}},
Author-Email = {{zhaoy@mail.buct.edu.cn}},
ORCID-Numbers = {{Yu, Shui/0000-0003-4485-6743}},
Number-of-Cited-References = {{35}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{8}},
Usage-Count-Since-2013 = {{8}},
Journal-ISO = {{Digit. Commun. Netw.}},
Doc-Delivery-Number = {{UK2TA}},
Unique-ID = {{WOS:000691826200015}},
OA = {{Green Published, gold}},
DA = {{2021-11-23}},
}

@article{ WOS:000525389000016,
Author = {Yang, Yanqing and Zheng, Kangfeng and Wu, Bin and Yang, Yixian and Wang,
   Xiujuan},
Title = {{Network Intrusion Detection Based on Supervised Adversarial Variational
   Auto-Encoder With Regularization}},
Journal = {{IEEE ACCESS}},
Year = {{2020}},
Volume = {{8}},
Pages = {{42169-42184}},
Abstract = {{To explore the advantages of adversarial learning and deep learning, we
   propose a novel network intrusion detection model called SAVAER-DNN,
   which can not only detect known and unknown attacks but also improve the
   detection rate of low-frequent attacks. SAVAER is a supervised
   variational auto-encoder with regularization, which uses WGAN-GP instead
   of the vanilla GAN to learn the latent distribution of the original
   data. SAVAER's decoder is used to synthesize samples of low-frequent and
   unknown attacks, thereby increasing the diversity of training samples
   and balancing the training data set. SAVAER's encoder is used to
   initialize the weights of the hidden layers of the DNN and explore
   high-level feature representations of the original samples. The
   benchmark NSL-KDD (KDDTest+), NSL-KDD (KDDTest-21) and UNSW-NB15
   datasets are used to evaluate the performance of the proposed model. The
   experimental results show that the proposed SAVAER-DNN is more suitable
   for data augmentation than the other three well-known data oversampling
   methods. Moreover, the proposed SAVAER-DNN outperforms eight well-known
   classification models in detection performance and is more effective in
   detecting low-frequent and unknown attacks. Furthermore, compared with
   other state-of-the-art intrusion detection models reported in the IDS
   literature, the proposed SAVAER-DNN offers better performance in terms
   of overall accuracy, detection rate, F1 score, and false positive rate.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Zheng, KF (Corresponding Author), Beijing Univ Posts \& Telecommun, Sch Cyberspace Secur, Beijing 100876, Peoples R China.
   Yang, Yanqing; Zheng, Kangfeng; Wu, Bin; Yang, Yixian, Beijing Univ Posts \& Telecommun, Sch Cyberspace Secur, Beijing 100876, Peoples R China.
   Yang, Yanqing, Xinjiang Univ, Coll Informat Sci \& Engn, Urumqi 830046, Peoples R China.
   Yang, Yixian, Guizhou Univ, Guizhou Prov Key Lab Publ Big Data, Guiyang 550025, Peoples R China.
   Wang, Xiujuan, Beijing Univ Technol, Coll Comp Sci, Beijing 100124, Peoples R China.}},
DOI = {{10.1109/ACCESS.2020.2977007}},
ISSN = {{2169-3536}},
Keywords = {{Intrusion detection; Machine learning; Feature extraction; Training;
   Gallium nitride; Neural networks; Intrusion detection; supervised
   adversarial variational auto-encoder; regularization; WGAN-GP; deep
   learning}},
Keywords-Plus = {{DEEP LEARNING APPROACH}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{zkf\_bupt@163.com}},
ResearcherID-Numbers = {{yang, yanqing/C-1542-2019
   }},
ORCID-Numbers = {{yang, yanqing/0000-0001-9993-7757
   Zheng, Kangfeng/0000-0002-1160-5596
   Wu, Bin/0000-0003-0657-3427}},
Funding-Acknowledgement = {{National Key Research and Development Program of China
   {[}2017YFB0802703]; National Natural Science Foundation of ChinaNational
   Natural Science Foundation of China (NSFC) {[}61602052]}},
Funding-Text = {{This work was supported in part by the National Key Research and
   Development Program of China under Grant 2017YFB0802703, and in part by
   the National Natural Science Foundation of China under Grant 61602052.}},
Number-of-Cited-References = {{50}},
Times-Cited = {{19}},
Usage-Count-Last-180-days = {{5}},
Usage-Count-Since-2013 = {{11}},
Journal-ISO = {{IEEE Access}},
Doc-Delivery-Number = {{LC5SC}},
Unique-ID = {{WOS:000525389000016}},
OA = {{gold}},
DA = {{2021-11-23}},
}

@article{ WOS:000445258000001,
Author = {Kwon, Hyun and Kim, Yongchul and Park, Ki-Woong and Yoon, Hyunsoo and
   Choi, Daeseon},
Title = {{Multi-Targeted Adversarial Example in Evasion Attack on Deep Neural
   Network}},
Journal = {{IEEE ACCESS}},
Year = {{2018}},
Volume = {{6}},
Pages = {{46084-46096}},
Abstract = {{Deep neural networks (DNNs) are widely used for image recognition,
   speech recognition, pattern analysis, and intrusion detection. Recently,
   the adversarial example attack, in which the input data are only
   slightly modified, although not an issue for human interpretation, is a
   serious threat to a DNN as an attack as it causes the machine to
   misinterpret the data. The adversarial example attack has been receiving
   considerable attention owing to its potential threat to machine
   learning. It is divided into two categories: targeted adversarial
   example and untargeted adversarial example. The untargeted adversarial
   example happens when machines misclassify an object into an incorrect
   class. In contrast, the targeted adversarial example attack causes
   machines to misinterpret the image as the attacker's desired class.
   Thus, the latter is a more elaborate and powerful attack than the
   former. The existing targeted adversarial example is a single targeted
   attack that allows only one class to be recognized. However, in some
   cases, a multi-targeted adversarial example can be useful for an
   attacker to make multiple models recognize a single original image as
   different classes. For example, an attacker can use a single road sign
   generated by a multi-targeted adversarial example scheme to make model A
   recognize it as a stop sign and model B recognize it as a left turn,
   whereas a human might recognize it as a right turn. Therefore, in this
   paper, we propose a multi-targeted adversarial example that attacks
   multiple models within each target class with a single modified image.
   To produce such examples, we carried out a transformation to maximize
   the probability of different target classes by multiple models. We used
   the MNIST datasets and TensorFlow library for our experiment. The
   experimental results showed that the proposed scheme for generating a
   multi-targeted adversarial example achieved a 100\% attack success rate.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Choi, D (Corresponding Author), Kongju Natl Univ, Dept Med Informat, Gongju 32588, South Korea.
   Kwon, Hyun; Yoon, Hyunsoo, Korea Adv Inst Sci \& Technol, Sch Comp, Daejeon 34141, South Korea.
   Kim, Yongchul, Korea Mil Acad, Dept Elect Engn, Seoul 01819, South Korea.
   Park, Ki-Woong, Sejong Univ, Dept Comp \& Informat Secur, Seoul 05006, South Korea.
   Choi, Daeseon, Kongju Natl Univ, Dept Med Informat, Gongju 32588, South Korea.}},
DOI = {{10.1109/ACCESS.2018.2866197}},
ISSN = {{2169-3536}},
Keywords = {{Deep neural network (DNN); evasion attack; adversarial example; machine
   learning}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{sunchoi@kongju.ac.kr}},
ResearcherID-Numbers = {{Yoon, Hyunsoo/C-2000-2011
   Kwon, Hyun/M-1140-2018
   }},
ORCID-Numbers = {{Kwon, Hyun/0000-0003-1169-9892
   Park, Ki-Woong/0000-0002-3377-223X}},
Funding-Acknowledgement = {{National Research Foundation of Korea - Korea Government (MSIT)
   {[}2016R1A4A1011761, 2017R1A2B4006026]; Institute for Information and
   Communications Technology Promotion - Korea Government (MSIT)
   {[}2016-0-00173]}},
Funding-Text = {{This work was supported in part by the National Research Foundation of
   Korea funded by the Korea Government (MSIT) under Grants
   2016R1A4A1011761 and 2017R1A2B4006026, and in part by the Institute for
   Information and Communications Technology Promotion funded by the Korea
   Government (MSIT) under Grant 2016-0-00173 (Security Technologies for
   Financial Fraud Prevention on Fintech).}},
Number-of-Cited-References = {{44}},
Times-Cited = {{13}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{11}},
Journal-ISO = {{IEEE Access}},
Doc-Delivery-Number = {{GU4MM}},
Unique-ID = {{WOS:000445258000001}},
OA = {{gold}},
DA = {{2021-11-23}},
}

@article{ WOS:000578132600001,
Author = {Qureshi, Ayyaz Ul Haq and Larijani, Hadi and Yousefi, Mehdi and Adeel,
   Ahsan and Mtetwa, Nhamoinesu},
Title = {{An Adversarial Approach for Intrusion Detection Systems Using Jacobian
   Saliency Map Attacks (JSMA) Algorithm}},
Journal = {{COMPUTERS}},
Year = {{2020}},
Volume = {{9}},
Number = {{3}},
Month = {{SEP}},
Abstract = {{In today's digital world, the information systems are revolutionizing
   the way we connect. As the people are trying to adopt and integrate
   intelligent systems into daily lives, the risks around cyberattacks on
   user-specific information have significantly grown. To ensure safe
   communication, the Intrusion Detection Systems (IDS) were developed
   often by using machine learning (ML) algorithms that have the unique
   ability to detect malware against network security violations. Recently,
   it was reported that the IDS are prone to carefully crafted
   perturbations known as adversaries. With the aim to understand the
   impact of such attacks, in this paper, we have proposed a novel random
   neural network-based adversarial intrusion detection system (RNN-ADV).
   The NSL-KDD dataset is utilized for training. For adversarial attack
   crafting, the Jacobian Saliency Map Attack (JSMA) algorithm is used,
   which identifies the feature which can cause maximum change to the
   benign samples with minimum added perturbation. To check the
   effectiveness of the proposed adversarial scheme, the results are
   compared with a deep neural network which indicates that RNN-ADV
   performs better in terms of accuracy, precision, recall, F1 score and
   training epochs.}},
Publisher = {{MDPI}},
Address = {{ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Larijani, H (Corresponding Author), Glasgow Caledonian Univ, Sch Comp Engn \& Built Environm, Glasgow G4 0BA, Lanark, Scotland.
   Qureshi, Ayyaz Ul Haq; Larijani, Hadi; Yousefi, Mehdi, Glasgow Caledonian Univ, Sch Comp Engn \& Built Environm, Glasgow G4 0BA, Lanark, Scotland.
   Adeel, Ahsan, deepCI Org, Edinburgh, Midlothian, Scotland.
   Adeel, Ahsan, Univ Wolverhampton, Sch Math \& Comp Sci, Wolverhampton WV1 1LY, England.
   Mtetwa, Nhamoinesu, Barclays Bank Plc, Glasgow G2 7JT, Lanark, Scotland.}},
DOI = {{10.3390/computers9030058}},
Article-Number = {{58}},
ISSN = {{2073-431X}},
Keywords = {{intrusion detection; adversarial attacks; JSMA; NSL-KDD; network
   security}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Interdisciplinary Applications}},
Author-Email = {{Ayyaz.qureshi@gcu.ac.uk
   H.Larijani@gcu.ac.uk
   Mehdi.Yousefi@gcu.ac.uk
   ahsan.adeel@deepci.org
   nhamo.mtetwa@barclays.com}},
ORCID-Numbers = {{Larijani, Hadi/0000-0002-6826-207X}},
Number-of-Cited-References = {{24}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{Computers}},
Doc-Delivery-Number = {{OA9XR}},
Unique-ID = {{WOS:000578132600001}},
OA = {{Green Accepted, gold}},
DA = {{2021-11-23}},
}

@article{ WOS:000591261400001,
Author = {Kwon, Hyun and Kim, Yongchul and Yoon, Hyunsoo and Choi, Daeseon},
Title = {{Classification score approach for detecting adversarial example in deep
   neural network}},
Journal = {{MULTIMEDIA TOOLS AND APPLICATIONS}},
Year = {{2021}},
Volume = {{80}},
Number = {{7}},
Pages = {{10339-10360}},
Month = {{MAR}},
Abstract = {{Deep neural networks (DNNs) provide superior performance on machine
   learning tasks such as image recognition, speech recognition, pattern
   analysis, and intrusion detection. However, an adversarial example,
   created by adding a little noise to an original sample, can cause
   misclassification by a DNN. This is a serious threat to the DNN because
   the added noise is not detected by the human eye. For example, if an
   attacker modifies a right-turn sign so that it misleads to the left,
   autonomous vehicles with the DNN will incorrectly classify the modified
   sign as pointing to the left, but a person will correctly classify the
   modified sign as pointing to the right. Studies are under way to defend
   against such adversarial examples. The existing method of defense
   against adversarial examples requires an additional process such as
   changing the classifier or modifying input data. In this paper, we
   propose a new method for detecting adversarial examples that does not
   invoke any additional process. The proposed scheme can detect
   adversarial examples by using a pattern feature of the classification
   scores of adversarial examples. We used MNIST and CIFAR10 as
   experimental datasets and Tensorflow as a machine learning library. The
   experimental results show that the proposed method can detect
   adversarial examples with success rates: 99.05\% and 99.9\% for the
   untargeted and targeted cases in MNIST, respectively, and 94.7\% and
   95.8\% for the untargeted and targeted cases in CIFAR10, respectively.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Choi, D (Corresponding Author), Soongsil Univ, Dept Software, 369 Sangdo Ro, Seoul, South Korea.
   Kwon, Hyun; Kim, Yongchul, Korea Mil Acad, Dept Elect Engn, 574 Hwarang Ro, Seoul 01819, South Korea.
   Yoon, Hyunsoo, Korea Adv Inst Sci \& Technol KAIST, Sch Comp, 291 Daehak Ro, Daejeon 34141, South Korea.
   Choi, Daeseon, Soongsil Univ, Dept Software, 369 Sangdo Ro, Seoul, South Korea.}},
DOI = {{10.1007/s11042-020-09167-z}},
Early Access Date = {{NOV 2020}},
ISSN = {{1380-7501}},
EISSN = {{1573-7721}},
Keywords = {{Deep neural network; Evasion attack; Adversarial example; Machine
   learning; Detection method; Classification score}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory \& Methods; Engineering,
   Electrical \& Electronic}},
Author-Email = {{hkwon.cs@gmail.com
   sunchoi@ssu.ac.kr}},
ResearcherID-Numbers = {{Kwon, Hyun/M-1140-2018}},
ORCID-Numbers = {{Kwon, Hyun/0000-0003-1169-9892}},
Funding-Acknowledgement = {{Hwarang-Dae Research Institute of Korea Military Academy; National
   Research Foundation of Korea (NRF) - Korea government (MEST)Ministry of
   Education, Science and Technology, Republic of KoreaNational Research
   Foundation of KoreaKorean Government {[}2020R1A2C1014813]}},
Funding-Text = {{This work was supported by the Hwarang-Dae Research Institute of Korea
   Military Academy and the National Research Foundation of Korea (NRF)
   grant funded by the Korea government (MEST) (No.2020R1A2C1014813).}},
Number-of-Cited-References = {{33}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{7}},
Journal-ISO = {{Multimed. Tools Appl.}},
Doc-Delivery-Number = {{RC8BM}},
Unique-ID = {{WOS:000591261400001}},
OA = {{hybrid}},
DA = {{2021-11-23}},
}

@article{ WOS:000665207100011,
Author = {Qiu, Han and Dong, Tian and Zhang, Tianwei and Lu, Jialiang and Memmi,
   Gerard and Qiu, Meikang},
Title = {{Adversarial Attacks Against Network Intrusion Detection in IoT Systems}},
Journal = {{IEEE INTERNET OF THINGS JOURNAL}},
Year = {{2021}},
Volume = {{8}},
Number = {{13}},
Pages = {{10327-10335}},
Month = {{JUL 1}},
Abstract = {{Deep learning (DL) has gained popularity in network intrusion detection,
   due to its strong capability of recognizing subtle differences between
   normal and malicious network activities. Although a variety of methods
   have been designed to leverage DL models for security protection,
   whether these systems are vulnerable to adversarial examples (AEs) is
   unknown. In this article, we design a novel adversarial attack against
   DL-based network intrusion detection systems (NIDSs) in the
   Internet-of-Things environment, with only black-box accesses to the DL
   model in such NIDS. We introduce two techniques: 1) model extraction is
   adopted to replicate the black-box model with a small amount of training
   data and 2) a saliency map is then used to disclose the impact of each
   packet attribute on the detection results, and the most critical
   features. This enables us to efficiently generate AEs using conventional
   methods. With these tehniques, we successfully compromise one
   state-of-the-art NIDS, Kitsune: the adversary only needs to modify less
   than 0.005\% of bytes in the malicious packets to achieve an average
   94.31\% attack success rate.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Qiu, MK (Corresponding Author), Texas A\&M Univ, Dept Comp Sci, Commerce, TX 75428 USA.
   Qiu, Han; Memmi, Gerard, Telecom Paris, LTCI, F-91120 Palaiseau, France.
   Dong, Tian; Lu, Jialiang, Shanghai Jiao Tong Univ, SPEIT, Shanghai 200240, Peoples R China.
   Zhang, Tianwei, Nanyang Technol Univ, Sch Comp Sci \& Engn, Singapore 639798, Singapore.
   Qiu, Meikang, Texas A\&M Univ, Dept Comp Sci, Commerce, TX 75428 USA.}},
DOI = {{10.1109/JIOT.2020.3048038}},
ISSN = {{2327-4662}},
Keywords = {{Feature extraction; Computational modeling; Internet of Things;
   Training; Perturbation methods; Mathematical model; Detectors;
   Adversarial examples (AEs); deep learning (DL); Internet of Things
   (IoT); network intrusion detection}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{han.qiu@telecom-paris.fr
   dongtian9702@gmail.com
   tianwei.zhang@ntu.edu.sg
   jialiang.lu@sjtu.edu.cn
   gerard.memmi@telecom-paris.fr
   meikang.qiu@tamuc.edu}},
ORCID-Numbers = {{Qiu, Meikang/0000-0002-1004-0140
   Qiu, Han/0000-0003-2678-8070}},
Number-of-Cited-References = {{30}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{4}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{IEEE Internet Things J.}},
Doc-Delivery-Number = {{SX4WM}},
Unique-ID = {{WOS:000665207100011}},
DA = {{2021-11-23}},
}

@article{ WOS:000504781200012,
Author = {Maestre Vidal, Jorge and Sotelo Monge, Marco Antonio and Martinez
   Monterrubio, Sergio Mauricio},
Title = {{EsPADA: Enhanced Payload Analyzer for malware Detection robust against
   Adversarial threats}},
Journal = {{FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE}},
Year = {{2020}},
Volume = {{104}},
Pages = {{159-173}},
Month = {{MAR}},
Abstract = {{The emergent communication technologies landscape has consolidated the
   anomaly-based intrusion detection paradigm as one of the most prominent
   solutions able to discover unprecedented malicious traits. It relied on
   building models of the normal/legitimate activities registered at the
   protected systems, from them analyzing the incoming observations looking
   for significant discordances that may reveal misbehaviors. But in the
   last years, the adversarial machine learning paradigm introduced
   never-seen-before evasion procedures able to jeopardize the traditional
   anomaly-based methods, thus entailing one of the major emerging
   challenges in the cybersecurity landscape. With the aim on contributing
   to their adaptation against adversarial threats, this paper presents
   EsPADA (Enhanced Payload Analyzer for malware Detection robust against
   Adversarial threats), a novel approach built on the grounds of the PAYL
   sensor family. At the SPARTA Training stage, both normal and adversarial
   models are constructed according to features extracted by N-gram, which
   are stored within Counting Bloom Filters (CBF). In this way it is
   possible to take advantage of both binary-based and spectral-based
   traffic modeling procedures for malware detection. At Detection stage,
   the payloads to be analyzed are collected from the protected environment
   and compared with the usage models previously built at Training. This
   leads to calculate different scores that allow to discriminate their
   nature (normal or suspicious) and to assess the labeling coherency, the
   latest studied for estimating the likelihood of the payload disguising
   mimicry attacks. The effectiveness of EsPADA was demonstrated on the
   public datasets DARPA'99 and UCM 2011 by achieving promising
   preliminarily results. (C) 2019 Elsevier B.V. All rights reserved.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Vidal, JM (Corresponding Author), Indra, Digital Labs, Ave Bruselas 35, Madrid 28108, Spain.
   Maestre Vidal, Jorge, Indra, Digital Labs, Ave Bruselas 35, Madrid 28108, Spain.
   Sotelo Monge, Marco Antonio, Univ Lima, Ave Javier Prado Este 4600, Lima, Peru.
   Maestre Vidal, Jorge; Martinez Monterrubio, Sergio Mauricio, Univ Complutense Madrid, Sch Comp Sci, Dept Software Engn \& Artificial Intelligence DISI, Calle Prof Jose Garcia Santesmases 9,Ciudad Univ, E-28040 Madrid, Spain.}},
DOI = {{10.1016/j.future.2019.10.022}},
ISSN = {{0167-739X}},
EISSN = {{1872-7115}},
Keywords = {{Adversarial machine learning; Anomaly recognition; Communication
   networks; Intrusion detection; Malware}},
Keywords-Plus = {{INTRUSION; CLASSIFIER; SECURITY; ATTACKS; ANAGRAM; SYSTEM}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods}},
Author-Email = {{jmaestre@ucm.es}},
ResearcherID-Numbers = {{Monterrubio, Sergio Mauricio Martinez/AAC-6791-2019
   }},
ORCID-Numbers = {{Monterrubio, Sergio Mauricio Martinez/0000-0002-1520-1249
   Sotelo Monge, Marco Antonio/0000-0001-6392-0216}},
Funding-Acknowledgement = {{European CommissionEuropean CommissionEuropean Commission Joint Research
   Centre {[}830892, H2020-SU-ICT-03-2018/830892]; Secretariat of
   Education, Technology and Innovation of Mexico City (SECTEI)}},
Funding-Text = {{This work is funded by the European Commission Horizon 2020 Programme
   under grant agreement number 830892, as part of the project
   H2020-SU-ICT-03-2018/830892 SPARTA: Special projects for advanced
   research and technology in Europe; Thanks to the Secretariat of
   Education, Technology and Innovation of Mexico City (SECTEI) for their
   support with the third author's postdoctoral fellowship during his
   studies at the Cornplutense University of Madrid.}},
Number-of-Cited-References = {{52}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{18}},
Journal-ISO = {{Futur. Gener. Comp. Syst.}},
Doc-Delivery-Number = {{JZ0FV}},
Unique-ID = {{WOS:000504781200012}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000552238606108,
Author = {Ibitoye, Olakunle and Shafiq, Omair and Matrawy, Ashraf},
Book-Group-Author = {{IEEE}},
Title = {{Analyzing Adversarial Attacks Against Deep Learning for Intrusion
   Detection in IoT Networks}},
Booktitle = {{2019 IEEE GLOBAL COMMUNICATIONS CONFERENCE (GLOBECOM)}},
Series = {{IEEE Global Communications Conference}},
Year = {{2019}},
Note = {{IEEE Global Communications Conference (GLOBECOM), Waikoloa, HI, DEC
   09-13, 2019}},
Organization = {{IEEE; Huawei; Intel; ZTE; Google; Qualcomm; Natl Instruments; IEEE
   Commun Soc}},
Abstract = {{Adversarial attacks have been widely studied in the field of computer
   vision but their impact on network security applications remains an area
   of open research. As IoT, 5G and AI continue to converge to realize the
   promise of the fourth industrial revolution (Industry 4.0), security
   incidents and events on IoT networks have increased. Deep learning
   techniques are being applied to detect and mitigate many of such
   security threats against IoT networks. Feed-forward Neural Networks
   (FNN) have been widely used for classifying intrusion attacks in IoT
   networks. In this paper, we consider a variant of the FNN known as the
   Self-normalizing Neural Network (SNN) and compare its performance with
   the FNN for classifying intrusion attacks in an IoT network. Our
   analysis is performed using the BoT-IoT dataset from the Cyber Range Lab
   of the center of UNSW Canberra Cyber. In our experimental results, the
   FNN outperforms the SNN for intrusion detection in IoT networks based on
   multiple performance metrics such as accuracy, precision, and recall as
   well as multi-classification metrics such as Cohen Cappas score.
   However, when tested for adversarial robustness, the SNN demonstrates
   better resilience against the adversarial samples from the IoT dataset,
   presenting a promising future in the quest for safer and more secure
   deep learning in IoT networks.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Ibitoye, O (Corresponding Author), Carleton Univ, Sch Informat Technol, Ottawa, ON, Canada.
   Ibitoye, Olakunle; Shafiq, Omair; Matrawy, Ashraf, Carleton Univ, Sch Informat Technol, Ottawa, ON, Canada.}},
ISSN = {{2334-0983}},
ISBN = {{978-1-7281-0962-6}},
Keywords = {{Intrusion Detection; Adversarial samples; Feed-forward Neural Networks
   (FNN); Resilience; Self-normalizing Neural Networks (SNN); Internet of
   things (IoT)}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{Kunle.Ibitoye@carleton.ca
   Omair.Shafiq@carleton.ca
   Ashraf.Matrawy@carleton.ca}},
Funding-Acknowledgement = {{Natural Sciences and Engineering Research Council of Canada (NSERC)
   through the NSERC Discovery Grant programNatural Sciences and
   Engineering Research Council of Canada (NSERC)}},
Funding-Text = {{This work was supported by the Natural Sciences and Engineering Research
   Council of Canada (NSERC) through the NSERC Discovery Grant program.}},
Number-of-Cited-References = {{17}},
Times-Cited = {{9}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BP4GG}},
Unique-ID = {{WOS:000552238606108}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000626021407037,
Author = {Zhang, Yongxuan and Yan, Jun},
Book-Group-Author = {{IEEE}},
Title = {{Semi-Supervised Domain-Adversarial Training for Intrusion Detection
   against False Data Injection in the Smart Grid}},
Booktitle = {{2020 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)}},
Series = {{IEEE International Joint Conference on Neural Networks (IJCNN)}},
Year = {{2020}},
Note = {{International Joint Conference on Neural Networks (IJCNN) held as part
   of the IEEE World Congress on Computational Intelligence (IEEE WCCI),
   ELECTR NETWORK, JUL 19-24, 2020}},
Organization = {{IEEE; IEEE Computat Intelligence Soc; Int Neural Network Soc}},
Abstract = {{The smart grid faces with increasingly sophisticated cyber-physical
   threats, against which machine learning (ML)-based intrusion detection
   systems have become a powerful and promising solution to smart grid
   security monitoring. However, many ML algorithms presume that training
   and testing data follow the same or similar data distributions, which
   may not hold in the dynamic time-varying systems like the smart grid. As
   operating points may change dramatically over time, the resulting data
   distribution shifts could lead to degraded detection performance and
   delayed incidence responses. To address this challenge, this paper
   proposes a semi-supervised framework based on domain-adversarial
   training to transfer the knowledge of known attack incidences to detect
   returning threats at different hours and load patterns. Using normal
   operation data of the ISO New England grids, the proposed framework
   leverages adversarial training to adapt learned models against new
   attacks launched at different times of the day. Effectiveness of the
   proposed detection framework is evaluated against the well-studied false
   data injection attacks synthesized on the IEEE 30-bus system, and the
   results demonstrated the superiority of the framework against persistent
   threats recurring in the highly dynamic smart grid.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Zhang, YX (Corresponding Author), Concordia Univ, Dept Comp Sci \& Software Engn CSSE, Montreal, PQ H3G 1M8, Canada.
   Zhang, Yongxuan, Concordia Univ, Dept Comp Sci \& Software Engn CSSE, Montreal, PQ H3G 1M8, Canada.
   Yan, Jun, Concordia Univ, Concordia Inst Informat Syst Engn CIISE, Montreal, PQ H3G 1M8, Canada.}},
ISSN = {{2161-4393}},
ISBN = {{978-1-7281-6926-2}},
Keywords = {{Adversarial training; false data injection; intrusion detection; smart
   grid security; transfer learning; domain adaptation}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Hardware \&
   Architecture}},
Author-Email = {{z\_yongxu@encs.concordia.ca
   jun.yan@concordia.ca}},
Funding-Acknowledgement = {{Natural Sciences and Engineering Research Council of Canada
   (NSERC)Natural Sciences and Engineering Research Council of Canada
   (NSERC) {[}RGPIN-2018-06724, DGECR-2018-00022]; Fonds de Recherche du
   Quebec-Nature et Technologies (FRQNT) {[}2019-NC-254971]}},
Funding-Text = {{This research is supported by the Natural Sciences and Engineering
   Research Council of Canada (NSERC) under grants RGPIN-2018-06724 and
   DGECR-2018-00022 and the Fonds de Recherche du Quebec-Nature et
   Technologies (FRQNT) under grant 2019-NC-254971.}},
Number-of-Cited-References = {{37}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BQ9MM}},
Unique-ID = {{WOS:000626021407037}},
DA = {{2021-11-23}},
}

@article{ WOS:000525560600001,
Author = {Martins, Nuno and Cruz, Jose Magalhaes and Cruz, Tiago and Abreu, Pedro
   Henriques},
Title = {{Adversarial Machine Learning Applied to Intrusion and Malware Scenarios:
   A Systematic Review}},
Journal = {{IEEE ACCESS}},
Year = {{2020}},
Volume = {{8}},
Pages = {{35403-35419}},
Abstract = {{Cyber-security is the practice of protecting computing systems and
   networks from digital attacks, which are a rising concern in the
   Information Age. With the growing pace at which new attacks are
   developed, conventional signature based attack detection methods are
   often not enough, and machine learning poses as a potential solution.
   Adversarial machine learning is a research area that examines both the
   generation and detection of adversarial examples, which are inputs
   specially crafted to deceive classifiers, and has been extensively
   studied specifically in the area of image recognition, where minor
   modifications are performed on images that cause a classifier to produce
   incorrect predictions. However, in other fields, such as intrusion and
   malware detection, the exploration of such methods is still growing. The
   aim of this survey is to explore works that apply adversarial machine
   learning concepts to intrusion and malware detection scenarios. We
   concluded that a wide variety of attacks were tested and proven
   effective in malware and intrusion detection, although their
   practicality was not tested in intrusion scenarios. Adversarial defenses
   were substantially less explored, although their effectiveness was also
   proven at resisting adversarial attacks. We also concluded that,
   contrarily to malware scenarios, the variety of datasets in intrusion
   scenarios is still very small, with the most used dataset being greatly
   outdated.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Review}},
Language = {{English}},
Affiliation = {{Martins, N (Corresponding Author), Univ Porto, Fac Engn, P-4200465 Porto, Portugal.
   Martins, Nuno; Cruz, Jose Magalhaes, Univ Porto, Fac Engn, P-4200465 Porto, Portugal.
   Cruz, Tiago; Abreu, Pedro Henriques, Univ Coimbra, Fac Sci \& Technol, P-3030290 Coimbra, Portugal.}},
DOI = {{10.1109/ACCESS.2020.2974752}},
ISSN = {{2169-3536}},
Keywords = {{Cybersecurity; adversarial machine learning; intrusion detection;
   malware detection}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{up201405079@fe.up.pt}},
ResearcherID-Numbers = {{Cruz, Tiago/M-5054-2017
   Abreu, Pedro Henriques/ABE-1698-2020
   }},
ORCID-Numbers = {{Cruz, Tiago/0000-0001-9278-6503
   Abreu, Pedro Henriques/0000-0002-9278-8194
   Cruz, Jose/0000-0003-4516-6752}},
Number-of-Cited-References = {{63}},
Times-Cited = {{15}},
Usage-Count-Last-180-days = {{10}},
Usage-Count-Since-2013 = {{16}},
Journal-ISO = {{IEEE Access}},
Doc-Delivery-Number = {{LC8CO}},
Unique-ID = {{WOS:000525560600001}},
OA = {{gold, Green Submitted}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000675595400035,
Author = {Alrawashdeh, Khaled and Goldsmith, Stephen},
Book-Group-Author = {{IEEE}},
Title = {{Optimizing Deep Learning Based Intrusion Detection Systems Defense
   Against White-Box and Backdoor Adversarial Attacks Through a Genetic
   Algorithm}},
Booktitle = {{2020 IEEE APPLIED IMAGERY PATTERN RECOGNITION WORKSHOP (AIPR): TRUSTED
   COMPUTING, PRIVACY, AND SECURING MULTIMEDIA}},
Series = {{IEEE Applied Imagery Pattern Recognition Workshop}},
Year = {{2020}},
Note = {{IEEE Applied Imagery Pattern Recognition Workshop (AIPR), ELECTR
   NETWORK, OCT 13-15, 2020}},
Organization = {{IEEE}},
Abstract = {{Recent years have witnessed rapid progress and significant success in
   the use of deep learning neural networks (DLNNs) in a wide range of
   applications. Recently, DLNN has been integrated with intrusion
   detection system (IDS) to enhance network security to detect zero-day
   attacks. However, DLNNs themselves have been recently found vulnerable
   to attacks called adversarial examples and backdoor attacks for image
   recognition applications. In this work, we present an effective defense
   method for DLNN based IDS by using Genetic Algorithm (GA) to optimize
   the generation of triggers neurons selected based on their response to
   the features to produce the output. We embed the GA-Trigger-Detection
   neurons within the model to detect and prevent white-box advertorial
   examples and backdoor attacks against two DLNNs based IDS: Deep Belief
   Network (DBN) and Stacked Sparse AutoEncoder Based Extreme Learning
   Machine (SSAELM). We implement two whitebox adversarial examples and
   backdoor attacks from prior work and use them to investigate the
   proposed defense method. We show that the defense method is sufficient
   to defend against sophisticated We then show that it successfully
   weakens backdoor attacks on the two DNN architectures using two
   benchmark datasets: KDDCUP'99 and Kyoto. Our work provides an important
   step toward defenses against white-box advertorial examples and backdoor
   attacks in DLNNs based IDS.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Alrawashdeh, K (Corresponding Author), Avila Univ, Dept Comp Sci \& Cybersecur, Kansas City, MO 64145 USA.
   Alrawashdeh, Khaled; Goldsmith, Stephen, Avila Univ, Dept Comp Sci \& Cybersecur, Kansas City, MO 64145 USA.}},
DOI = {{10.1109/AIPR50011.2020.9425293}},
ISSN = {{1550-5219}},
ISBN = {{978-1-7281-8243-8}},
Keywords = {{Deep Learning; Neural Network; Intrusion Detection System; Adversarial
   Examples; Cyber security}},
Keywords-Plus = {{MACHINE}},
Research-Areas = {{Computer Science; Engineering; Imaging Science \& Photographic
   Technology}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical \& Electronic; Imaging Science \&
   Photographic Technology}},
Author-Email = {{khaled.alrawashdeh@avila.edu
   goldsmith319053@avila.edu}},
ResearcherID-Numbers = {{Alrawashdeh, Khaled/AAS-6507-2021}},
ORCID-Numbers = {{Alrawashdeh, Khaled/0000-0002-3041-8876}},
Number-of-Cited-References = {{36}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BR9HA}},
Unique-ID = {{WOS:000675595400035}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000553441500171,
Author = {Peng, Xiao and Huang, Weiqing and Shi, Zhixin},
Book-Group-Author = {{IEEE}},
Title = {{Adversarial Attack against DoS Intrusion Detection: An Improved
   Boundary-Based Method}},
Booktitle = {{2019 IEEE 31ST INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL
   INTELLIGENCE (ICTAI 2019)}},
Series = {{Proceedings-International Conference on Tools With Artificial
   Intelligence}},
Year = {{2019}},
Pages = {{1288-1295}},
Note = {{31st IEEE International Conference on Tools with Artificial Intelligence
   (ICTAI), Portland, OR, NOV 04-06, 2019}},
Organization = {{IEEE; IEEE Comp Soc}},
Abstract = {{Denial of Service (DoS) attacks pose serious threats to network
   security. With the rapid development of machine learning technologies,
   artificial neural network (ANN) has been used to classify DoS attacks.
   However, ANN models are vulnerable to adversarial samples: inputs that
   are specially crafted to yield incorrect outputs. In this work, we
   explore a kind of DoS adversarial attacks which aim to bypass ANN-based
   DoS intrusion detection systems. By analyzing features of DoS samples,
   we propose an improved boundary-based method to craft adversarial DoS
   samples. The key idea is to optimize a Mahalanobis distance by
   perturbing continuous features and discrete features of DoS samples
   respectively. We experimentally study the effectiveness of our method in
   two trained ANN classifiers on KDDcup99 dataset and CICIDS2017 dataset.
   Results show that our method can craft adversarial DoS samples with
   limited queries.}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Shi, ZX (Corresponding Author), Chinese Acad Sci, Inst Informat Engn, Beijing, Peoples R China.
   Peng, Xiao; Huang, Weiqing; Shi, Zhixin, Chinese Acad Sci, Inst Informat Engn, Beijing, Peoples R China.
   Peng, Xiao; Huang, Weiqing, Univ Chinese Acad Sci, Sch Cyber Secur, Beijing, Peoples R China.}},
DOI = {{10.1109/ICTAI.2019.00179}},
ISSN = {{1082-3409}},
ISBN = {{978-1-7281-3798-8}},
Keywords = {{Adversarial samples; DoS detection; ANN; Boundary-based attack;
   Optimization; Mahalanobis distance}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods}},
Author-Email = {{pengxiao@iie.ac.cn
   huangweiqing@iie.ac.cn
   shizhixin@iie.ac.cn}},
Number-of-Cited-References = {{30}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BP4NY}},
Unique-ID = {{WOS:000553441500171}},
DA = {{2021-11-23}},
}

@article{ WOS:000668405700002,
Author = {Fu, Xingbing and Zhou, Nan and Jiao, Libin and Li, Haifeng and Zhang,
   Jianwu},
Title = {{The robust deep learning-based schemes for intrusion detection in
   Internet of Things environments}},
Journal = {{ANNALS OF TELECOMMUNICATIONS}},
Year = {{2021}},
Volume = {{76}},
Number = {{5-6, SI}},
Pages = {{273-285}},
Month = {{JUN}},
Abstract = {{With the advent of the Internet of Things (IoT), network attacks have
   become more diverse and intelligent. In order to ensure the security of
   the network, Intrusion Detection system (IDS) has become very important.
   However, when met with the adversarial examples, IDS has itself become
   no longer secure, and the attackers can increase the success rate of
   attacks by misleading IDS. Therefore, it is necessary to improve the
   robustness of the IDS. In this paper, we employ Fast Gradient Sign
   Method (FGSM) to generate adversarial examples to test the robustness of
   three intrusion detection models based on convolutional neural network
   (CNN), long short-term memory (LSTM), and gated recurrent unit (GRU). We
   employ three training methods: the first is to train the models with
   normal examples, the second is to train the models directly with
   adversarial examples, and the last is to pretrain the models with normal
   examples, and then employ adversarial examples to train the models. We
   evaluate the performance of the three models under different training
   methods, and find that under normal training method, CNN is the most
   robust model to adversarial examples. After adversarial training, the
   robustness of GRU and LSTM to adversarial examples has greatly been
   improved.}},
Publisher = {{SPRINGER INTERNATIONAL PUBLISHING AG}},
Address = {{GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Fu, XB (Corresponding Author), Hangzhou Dianzi Univ, Sch Cyberspace, Hangzhou 310018, Peoples R China.
   Fu, XB (Corresponding Author), Sci \& Technol Commun Networks Lab, Shijiazhuang, Hebei, Peoples R China.
   Fu, Xingbing; Zhou, Nan, Hangzhou Dianzi Univ, Sch Cyberspace, Hangzhou 310018, Peoples R China.
   Fu, Xingbing; Jiao, Libin, Sci \& Technol Commun Networks Lab, Shijiazhuang, Hebei, Peoples R China.
   Li, Haifeng, Dalian Univ Technol, Sch Software, Dalian 116024, Peoples R China.
   Zhang, Jianwu, Hangzhou Dianzi Univ, Sch Commun Engn, Hangzhou 310018, Peoples R China.}},
DOI = {{10.1007/s12243-021-00854-y}},
Early Access Date = {{JUN 2021}},
ISSN = {{0003-4347}},
EISSN = {{1958-9395}},
Keywords = {{Adversarial examples; Adversary training; CNN; FGSM; LSTM; GRU}},
Research-Areas = {{Telecommunications}},
Web-of-Science-Categories  = {{Telecommunications}},
Author-Email = {{uestcfuxb@126.com}},
Number-of-Cited-References = {{23}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{Ann. Telecommun.}},
Doc-Delivery-Number = {{TC9GH}},
Unique-ID = {{WOS:000668405700002}},
DA = {{2021-11-23}},
}

@article{ WOS:000588612300002,
Author = {Zhou, Mu and Li, Yaoping and Yuan, Hui and Wang, Jiacheng and Pu,
   Qiaolin},
Title = {{Indoor WLAN Personnel Intrusion Detection Using Transfer Learning-Aided
   Generative Adversarial Network with Light-Loaded Database}},
Journal = {{MOBILE NETWORKS \& APPLICATIONS}},
Year = {{2021}},
Volume = {{26}},
Number = {{3, SI}},
Pages = {{1024-1042}},
Month = {{JUN}},
Abstract = {{The Internet of Everything (IoE) provides a platform that allows devices
   to be remotely connected, sensed, and controlled across the network
   infrastructure. The smart home in the era of the IoE is born on the
   basis of the high integration of emerging communication technologies
   such as big data, sensors, and machine learning. In this paper, we focus
   on wireless detection technologies using smartphones and computers in
   smart homes. Among them, the indoor Wireless Local Area Network (WLAN)
   personnel intrusion detection technology based on the database
   construction has become one of the comprehensive detection technologies
   by advantages of the convenient accessibility of the WLAN signal and
   minimal hardware requirement. However, the considerable labor and time
   cost involved in the database construction affects the popularity and
   application of database-based intrusion detection systems. To cope with
   this problem, we propose a new indoor WLAN personnel intrusion detection
   approach with the reduced overhead of the database construction.
   Specifically, first of all, the offline database is extended by fake
   Received Signal Strength (RSS) data, which are generated by the
   Generative Adversarial Network (GAN) based supervised learning from
   actual labeled RSS data. Second, the difference between the extended
   database and online RSS data caused by the time-variant environment
   noise is reduced by minimizing the Maximum Mean Discrepancy (MMD)
   between marginal distributions of RSS data through the transfer
   learning. Finally, the intrusion detection is achieved by classifying
   online RSS data with classifiers trained from the extended database.
   Furthermore, experimental results show that the proposed approach can
   not only perform well in reducing the database overhead and the
   difference of data in source and target domains, which are corresponding
   to the same environment state but also detect environment states with
   satisfactory accuracy.}},
Publisher = {{SPRINGER}},
Address = {{ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Zhou, M (Corresponding Author), Chongqing Univ Posts \& Telecommun, Sch Commun \& Informat Engn, 2 Chongwen Rd, Chongqing 400065, Nanan District, Peoples R China.
   Zhou, Mu; Li, Yaoping; Yuan, Hui; Wang, Jiacheng, Chongqing Univ Posts \& Telecommun, Sch Commun \& Informat Engn, 2 Chongwen Rd, Chongqing 400065, Nanan District, Peoples R China.
   Pu, Qiaolin, Hong Kong Baptist Univ, Hong Kong 999077, Peoples R China.}},
DOI = {{10.1007/s11036-020-01663-8}},
Early Access Date = {{NOV 2020}},
ISSN = {{1383-469X}},
EISSN = {{1572-8153}},
Keywords = {{Personnel intrusion detection; Database extension; Generative
   adversarial network; Transfer learning; Wireless local area network}},
Research-Areas = {{Computer Science; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Hardware \& Architecture; Computer Science,
   Information Systems; Telecommunications}},
Author-Email = {{zhoumu@cqupt.edu.cn}},
Funding-Acknowledgement = {{National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}61771083, 61704015]; Program for
   Changjiang Scholars and Innovative Research Team in UniversityProgram
   for Changjiang Scholars \& Innovative Research Team in University
   (PCSIRT) {[}IRT1299]; Postgraduate Scientific Research and Innovation
   Project of Chongqing {[}CYS18240]}},
Funding-Text = {{This work is supported in part by the National Natural Science
   Foundation of China (61771083, 61704015), Program for Changjiang
   Scholars and Innovative Research Team in University (IRT1299), and
   Postgraduate Scientific Research and Innovation Project of Chongqing
   (CYS18240).}},
Number-of-Cited-References = {{42}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{7}},
Usage-Count-Since-2013 = {{13}},
Journal-ISO = {{Mobile Netw. Appl.}},
Doc-Delivery-Number = {{TP7EK}},
Unique-ID = {{WOS:000588612300002}},
DA = {{2021-11-23}},
}

@article{ WOS:000471293100006,
Author = {Handa, Anand and Sharma, Ashu and Shukla, Sandeep K.},
Title = {{Machine learning in cybersecurity: A review}},
Journal = {{WILEY INTERDISCIPLINARY REVIEWS-DATA MINING AND KNOWLEDGE DISCOVERY}},
Year = {{2019}},
Volume = {{9}},
Number = {{4}},
Month = {{JUL}},
Abstract = {{Machine learning technology has become mainstream in a large number of
   domains, and cybersecurity applications of machine learning techniques
   are plenty. Examples include malware analysis, especially for zero-day
   malware detection, threat analysis, anomaly based intrusion detection of
   prevalent attacks on critical infrastructures, and many others. Due to
   the ineffectiveness of signature-based methods in detecting zero day
   attacks or even slight variants of known attacks, machine learning-based
   detection is being used by researchers in many cybersecurity products.
   In this review, we discuss several areas of cybersecurity where machine
   learning is used as a tool. We also provide a few glimpses of
   adversarial attacks on machine learning algorithms to manipulate
   training and test data of classifiers, to render such tools ineffective.
   This article is categorized under: Application Areas > Science and
   Technology Technologies > Machine Learning Technologies > Classification
   Application Areas > Data Mining Software Tools}},
Publisher = {{WILEY PERIODICALS, INC}},
Address = {{ONE MONTGOMERY ST, SUITE 1200, SAN FRANCISCO, CA 94104 USA}},
Type = {{Review}},
Language = {{English}},
Affiliation = {{Shukla, SK (Corresponding Author), Indian Inst Technol, Interdisciplinary Ctr Cyber Secur \& Cyber Def Cri, Dept Comp Sci \& Engn, Kanpur, Uttar Pradesh, India.
   Handa, Anand; Sharma, Ashu; Shukla, Sandeep K., Indian Inst Technol, Interdisciplinary Ctr Cyber Secur \& Cyber Def Cri, Dept Comp Sci \& Engn, Kanpur, Uttar Pradesh, India.}},
DOI = {{10.1002/widm.1306}},
Article-Number = {{e1306}},
ISSN = {{1942-4787}},
EISSN = {{1942-4795}},
Keywords = {{adversarial learning; intrusion detection; machine learning; malware
   analysis}},
Keywords-Plus = {{MALWARE; CLASSIFICATION; SECURITY}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods}},
Author-Email = {{sandeeps@cse.iitk.ac.in}},
Number-of-Cited-References = {{55}},
Times-Cited = {{15}},
Usage-Count-Last-180-days = {{18}},
Usage-Count-Since-2013 = {{59}},
Journal-ISO = {{Wiley Interdiscip. Rev.-Data Mining Knowl. Discov.}},
Doc-Delivery-Number = {{IC9HP}},
Unique-ID = {{WOS:000471293100006}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000626021408008,
Author = {Qureshi, Ayyaz-Ul-Haq and Larijani, Hadi and Mtetwa, Nhamoinesu and
   Yousefi, Mehdi and Javed, Abbas},
Book-Group-Author = {{IEEE}},
Title = {{An Adversarial Attack Detection Paradigm With Swarm Optimization}},
Booktitle = {{2020 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)}},
Series = {{IEEE International Joint Conference on Neural Networks (IJCNN)}},
Year = {{2020}},
Note = {{International Joint Conference on Neural Networks (IJCNN) held as part
   of the IEEE World Congress on Computational Intelligence (IEEE WCCI),
   ELECTR NETWORK, JUL 19-24, 2020}},
Organization = {{IEEE; IEEE Computat Intelligence Soc; Int Neural Network Soc}},
Abstract = {{The rise of smart devices and applications has increased the dependence
   of human beings on machine learning (ML) based code-driven systems.
   While many of the pragmatic problems such as image classification,
   medical diagnosis, and statistical arbitrage have been addressed by
   extensive recent research in machine learning, it still lacks
   substantial work in the field of adversarial attacks on safety-critical
   networked systems. It is a matter of significant importance, as using
   the adversarial samples, attackers are now able to evade pre-trained
   systems and mount black-box attacks hence increasing the false
   positives. In this research, we are proposing a Random Neural Network
   based Adversarial intrusion detection system (RNN-ADV). For adversarial
   attack generation, the Jacobian Saliency Map Attack (JSMA) algorithm has
   been used. Swarm optimization capabilities have been implemented by
   training the system with the Artificial Bee Colony (ABC) algorithm.
   Different scenarios have been designed and the proposed system is then
   evaluated with benchmark benign NSL-KDD dataset, adversarial data, and
   the performance is compared with deep neural networks (DNN) using
   several performance metrics. The results suggest that the proposed
   scheme outperforms DNN in terms of adversarial attack detection where it
   has successfully classified benign samples from crafted samples with
   better accuracy and high F1 scores.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Qureshi, AU (Corresponding Author), Glasgow Caledonian Univ, Sch Comp Engn \& Built Environm, Glasgow, Lanark, Scotland.
   Qureshi, Ayyaz-Ul-Haq; Larijani, Hadi; Mtetwa, Nhamoinesu; Yousefi, Mehdi, Glasgow Caledonian Univ, Sch Comp Engn \& Built Environm, Glasgow, Lanark, Scotland.
   Javed, Abbas, COMSATS Univ Islamabad, Dept Elect \& Comp Engn, Lahore Campus, Lahore, Pakistan.}},
ISSN = {{2161-4393}},
ISBN = {{978-1-7281-6926-2}},
Keywords = {{Intrusion Detection; Swarm Intelligence; Adversarial Machine Learning;
   NSL-KDD; JSMA}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Hardware \&
   Architecture}},
Number-of-Cited-References = {{25}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BQ9MM}},
Unique-ID = {{WOS:000626021408008}},
DA = {{2021-11-23}},
}

@article{ WOS:000685459300022,
Author = {Phan The Duy and Le Khac Tien and Nghi Hoang Khoa and Do Thi Thu Hien
   and Anh Gia-Tuan Nguyen and Van-Hau Pham},
Title = {{DIGFuPAS: Deceive IDS with GAN and function-preserving on adversarial
   samples in SDN-enabled networks}},
Journal = {{COMPUTERS \& SECURITY}},
Year = {{2021}},
Volume = {{109}},
Month = {{OCT}},
Abstract = {{Showing a great potential in various domains, machine learning
   techniques are more and more used in the task of malicious network
   traffic detection to significantly enhance the ability of intrusion
   detection system (IDS). When associating with Software-Defined Networks
   (SDN), the deployment of IDSs can leverage the centralized control plane
   in SDN to support for large-scale network monitoring. However, machine
   learning-based IDSs themselves can be attacked and tricked by
   adversarial examples with additional perturbation from the original
   ones. It is vital to provide supplementary unknown traffic to evaluate
   and improve the resilience of IDS against variants of cyberattacks.
   Thus, this work explores the method of generating adversarial attack
   samples by Generative Adversarial Model (GAN) to deceive IDS. We propose
   DIGFuPAS, a framework can create attack samples which can bypass machine
   learning-based IDSs in SDN with the black-box manner. In this framework,
   instead of Vanilla GAN, we use Wassertein GAN (WGAN) to improve the
   ability of GAN convergence training. In addition, the strategy of
   preserving functional features of attack traffic is applied to maintain
   the operational aspect of adversarial attacks. Through our
   implementation and experiments on NSL-KDD and CICIDS2018 dataset, the
   decreased detection rate of black-box IDSs on adversarial attacks
   demonstrates that our proposed framework can make IDSs in SDN-enabled
   networks misclassify on GAN-based synthetic attacks. Also, we utilize
   DIGFuPAS as a tool for evaluating and improving the robustness of IDS by
   repetitively retraining classifiers from crafted network traffic flow.
   (c) 2021 Elsevier Ltd. All rights reserved.}},
Publisher = {{ELSEVIER ADVANCED TECHNOLOGY}},
Address = {{OXFORD FULFILLMENT CENTRE THE BOULEVARD, LANGFORD LANE, KIDLINGTON,
   OXFORD OX5 1GB, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Duy, PT; Pham, VH (Corresponding Author), Univ Informat Technol, Informat Secur Lab, Ho Chi Minh City, Vietnam.
   Duy, PT; Pham, VH (Corresponding Author), Vietnam Natl Univ, Ho Chi Minh City, Vietnam.
   Phan The Duy; Le Khac Tien; Nghi Hoang Khoa; Do Thi Thu Hien; Anh Gia-Tuan Nguyen; Van-Hau Pham, Univ Informat Technol, Informat Secur Lab, Ho Chi Minh City, Vietnam.
   Phan The Duy; Le Khac Tien; Nghi Hoang Khoa; Do Thi Thu Hien; Anh Gia-Tuan Nguyen; Van-Hau Pham, Vietnam Natl Univ, Ho Chi Minh City, Vietnam.}},
DOI = {{10.1016/j.cose.2021.102367}},
Article-Number = {{102367}},
ISSN = {{0167-4048}},
EISSN = {{1872-6208}},
Keywords = {{GAN; Adversarial attacks; Intrusion detection; IDS; Network anomaly
   detection; SDN}},
Keywords-Plus = {{INTRUSION DETECTION}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems}},
Author-Email = {{duypt@uit.edu.vn
   16521221@gm.uit.edu.vn
   khoanh@uit.edu.vn
   hiendtt@uit.edu.vn
   anhngt@uit.edu.vn
   haupv@uit.edu.vn}},
ORCID-Numbers = {{Nghi Hoang, Khoa/0000-0001-6418-4169}},
Funding-Acknowledgement = {{Vietnam National University HoChiMinh City (VNU-HCM) {[}DSC2021-26-05];
   Vingroup Joint Stock Company; Domestic Master/PhD Scholarship Programme
   of Vingroup Innovation Foundation (VINIF), Vingroup Big Data Institute
   (VINBIGDATA) {[}VINIF.2020.TS.138]}},
Funding-Text = {{This research is funded by Vietnam National University HoChiMinh City
   (VNU-HCM) under grant number DSC2021-26-05.; Phan The Duy was funded by
   Vingroup Joint Stock Company and supported by the Domestic Master/PhD
   Scholarship Programme of Vingroup Innovation Foundation (VINIF),
   Vingroup Big Data Institute (VINBIGDATA), code VINIF.2020.TS.138.}},
Number-of-Cited-References = {{59}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{8}},
Usage-Count-Since-2013 = {{8}},
Journal-ISO = {{Comput. Secur.}},
Doc-Delivery-Number = {{UA9FF}},
Unique-ID = {{WOS:000685459300022}},
DA = {{2021-11-23}},
}

@article{ WOS:000371895600003,
Author = {Bailetti, Tony and Gad, Mahmoud and Shah, Ahmed},
Title = {{Intrusion Learning: An Overview of an Emergent Discipline}},
Journal = {{TECHNOLOGY INNOVATION MANAGEMENT REVIEW}},
Year = {{2016}},
Pages = {{15-20}},
Month = {{FEB}},
Abstract = {{The purpose of this article is to provide a definition of intrusion
   learning, identify its distinctive aspects, and provide recommendations
   for advancing intrusion learning as a practice domain. The authors
   define intrusion learning as the collection of online network algorithms
   that learn from and monitor streaming network data resulting in
   effective intrusion-detection methods for enabling the security and
   resiliency of enterprise systems. The network algorithms build on
   advances in cyber-defensive and cyber-offensive capabilities. Intrusion
   learning is an emerging domain that draws from machine learning,
   intrusion detection, and streaming network data. Intrusion learning
   offers to significantly enhance enterprise security and resiliency
   through augmented perimeter defense and may mitigate increasing threats
   facing enterprise perimeter protection. The article will be of interest
   to researchers, sponsors, and entrepreneurs interested in enhancing
   enterprise security and resiliency.}},
Publisher = {{CARLETON UNIV GRAPHIC SERVICES}},
Address = {{DUNTON TOWER RM 2122, 1125 COLONEL BY DR, OTTAWA, ON K1A 5B6, CANADA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Bailetti, T (Corresponding Author), Carleton Univ, Sch Business, Sprott, Ottawa, ON K1S 5B6, Canada.
   Bailetti, T (Corresponding Author), Carleton Univ, Dept Syst \& Comp Engn, Ottawa, ON K1S 5B6, Canada.
   Bailetti, T (Corresponding Author), Carleton Univ, TIM Program, Ottawa, ON K1S 5B6, Canada.
   Bailetti, Tony, Carleton Univ, Sch Business, Sprott, Ottawa, ON K1S 5B6, Canada.
   Bailetti, Tony, Carleton Univ, Dept Syst \& Comp Engn, Ottawa, ON K1S 5B6, Canada.
   Bailetti, Tony, Carleton Univ, TIM Program, Ottawa, ON K1S 5B6, Canada.
   Gad, Mahmoud, VENUS Cybersecur, Ottawa, ON, Canada.
   Shah, Ahmed, VENUS Cybersecur Corp, Cybersecur Res, Ottawa, ON, Canada.
   Shah, Ahmed, IBM Corp, Bangalore, Karnataka, India.}},
ISSN = {{1927-0321}},
Keywords = {{cybersecurity; intrusion learning; intrusion detection; machine
   learning; learning algorithms; adversarial learning; clustering;
   streaming network data; real-time analysis; enterprise; security;
   resiliency}},
Research-Areas = {{Business \& Economics}},
Web-of-Science-Categories  = {{Management}},
Number-of-Cited-References = {{18}},
Times-Cited = {{6}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{9}},
Journal-ISO = {{Technol. Innov. Manag. Rev.}},
Doc-Delivery-Number = {{DG2KK}},
Unique-ID = {{WOS:000371895600003}},
DA = {{2021-11-23}},
}

@article{ WOS:000677639500011,
Author = {Anthi, Eirini and Williams, Lowri and Laved, Amir and Burnap, Pete},
Title = {{Hardening machine learning denial of service (DoS) defences against
   adversarial attacks in IoT smart home networks}},
Journal = {{COMPUTERS \& SECURITY}},
Year = {{2021}},
Volume = {{108}},
Month = {{SEP}},
Abstract = {{Machine learning based Intrusion Detection Systems (IDS) allow flexible
   and efficient automated detection of cyberattacks in Internet of Things
   (IoT) networks. However, this has also created an additional attack
   vector; the machine learning models which support the IDS's decisions
   may also be subject to cyberattacks known as Adversarial Machine
   Learning (AML). In the context of IoT, AML can be used to manipulate
   data and network traffic that traverse through such devices. These
   perturbations increase the confusion in the decision boundaries of the
   machine learning classifier, where malicious network packets are often
   miss-classified as being benign. Consequently, such errors are bypassed
   by machine learning based detectors, which increases the potential of
   significantly delaying attack detection and further consequences such as
   personal information leakage, damaged hardware, and financial loss.
   Given the impact that these attacks may have, this paper proposes a
   rule-based approach towards generating AML attack samples and explores
   how they can be used to target a range of supervised machine learning
   classifiers used for detecting Denial of Service attacks in an IoT smart
   home network. The analysis explores which DoS packet features to perturb
   and how such adversarial samples can support increasing the robustness
   of supervised models using adversarial training. The results
   demonstrated that the performance of all the top performing classifiers
   were affected, decreasing a maximum of 47.2 percentage points when
   adversarial samples were present. Their performances improved following
   adversarial training, demonstrating their robustness towards such
   attacks. Crown Copyright (c) 2021 Published by Elsevier Ltd. This is an
   open access article under the CC BY license (
   http://creativecommons.org/licenses/by/4.0/ )}},
Publisher = {{ELSEVIER ADVANCED TECHNOLOGY}},
Address = {{OXFORD FULFILLMENT CENTRE THE BOULEVARD, LANGFORD LANE, KIDLINGTON,
   OXFORD OX5 1GB, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Anthi, E (Corresponding Author), Cardiff Univ, Sch Comp Sci Informat, Cardiff, Wales.
   Anthi, Eirini; Williams, Lowri; Laved, Amir; Burnap, Pete, Cardiff Univ, Sch Comp Sci Informat, Cardiff, Wales.}},
DOI = {{10.1016/j.cose.2021.102352}},
Article-Number = {{102352}},
ISSN = {{0167-4048}},
EISSN = {{1872-6208}},
Keywords = {{Internet of things (IoT); Smart homes; Networking; Supervised machine
   learning; Adversarial machine learning; Attack detection; Intrusion
   detection systems}},
Keywords-Plus = {{INTERNET; THINGS}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems}},
Author-Email = {{anthies@cardiff.ac.uk}},
ORCID-Numbers = {{Williams, Lowri/0000-0002-3794-6145}},
Funding-Acknowledgement = {{Engineering and Phys-ical Sciences Research Council (EPSRC)UK Research
   \& Innovation (UKRI)Engineering \& Physical Sciences Research Council
   (EPSRC) {[}EP/S035362/1]}},
Funding-Text = {{This work was part-funded by the Engineering and Phys-ical Sciences
   Research Council (EPSRC) -project number EP/S035362/1 (PETRAS 2) .}},
Number-of-Cited-References = {{44}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{5}},
Usage-Count-Since-2013 = {{5}},
Journal-ISO = {{Comput. Secur.}},
Doc-Delivery-Number = {{TP5KZ}},
Unique-ID = {{WOS:000677639500011}},
OA = {{hybrid, Green Accepted}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000519271301100,
Author = {Li, Pan and Liu, Qiang and Zhao, Wentao and Wang, Dongxu and Wang, Siqi},
Book-Group-Author = {{IEEE}},
Title = {{Chronic Poisoning Against Machine Learning Based IDSs Using Edge Pattern
   Detection}},
Booktitle = {{2018 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS (ICC)}},
Series = {{IEEE International Conference on Communications}},
Year = {{2018}},
Note = {{IEEE International Conference on Communications (ICC) / Workshop on
   Integrating UAVs into 5G, Kansas City, MO, MAY 20-24, 2018}},
Organization = {{IEEE; Sprint; Qualcomm; Cisco; Huawei; Natl Instruments; Nokia; Comput
   Res Assoc Women; GARMIN; Juniper Networks; NSF}},
Abstract = {{In big data era, machine learning is one of fundamental techniques in
   intrusion detection systems (IDSs). Poisoning attack, which is one of
   the most recognized security threats towards machine learning-based
   IDSs, injects some adversarial samples into the training phase, inducing
   data drifting of training data and a significant performance decrease of
   target IDSs over testing data. In this paper, we adopt the Edge Pattern
   Detection (EPD) algorithm to design a novel poisoning method that attack
   against several machine learning algorithms used in IDSs. Specifically,
   we propose a boundary pattern detection algorithm to efficiently
   generate the points that are near to abnormal data but considered to be
   normal ones by current classifiers. Then, we introduce a Batch-EPD
   Boundary Pattern (BEBP) detection algorithm to overcome the limitation
   of the number of edge pattern points generated by EPD and to obtain more
   useful adversarial samples. Based on BEBP, we further present a moderate
   but effective poisoning method called chronic poisoning attack.
   Extensive experiments on synthetic and three real network data sets
   demonstrate the performance of the proposed poisoning method against
   several well-known machine learning algorithms and a practical intrusion
   detection method named FMIFS-LSSVM-IDS.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Li, P (Corresponding Author), Natl Univ Def Technol, Coll Comp, Changsha 410073, Hunan, Peoples R China.
   Li, Pan; Liu, Qiang; Zhao, Wentao; Wang, Dongxu; Wang, Siqi, Natl Univ Def Technol, Coll Comp, Changsha 410073, Hunan, Peoples R China.}},
ISSN = {{1550-3607}},
ISBN = {{978-1-5386-3180-5}},
Keywords = {{Chronic poisoning; intrusion detection system; machine learning; data
   drifting}},
Research-Areas = {{Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic; Telecommunications}},
Author-Email = {{lipan16@nudt.edu.cn
   qiangliu06@nudt.edu.cn
   wtzhao@nudt.edu.cn
   wangdongxu15@nudt.edu.cn
   wangsiqi10c@gmail.com}},
Number-of-Cited-References = {{20}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BO5ZI}},
Unique-ID = {{WOS:000519271301100}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000516620100066,
Author = {Kwon, Hyun and Yoon, Hyunsoo and Choi, Daeseon},
Book-Group-Author = {{ACM}},
Title = {{Zero-Day Evasion Attack Analysis on Race between Attack and Defense}},
Booktitle = {{PROCEEDINGS OF THE 2018 ACM ASIA CONFERENCE ON COMPUTER AND
   COMMUNICATIONS SECURITY (ASIACCS'18)}},
Year = {{2018}},
Pages = {{805-807}},
Note = {{13th ACM Asia Conference on Information, Computer and Communications
   Security (ASIACCS), Incheon, SOUTH KOREA, JUN 04-08, 2018}},
Organization = {{Assoc Comp Machinery; ACM SIGSAC; Samsung Res; Huawei; Internet Finance
   Authenticat Alliance; Naver; Somansa; Penta Secur}},
Abstract = {{Deep neural networks (DNNs) exhibit excellent performance in machine
   learning tasks such as image recognition, pattern recognition, speech
   recognition, and intrusion detection. However, the usage of adversarial
   examples, which are intentionally corrupted by noise, can lead to
   misclassification. As adversarial examples are serious threats to DNNs,
   both adversarial attacks and methods of defending against adversarial
   examples have been continuously studied. Zero-day adversarial examples
   are created with new test data and are unknown to the classifier; hence,
   they represent a more significant threat to DNNs. To the best of our
   knowledge, there are no analytical studies in the literature of zero-day
   adversarial examples with a focus on attack and defense methods through
   experiments using several scenarios. Therefore, in this study, zero-day
   adversarial examples are practically analyzed with an emphasis on attack
   and defense methods through experiments using various scenarios composed
   of a fixed target model and an adaptive target model. The Carlini method
   was used for a state-of-the-art attack, while an adversarial training
   method was used as a typical defense method. We used the MNIST dataset
   and analyzed success rates of zero-day adversarial examples, average
   distortions, and recognition of original samples through several
   scenarios of fixed and adaptive target models. Experimental results
   demonstrate that changing the parameters of the target model in real
   time leads to resistance to adversarial examples in both the fixed and
   adaptive target models.}},
Publisher = {{ASSOC COMPUTING MACHINERY}},
Address = {{1515 BROADWAY, NEW YORK, NY 10036-9998 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Kwon, H (Corresponding Author), Korea Adv Inst Sci \& Technol, Sch Comp, Daejeon, South Korea.
   Kwon, Hyun; Yoon, Hyunsoo, Korea Adv Inst Sci \& Technol, Sch Comp, Daejeon, South Korea.
   Choi, Daeseon, Kongju Natl Univ, Dept Med Informat, Gongju Si, South Korea.}},
DOI = {{10.1145/3196494.3201583}},
ISBN = {{978-1-4503-5576-6}},
Keywords = {{Deep neural network (DNN); Zero-day adversarial examples; Adversarial
   example; Adversarial training}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods}},
Author-Email = {{khkh@kaist.ac.kr
   hyoon@kaist.ac.kr
   sunchoi@kongju.ac.kr}},
ResearcherID-Numbers = {{Kwon, Hyun/M-1140-2018}},
ORCID-Numbers = {{Kwon, Hyun/0000-0003-1169-9892}},
Funding-Acknowledgement = {{National Research Foundation (NRF) of Korea - Korea government (MSIT)
   {[}2016R1A4A1011761, 2017R1A2B4006026]; Institute for Information \&
   communications Technology Promotion (IITP) - Korea government (MSIT)
   {[}2016-0-00173]}},
Funding-Text = {{This work was supported by the National Research Foundation (NRF) of
   Korea grant funded by the Korea government (MSIT) (2016R1A4A1011761 and
   2017R1A2B4006026) and Institute for Information \& communications
   Technology Promotion (IITP) grant funded by the Korea government (MSIT)
   (No. 2016-0-00173).}},
Number-of-Cited-References = {{6}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BO5BA}},
Unique-ID = {{WOS:000516620100066}},
DA = {{2021-11-23}},
}

@article{ WOS:000516827000097,
Author = {Sagar, Ramani and Jhaveri, Rutvij and Borrego, Carlos},
Title = {{Applications in Security and Evasions in Machine Learning: A Survey}},
Journal = {{ELECTRONICS}},
Year = {{2020}},
Volume = {{9}},
Number = {{1}},
Month = {{JAN}},
Abstract = {{In recent years, machine learning (ML) has become an important part to
   yield security and privacy in various applications. ML is used to
   address serious issues such as real-time attack detection, data leakage
   vulnerability assessments and many more. ML extensively supports the
   demanding requirements of the current scenario of security and privacy
   across a range of areas such as real-time decision-making, big data
   processing, reduced cycle time for learning, cost-efficiency and
   error-free processing. Therefore, in this paper, we review the state of
   the art approaches where ML is applicable more effectively to fulfill
   current real-world requirements in security. We examine different
   security applications' perspectives where ML models play an essential
   role and compare, with different possible dimensions, their accuracy
   results. By analyzing ML algorithms in security application it provides
   a blueprint for an interdisciplinary research area. Even with the use of
   current sophisticated technology and tools, attackers can evade the ML
   models by committing adversarial attacks. Therefore, requirements rise
   to assess the vulnerability in the ML models to cope up with the
   adversarial attacks at the time of development. Accordingly, as a
   supplement to this point, we also analyze the different types of
   adversarial attacks on the ML models. To give proper visualization of
   security properties, we have represented the threat model and defense
   strategies against adversarial attack methods. Moreover, we illustrate
   the adversarial attacks based on the attackers' knowledge about the
   model and addressed the point of the model at which possible attacks may
   be committed. Finally, we also investigate different types of properties
   of the adversarial attacks.}},
Publisher = {{MDPI}},
Address = {{ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Sagar, R (Corresponding Author), Gujarat Technol Univ, Comp IT Engn Dept, Ahmadabad 382424, Gujarat, India.
   Sagar, Ramani, Gujarat Technol Univ, Comp IT Engn Dept, Ahmadabad 382424, Gujarat, India.
   Jhaveri, Rutvij, Pandit Deendayal Petr Univ, Dept Comp Sci \& Engn, Gandhinagar 382007, India.
   Borrego, Carlos, Autonomous Univ Barcelona, Dept Informat \& Commun Engn, E-08193 Barcelona, Spain.}},
DOI = {{10.3390/electronics9010097}},
Article-Number = {{97}},
EISSN = {{2079-9292}},
Keywords = {{security; privacy; adversarial attack; machine learning; attackers'
   knowledge}},
Keywords-Plus = {{INTRUSION DETECTION; NEURAL-NETWORK; MALWARE DETECTION; DETECTION
   SYSTEMS; DYNAMIC-ANALYSIS; PRIVACY; RISK; CLASSIFICATION; PROTECTION;
   DIAGNOSIS}},
Research-Areas = {{Computer Science; Engineering; Physics}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Physics, Applied}},
Author-Email = {{sagarramani@gmail.com
   rutvij.jhaveri@sot.pdpu.ac.in
   carlos.borrego@uab.cat}},
ResearcherID-Numbers = {{Jhaveri, Rutvij H./A-5354-2018
   Borrego Iglesias, Carlos/K-8681-2014}},
ORCID-Numbers = {{Jhaveri, Rutvij H./0000-0002-3285-7346
   Borrego Iglesias, Carlos/0000-0002-9452-9970}},
Number-of-Cited-References = {{170}},
Times-Cited = {{13}},
Usage-Count-Last-180-days = {{5}},
Usage-Count-Since-2013 = {{9}},
Journal-ISO = {{Electronics}},
Doc-Delivery-Number = {{KQ3LC}},
Unique-ID = {{WOS:000516827000097}},
OA = {{gold}},
DA = {{2021-11-23}},
}

@article{ WOS:000454725100076,
Author = {Kwon, Hyun and Kim, Yongchul and Yoon, Hyunsoo and Choi, Daeseon},
Title = {{Random Untargeted Adversarial Example on Deep Neural Network}},
Journal = {{SYMMETRY-BASEL}},
Year = {{2018}},
Volume = {{10}},
Number = {{12}},
Month = {{DEC}},
Abstract = {{Deep neural networks (DNNs) have demonstrated remarkable performance in
   machine learning areas such as image recognition, speech recognition,
   intrusion detection, and pattern analysis. However, it has been revealed
   that DNNs have weaknesses in the face of adversarial examples, which are
   created by adding a little noise to an original sample to cause
   misclassification by the DNN. Such adversarial examples can lead to
   fatal accidents in applications such as autonomous vehicles and disease
   diagnostics. Thus, the generation of adversarial examples has attracted
   extensive research attention recently. An adversarial example is
   categorized as targeted or untargeted. In this paper, we focus on the
   untargeted adversarial example scenario because it has a faster learning
   time and less distortion compared with the targeted adversarial example.
   However, there is a pattern vulnerability with untargeted adversarial
   examples: Because of the similarity between the original class and
   certain specific classes, it may be possible for the defending system to
   determine the original class by analyzing the output classes of the
   untargeted adversarial examples. To overcome this problem, we propose a
   new method for generating untargeted adversarial examples, one that uses
   an arbitrary class in the generation process. Moreover, we show that our
   proposed scheme can be applied to steganography. Through experiments, we
   show that our proposed scheme can achieve a 100\% attack success rate
   with minimum distortion (1.99 and 42.32 using the MNIST and CIFAR10
   datasets, respectively) and without the pattern vulnerability. Using a
   steganography test, we show that our proposed scheme can be used to fool
   humans, as demonstrated by the probability of their detecting hidden
   classes being equal to that of random selection.}},
Publisher = {{MDPI}},
Address = {{ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Choi, D (Corresponding Author), Kongju Natl Univ, Dept Med Informat, Gongju Si 32588, South Korea.
   Kwon, Hyun; Yoon, Hyunsoo, Korea Adv Inst Sci \& Technol, Sch Comp, Daejeon 34141, South Korea.
   Kim, Yongchul, Korea Mil Acad, Dept Elect Engn, Seoul 01805, South Korea.
   Choi, Daeseon, Kongju Natl Univ, Dept Med Informat, Gongju Si 32588, South Korea.}},
DOI = {{10.3390/sym10120738}},
Article-Number = {{738}},
EISSN = {{2073-8994}},
Keywords = {{deep neural network; adversarial example; untargeted adversarial
   example; random selection}},
Keywords-Plus = {{EVASION ATTACK}},
Research-Areas = {{Science \& Technology - Other Topics}},
Web-of-Science-Categories  = {{Multidisciplinary Sciences}},
Author-Email = {{khkh@kaist.ac.kr
   kyc6454@kma.ac.kr
   hyoon@kaist.ac.kr
   sunchoi@kongju.ac.kr}},
ResearcherID-Numbers = {{Kwon, Hyun/M-1140-2018}},
ORCID-Numbers = {{Kwon, Hyun/0000-0003-1169-9892}},
Funding-Acknowledgement = {{Institute for Information \& Communications Technology Promotion
   {[}2016-0-00173]; National Research Foundation {[}2017R1A2B4006026,
   2016R1A4A1011761]}},
Funding-Text = {{This study was supported by the Institute for Information \&
   Communications Technology Promotion (Grant No. 2016-0-00173) and the
   National Research Foundation (Grant No. 2017R1A2B4006026 and
   2016R1A4A1011761).}},
Number-of-Cited-References = {{26}},
Times-Cited = {{8}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{7}},
Journal-ISO = {{Symmetry-Basel}},
Doc-Delivery-Number = {{HG1NS}},
Unique-ID = {{WOS:000454725100076}},
OA = {{gold}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000505811103032,
Author = {Marino, Daniel L. and Wickramasinghe, Chathurika S. and Manic, Milos},
Book-Group-Author = {{IEEE}},
Title = {{An Adversarial Approach for Explainable AI in Intrusion Detection
   Systems}},
Booktitle = {{IECON 2018 - 44TH ANNUAL CONFERENCE OF THE IEEE INDUSTRIAL ELECTRONICS
   SOCIETY}},
Series = {{IEEE Industrial Electronics Society}},
Year = {{2018}},
Pages = {{3237-3243}},
Note = {{44th Annual Conference of the IEEE Industrial-Electronics-Society
   (IECON), Washington, DC, OCT 20-23, 2018}},
Organization = {{IEEE Ind Elect Soc; Inst Elect \& Elect Engineers}},
Abstract = {{Despite the growing popularity of modern machine learning techniques
   (e.g. Deep Neural Networks) in cyber-security applications, most of
   these models are perceived as a black-box for the user. Adversarial
   machine learning offers an approach to increase our understanding of
   these models. In this paper we present an approach to generate
   explanations for incorrect classifications made by data-driven Intrusion
   Detection Systems (IDSs) An adversarial approach is used to find the
   minimum modifications (of the input features) required to correctly
   classify a given set of misclassified samples. The magnitude of such
   modifications is used to visualize the most relevant features that
   explain the reason for the misclassification. The presented methodology
   generated satisfactory explanations that describe the reasoning behind
   the mis-classifications, with descriptions that match expert knowledge.
   The advantages of the presented methodology are: 1) applicable to any
   classifier with defined gradients. 2) does not require any modification
   of the classifier model. 3) can be extended to perform further diagnosis
   (e.g. vulnerability assessment) and gain further understanding of the
   system. Experimental evaluation was conducted on the NSL-KDD99 benchmark
   dataset using Linear and Multilayer perceptron classifiers. The results
   are shown using intuitive visualizations in order to improve the
   interpretability of the results.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Marino, DL (Corresponding Author), Virginia Commonwealth Univ, Dept Comp Sci, Richmond, VA 23284 USA.
   Marino, Daniel L.; Wickramasinghe, Chathurika S.; Manic, Milos, Virginia Commonwealth Univ, Dept Comp Sci, Richmond, VA 23284 USA.}},
ISSN = {{1553-572X}},
ISBN = {{978-1-5090-6684-1}},
Keywords = {{Adversarial Machine Learning; Adversarial samples; Explainable AI;
   cyber-security}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{marinodl@vcu.edu
   misko@ieee.org}},
ResearcherID-Numbers = {{Wickramasinghe, Chathurika S/AAC-7024-2020}},
Number-of-Cited-References = {{23}},
Times-Cited = {{11}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{5}},
Doc-Delivery-Number = {{BO2HR}},
Unique-ID = {{WOS:000505811103032}},
OA = {{Green Submitted}},
DA = {{2021-11-23}},
}

@article{ WOS:000672542400020,
Author = {Khraisat, Ansam and Gondal, Iqbal and Vamplew, Peter and Kamruzzaman,
   Joarder},
Title = {{Survey of intrusion detection systems: techniques, datasets and
   challenges}},
Journal = {{CYBERSECURITY}},
Year = {{2019}},
Volume = {{2}},
Number = {{1}},
Abstract = {{Cyber-attacks are becoming more sophisticated and thereby presenting
   increasing challenges in accurately detecting intrusions. Failure to
   prevent the intrusions could degrade the credibility of security
   services, e.g. data confidentiality, integrity, and availability.
   Numerous intrusion detection methods have been proposed in the
   literature to tackle computer security threats, which can be broadly
   classified into Signature-based Intrusion Detection Systems (SIDS) and
   Anomaly-based Intrusion Detection Systems (AIDS). This survey paper
   presents a taxonomy of contemporary IDS, a comprehensive review of
   notable recent works, and an overview of the datasets commonly used for
   evaluation purposes. It also presents evasion techniques used by
   attackers to avoid detection and discusses future research challenges to
   counter such techniques so as to make computer systems more secure.}},
Publisher = {{SPRINGERNATURE}},
Address = {{CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Khraisat, A (Corresponding Author), Federat Univ Australia, Internet Commerce Secur Lab, Mount Helen, Australia.
   Khraisat, Ansam; Gondal, Iqbal; Vamplew, Peter; Kamruzzaman, Joarder, Federat Univ Australia, Internet Commerce Secur Lab, Mount Helen, Australia.}},
DOI = {{10.1186/s42400-019-0038-7}},
Article-Number = {{20}},
EISSN = {{2523-3246}},
Keywords = {{Malware; Intrusion detection system; NSL\_KDD; Anomaly detection;
   Machine learning}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering}},
Author-Email = {{a.khraisat@federation.edu.au}},
ResearcherID-Numbers = {{Vamplew, Peter/I-3061-2015
   }},
ORCID-Numbers = {{Vamplew, Peter/0000-0002-8687-4424
   Kamruzzaman, Joarder/0000-0002-3748-0277
   Gondal, Iqbal/0000-0001-7963-2446}},
Funding-Acknowledgement = {{Westpac Banking Corporation}},
Funding-Text = {{This work was carried out within the Internet Commerce Security Lab,
   which is funded by Westpac Banking Corporation.}},
Number-of-Cited-References = {{120}},
Times-Cited = {{115}},
Usage-Count-Last-180-days = {{4}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{Cybersecurity}},
Doc-Delivery-Number = {{VK2XP}},
Unique-ID = {{WOS:000672542400020}},
OA = {{gold, Green Published}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000471259200024,
Author = {Ma, Yue and He, Yiwei and Tian, Yingjie},
Editor = {{Shi, Y and Wolcott, P and Kwak, W and Chen, Z and Tian, Y and Lee, H}},
Title = {{Online Robust Lagrangian Support Vector Machine against Adversarial
   Attack}},
Booktitle = {{6TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND QUANTITATIVE
   MANAGEMENT}},
Series = {{Procedia Computer Science}},
Year = {{2018}},
Volume = {{139}},
Pages = {{173-181}},
Note = {{6th International Conference on Information Technology and Quantitative
   Management (ITQM), Omaha, NE, OCT 20-21, 2018}},
Organization = {{Int Acad Informat Technol \& Quantitat Management; Univ Nebraska;
   Chinese Acad Sci, Res Ctr Fictitious Economy \& Data Sci; UCAS, Sch Econ
   \& Management; Chinese Acad Sci, Inst Sci \& Dev; Chinese Acad Sci, Key
   Lab Big Data Mining \& Knowledge Management; Chinese Acad Management,
   Business Intelligence Soc; SW Minzu Univ; TIBD}},
Abstract = {{In adversarial environment such as intrusion detection and spam
   filtering, the adversary intruder or spam advertiser may attempt to
   produce contaminate training instance and manipulate the learning of
   classifier. In order to keep good classification performance, many
   robuster learning methods have been proposed to deal with the
   adversarial attack. Support Vector Machines(SVMs) is a kind of
   successful approach in the adversarial classification tasks and the
   investigation of robust SVMs is very popular. However, in many real
   application, the data including stain instance is coming dynamically.
   Batch learning which needs retraining when encountering new samples,
   will consume more computing resources. In this paper, we propose a
   robust Lagrangian support vector machine (RLSVM) with modified kernel
   matrix and explore the online learning algorithm on it. The experimental
   results show the robustness of RLSVM against label noise produced by
   adversaries under the online adversarial environment. (C) 2018 The
   Authors. Published by Elsevier B.V.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Tian, YJ (Corresponding Author), Chinese Acad Sci, Res Ctr Fictitious Econ \& Data Sci, Beijing 100190, Peoples R China.
   Tian, YJ (Corresponding Author), Key Lab Big Data Min \& Knowledge Management, Beijing 100190, Peoples R China.
   Tian, YJ (Corresponding Author), Univ Chinese Acad Sci, Sch Econ \& Management, Beijing 100190, Peoples R China.
   Ma, Yue, Univ Chinese Acad Sci, Sch Math Sci, Beijing 100049, Peoples R China.
   Ma, Yue; Tian, Yingjie, Chinese Acad Sci, Res Ctr Fictitious Econ \& Data Sci, Beijing 100190, Peoples R China.
   He, Yiwei, Univ Chinese Acad Sci, Sch Comp \& Control Engn, Beijing 100049, Peoples R China.
   Tian, Yingjie, Key Lab Big Data Min \& Knowledge Management, Beijing 100190, Peoples R China.
   Tian, Yingjie, Univ Chinese Acad Sci, Sch Econ \& Management, Beijing 100190, Peoples R China.}},
DOI = {{10.1016/j.procs.2018.10.239}},
ISSN = {{1877-0509}},
Keywords = {{adversarial attack; poison attack; label noise; online learning;
   Lagrangian SVM}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods}},
Author-Email = {{tyj@ucas.ac.cn}},
Funding-Acknowledgement = {{National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}71731009, 61472390, 71331005, 91546201];
   Beijing Natural Science FoundationBeijing Natural Science Foundation
   {[}1162005]}},
Funding-Text = {{This work has been partially supported by grants from National Natural
   Science Foundation of China (Nos. 71731009, 61472390, 71331005, and
   91546201), the Beijing Natural Science Foundation (No.1162005).}},
Number-of-Cited-References = {{23}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BM9RC}},
Unique-ID = {{WOS:000471259200024}},
OA = {{gold}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000452027600017,
Author = {Huang, Chi-Hsuan and Lee, Tsung-Han and Chang, Lin-Huang and Lin,
   Jhih-Ren and Horng, Gwoboa},
Editor = {{Kim, KJ and Kim, H}},
Title = {{Adversarial Attacks on SDN-Based Deep Learning IDS System}},
Booktitle = {{MOBILE AND WIRELESS TECHNOLOGY 2018, ICMWT 2018}},
Series = {{Lecture Notes in Electrical Engineering}},
Year = {{2019}},
Volume = {{513}},
Pages = {{181-191}},
Note = {{iCatse International Conference on Mobile and Wireless Technology
   (ICMWT) / iTAIWAN Workshop, Hong Kong, HONG KONG, JUN 25-27, 2018}},
Organization = {{Inst Creat Adv Technologies, Sci \& Engn; Chinese Management Sci Soc;
   Korean Ind Secur Forum; Korea Informat Assurance Soc; Kyonggi Univ; Univ
   Sci \& Technol Beijing; King Mongkuts Univ Technol Thonburi; River
   Publishers; Software Engn Journal; Natl Def Univ Malaysia; Korea Inst
   Sci \& Technol Informat; Elect \& Telecommunicat Res Inst; Nam Seoul
   Univ; Software Networking Journal}},
Abstract = {{In recent years, software defined networking (SDN) has become a novel
   network architecture and design by employing manageable software between
   the control and data planes. Many SDN-based intrusion detection systems
   (IDS) have been proposed in recent researches. On the other hand, deep
   learning has emerged as an explosive growth in research and industry.
   The application of deep learning on IDS has been studied in many
   security-critical scenarios. However, some reports has indicated the
   vulnerability of adversarial attacks on deep learning IDS system with
   intentional perturbation injection or manipulation. It is important for
   the empowered IDS system employing deep learning to be responsible for
   not leading misclassification. Therefore, exploring the impact on the
   adversarial attacks over SDN networks or security-critical scenarios
   applying deep learning is an important step to confront such urgent
   issues. In this paper, we will conduct the SDN-based experiments on
   adversarial attacks for deep learning detecting system. We propose a
   novel class of adversarial attacks that exploits the vulnerability of
   the deep learning classifiers in SDN environment. Three typical deep
   learning models combining with four different adversarial testing will
   be conducted in the simulation for complete analysis.}},
Publisher = {{SPRINGER}},
Address = {{233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Chang, LH (Corresponding Author), Natl Taichung Univ Educ, Dept Comp Sci, Taichung, Taiwan.
   Huang, Chi-Hsuan; Horng, Gwoboa, Natl Chung Hsing Univ, Dept Comp Sci \& Engn, Taichung, Taiwan.
   Lee, Tsung-Han; Chang, Lin-Huang; Lin, Jhih-Ren, Natl Taichung Univ Educ, Dept Comp Sci, Taichung, Taiwan.}},
DOI = {{10.1007/978-981-13-1059-1\_17}},
ISSN = {{1876-1100}},
EISSN = {{1876-1119}},
ISBN = {{978-981-13-1059-1; 978-981-13-1058-4}},
Keywords = {{Adversarial attacks; SDN; Deep learning; IDS}},
Research-Areas = {{Telecommunications}},
Web-of-Science-Categories  = {{Telecommunications}},
Author-Email = {{d102056016@mail.nchu.edu.tw
   thlee@mail.ntcu.edu.tw
   lchang@mail.ntcu.edu.tw
   bcs105103@gm.ntcu.edu.tw
   gbhorng@cs.nchu.edu.tw}},
Funding-Acknowledgement = {{Ministry of Science and Technology, TaiwanMinistry of Science and
   Technology, Taiwan {[}MOST 105-2221-E-142-001-MY2,
   105-2221-E-142-002-MY2]}},
Funding-Text = {{This research was supported by research grants (MOST
   105-2221-E-142-001-MY2 and 105-2221-E-142-002-MY2) from Ministry of
   Science and Technology, Taiwan.}},
Number-of-Cited-References = {{10}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{31}},
Doc-Delivery-Number = {{BL5KW}},
Unique-ID = {{WOS:000452027600017}},
DA = {{2021-11-23}},
}

@article{ WOS:000661867900011,
Author = {Andresini, Giuseppina and Appice, Annalisa and De Rose, Luca and
   Malerba, Donato},
Title = {{GAN augmentation to deal with imbalance in imaging-based intrusion
   detection}},
Journal = {{FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE}},
Year = {{2021}},
Volume = {{123}},
Pages = {{108-127}},
Month = {{OCT}},
Abstract = {{Nowadays attacks on computer networks continue to advance at a rate
   outpacing cyber defenders' ability to write new attack signatures. This
   paper illustrates a deep learning methodology for the binary
   classification of the network traffic. The basic idea is to represent
   network flows as 2D images and use this imagery representation of the
   network traffic to train a Generative Adversarial Network (GAN) and a
   Convolutional Neural Network (CNN). The GAN is trained to produce new
   images of unforeseen network attacks by augmenting the training data
   used to learn a CNN-based intrusion detection model. The advantage is
   that the 2D data mapping technique used builds images of the network
   flows, which allow us to take advantage of deep learning architectures
   with convolution layers. In addition, the GAN-based data augmentation
   allows us to deal with the possible imbalance of malicious traffic that
   is commonly rarer than the normal traffic in the network traffic.
   Specifically, it is used to simulate unforeseen attacks to train a
   robust intrusion detection model. The proposed methodology leads to
   better predictive accuracy when compared to competitive intrusion
   detection architectures on four benchmark datasets. (C) 2021 Published
   by Elsevier B.V.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Andresini, G (Corresponding Author), Univ Bari Aldo Moro, Dept Informat, Via Orabona 4, I-70125 Bari, Italy.
   Andresini, Giuseppina; Appice, Annalisa; De Rose, Luca; Malerba, Donato, Univ Bari Aldo Moro, Dept Informat, Via Orabona 4, I-70125 Bari, Italy.
   Appice, Annalisa; Malerba, Donato, Consorzio Interuniv Nazl Informat CINI, Bari, Italy.}},
DOI = {{10.1016/j.future.2021.04.017}},
ISSN = {{0167-739X}},
EISSN = {{1872-7115}},
Keywords = {{Intrusion detection; Deep learning; Data augmentation; Image encoding}},
Keywords-Plus = {{DEEP LEARNING APPROACH; DETECTION SYSTEM; NEURAL-NETWORK;
   CLASSIFICATION; DIMENSIONALITY; INTERNET}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods}},
Author-Email = {{giuseppina.andresini@uniba.it
   annalisa.appice@uniba.it
   l.derose@studenti.uniba.it
   donato.malerba@uniba.it}},
ORCID-Numbers = {{Andresini, Giuseppina/0000-0002-5272-644X}},
Funding-Acknowledgement = {{MIURMinistero dell'Istruzione dell'Universita e della RicercaMinistry of
   Education, Universities and Research (MIUR) {[}ARS01\_01116]; University
   of Bari ``Aldo Moro{''}}},
Funding-Text = {{We acknowledge the support of the MIURMinistero dell'Istruzione
   dell'Universita e della Ricerca through the project ``TALIsManTecnologie
   di Assistenza personALizzata per il Miglioramento della quAlita della
   vitA{''} (Grant ID: ARS01\_01116) , funding scheme PON RI 2014-2020, as
   well as the project ``Modelli e tecniche di data science per la analisi
   di dati strutturati{''}funded by the University of Bari ``Aldo Moro{''}.
   The authors wish to thank Lynn Rudd for her help in reading the
   manuscript.}},
Number-of-Cited-References = {{121}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{39}},
Usage-Count-Since-2013 = {{39}},
Journal-ISO = {{Futur. Gener. Comp. Syst.}},
Doc-Delivery-Number = {{SS6MD}},
Unique-ID = {{WOS:000661867900011}},
DA = {{2021-11-23}},
}

@article{ WOS:000691795400008,
Author = {Mohamed, Safa and Ejbali, Ridha},
Title = {{ADVERSARIAL MULTI-AGENT REINFORCEMENT LEARNING ALGORITHM FOR ANOMALY
   NETWORK INTRUSION DETECTION SYSTEM}},
Journal = {{INTERNATIONAL JOURNAL ON INFORMATION TECHNOLOGIES AND SECURITY}},
Year = {{2021}},
Volume = {{13}},
Number = {{3}},
Pages = {{87-102}},
Abstract = {{With the rapid evolution of cyber-attacks in a dynamic environment,
   intrusion detection has become a difficult task. The application of new
   algorithms has become a necessity in detecting and classifying dangerous
   traffic. We propose a new Adversarial Multi-Agent Reinforcement Learning
   approach-based Deep SARSA algorithm (AE-Deep SARSA) that can address to
   solve the problem of imbalanced distribution dataset; the main
   contribution is to ameliorate the detection of minority classes that
   often account for rare instances in order to increase the performance of
   classifier prediction. We carried out our work using imbalanced NSL-KDD
   dataset that is known as NIDS benchmark datasets and this presented a
   classifier's challenge in our approach. We also validate the performance
   of our method by comparing with two classic machine learning methods and
   three related published results. The proposed model outperforms the
   other models in the Accuracy and F1-score metrics, it also requires less
   prediction time.}},
Publisher = {{UNION SCIENTISTS BULGARIA}},
Address = {{1505 SOFIA 39, MADRID BLVD, FLR 2, SOFIA, 00000, BULGARIA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Mohamed, S (Corresponding Author), Univ Gabes, Natl Engn Sch Gabes, Res Team Intelligent Machines RTIM, Gabes, Tunisia.
   Mohamed, Safa; Ejbali, Ridha, Univ Gabes, Natl Engn Sch Gabes, Res Team Intelligent Machines RTIM, Gabes, Tunisia.}},
ISSN = {{1313-8251}},
Keywords = {{Anomaly detection; NSL-KDD; NIDS; deep reinforcement learning; deep
   SARSA}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems}},
Author-Email = {{safamohamed280@yahoo.fr}},
ResearcherID-Numbers = {{Ejbali, Ridha/K-4234-2012}},
ORCID-Numbers = {{Ejbali, Ridha/0000-0002-8148-1621}},
Funding-Acknowledgement = {{General Direction of Scientific Research (DGRST), Tunisia, under the
   ARUB program}},
Funding-Text = {{The authors would like to acknowledge the financial support of this work
   by grants from General Direction of Scientific Research (DGRST),
   Tunisia, under the ARUB program.}},
Number-of-Cited-References = {{28}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{Int. J. Inf. Technol. Secur.}},
Doc-Delivery-Number = {{UK2HH}},
Unique-ID = {{WOS:000691795400008}},
DA = {{2021-11-23}},
}

@article{ WOS:000431441200012,
Author = {Yin, Zhizhou and Wang, Fei and Liu, Wei and Chawla, Sanjay},
Title = {{Sparse Feature Attacks in Adversarial Learning}},
Journal = {{IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING}},
Year = {{2018}},
Volume = {{30}},
Number = {{6}},
Pages = {{1164-1177}},
Month = {{JUN 1}},
Abstract = {{Adversarial learning is the study of machine learning techniques
   deployed in non-benign environments. Example applications include
   classification for detecting spam, network intrusion detection, and
   credit card scoring. In fact, as the use of machine learning grows in
   diverse application domains, the possibility for adversarial behavior is
   likely to increase. When adversarial learning is modelled in a
   game-theoretic setup, the standard assumption about the adversary
   (player) behavior is the ability to change all features of the
   classifiers (the opponent player) at will. The adversary pays a cost
   proportional to the size of the ``attack{''}. We refer to this form of
   adversarial behavior as a dense feature attack. However, the aim of an
   adversary is not just to subvert a classifier but carry out data
   transformation in a way such that spam continues to remain effective. We
   demonstrate that an adversary could potentially achieve this objective
   by carrying out a sparse feature attack. We design an algorithm to show
   how a classifier should be designed to be robust against sparse
   adversarial attacks. Our main insight is that sparse feature attacks are
   best defended by designing classifiers which use l(1) regularizers.}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Liu, W (Corresponding Author), Univ Technol Sydney, Adv Analyt Inst, Ultimo, NSW 2007, Australia.
   Yin, Zhizhou; Wang, Fei, Univ Sydney, Sch Informat Technol, Camperdown, NSW 2006, Australia.
   Liu, Wei, Univ Technol Sydney, Adv Analyt Inst, Ultimo, NSW 2007, Australia.
   Chawla, Sanjay, HBKU, Qatar Comp Res Inst, Doha 34110, Qatar.}},
DOI = {{10.1109/TKDE.2018.2790928}},
ISSN = {{1041-4347}},
EISSN = {{1558-2191}},
Keywords = {{Adversarial learning; sparse modelling; l(1) regularizer; stackelberg
   game; nash equilibrium}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical \& Electronic}},
Author-Email = {{zyin4256@uni.sydney.edu.au
   fwan7956@uni.sydney.edu.au
   wei.liu@uts.edu.au
   schawla@qf.org.qa}},
Number-of-Cited-References = {{33}},
Times-Cited = {{8}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{10}},
Journal-ISO = {{IEEE Trans. Knowl. Data Eng.}},
Doc-Delivery-Number = {{GE7VM}},
Unique-ID = {{WOS:000431441200012}},
DA = {{2021-11-23}},
}

@article{ WOS:000372921300022,
Author = {Arthur, Menaka Pushpa and Kannan, Kathiravan},
Title = {{Cross-layer based multiclass intrusion detection system for secure
   multicast communication of MANET in military networks}},
Journal = {{WIRELESS NETWORKS}},
Year = {{2016}},
Volume = {{22}},
Number = {{3}},
Pages = {{1035-1059}},
Month = {{APR}},
Abstract = {{Multicast communication of mobile ad hoc networks (MANET), rather than
   multiple unicast communication, delivers common content to more than one
   receiver at a time. Due to cutting-edge communication technology and
   advancements in terms of radio-mounted devices, groups in front-end war
   field, as well as rescue troops, are well connected to carry out their
   missions using multicast communication. The key to the success of
   military networks in a hostile environment is security and
   collaboration. Internal attacks are major threats to impose a great
   failure in their mission goal. We introduce a novel indirect internal
   stealthy attack and known direct internal stealthy attacks such as black
   hole and deny-to-forward attacks on tree-based multicast routing
   protocol. These internal attacks can induce the performance degradation
   in the multicast group. We design a distributed cross-layer based
   machine learning anomaly detection system for multicast communication of
   MANET. Using efficient multilayer features, rather than routing layer
   features alone, improve the accuracy of the Intrusion Detection System
   (IDS) in terms of detection of direct and indirect internal stealthy
   attacks. We evaluate the sensitivity, specificity and detection accuracy
   of well-known multiclass classifiers in combination with various feature
   subset selection algorithms. Since our problem with classification is a
   multiclass, the performance metrics calculated here are different from
   the binary classifiers. Our IDS is efficient, with respect to high true
   positives, very low false positives and less resource consumption even
   in the very challenging conditions of multicast communication of ad hoc
   networks.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Arthur, MP (Corresponding Author), Anna Univ, Madras 600025, Tamil Nadu, India.
   Arthur, Menaka Pushpa, Anna Univ, Madras 600025, Tamil Nadu, India.
   Kannan, Kathiravan, Easwari Engn Coll, Madras, Tamil Nadu, India.}},
DOI = {{10.1007/s11276-015-1065-2}},
ISSN = {{1022-0038}},
EISSN = {{1572-8196}},
Keywords = {{MANET; Multicast communication; Military networks; IDS; Internal
   stealthy attack; Cross-layer; Multiclass classifier; Feature subset
   selection algorithm; More}},
Keywords-Plus = {{HOC; PROTOCOL; ATTACKS}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{menaka\_engg@yahoo.com}},
ResearcherID-Numbers = {{Arthur, Menaka Pushpa/I-9163-2019}},
Number-of-Cited-References = {{46}},
Times-Cited = {{14}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{23}},
Journal-ISO = {{Wirel. Netw.}},
Doc-Delivery-Number = {{DH6SI}},
Unique-ID = {{WOS:000372921300022}},
DA = {{2021-11-23}},
}

@article{ WOS:000660636700003,
Author = {Siniosoglou, Ilias and Radoglou-Grammatikis, Panagiotis and
   Efstathopoulos, Georgios and Fouliras, Panagiotis and Sarigiannidis,
   Panagiotis},
Title = {{A Unified Deep Learning Anomaly Detection and Classification Approach
   for Smart Grid Environments}},
Journal = {{IEEE TRANSACTIONS ON NETWORK AND SERVICE MANAGEMENT}},
Year = {{2021}},
Volume = {{18}},
Number = {{2}},
Pages = {{1137-1151}},
Month = {{JUN}},
Abstract = {{The interconnected and heterogeneous nature of the next-generation
   Electrical Grid (EG), widely known as Smart Grid (SG), bring severe
   cybersecurity and privacy risks that can also raise domino effects
   against other Critical Infrastructures (CIs). In this paper, we present
   an Intrusion Detection System (IDS) specially designed for the SG
   environments that use Modbus/Transmission Control Protocol (TCP) and
   Distributed Network Protocol 3 (DNP3) protocols. The proposed IDS called
   MENSA (anoMaly dEtection aNd claSsificAtion) adopts a novel
   Autoencoder-Generative Adversarial Network (GAN) architecture for (a)
   detecting operational anomalies and (b) classifying Modbus/TCP and DNP3
   cyberattacks. In particular, MENSA combines the aforementioned Deep
   Neural Networks (DNNs) in a common architecture, taking into account the
   adversarial loss and the reconstruction difference. The proposed IDS is
   validated in four real SG evaluation environments, namely (a) SG lab,
   (b) substation, (c) hydropower plant and (d) power plant, solving
   successfully an outlier detection (i.e., anomaly detection) problem as
   well as a challenging multiclass classification problem consisting of 14
   classes (13 Modbus/TCP cyberattacks and normal instances). Furthermore,
   MENSA can discriminate five cyberattacks against DNP3. The evaluation
   results demonstrate the efficiency of MENSA compared to other Machine
   Learning (ML) and Deep Learning (DL) methods in terms of Accuracy, False
   Positive Rate (FPR), True Positive Rate (TPR) and the F1 score.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Sarigiannidis, P (Corresponding Author), Univ Western Macedonia, Dept Elect \& Comp Engn, Kozani 50100, Greece.
   Siniosoglou, Ilias; Radoglou-Grammatikis, Panagiotis; Sarigiannidis, Panagiotis, Univ Western Macedonia, Dept Elect \& Comp Engn, Kozani 50100, Greece.
   Efstathopoulos, Georgios, 0 Infin Ltd, Res \& Dev, London E6 2JG, England.
   Fouliras, Panagiotis, Univ Macedonia, Dept Appl Informat, Thessaloniki 54636, Greece.}},
DOI = {{10.1109/TNSM.2021.3078381}},
ISSN = {{1932-4537}},
Keywords = {{Computer crime; Protocols; Intrusion detection; Anomaly detection;
   Substations; Engines; Decision trees; Anomaly detection; auto-encoder;
   cybersecurity; generative adversarial network; deep learning; machine
   learning; modbus; smart grid}},
Keywords-Plus = {{INTRUSION DETECTION; TRAFFIC ANALYSIS; NETWORK; SECURITY; PRIVACY;
   ATTACKS; SYSTEMS}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems}},
Author-Email = {{isiniosoglou@uowm.gr
   pradoglou@uowm.gr
   george@0infinity.net
   psarigiannidis@uowm.gr
   pfoul@uom.edu.gr}},
ResearcherID-Numbers = {{Radoglou-Grammatikis, Panagiotis/AAF-4162-2021
   Sarigiannidis, Panagiotis/O-5246-2017}},
ORCID-Numbers = {{Radoglou-Grammatikis, Panagiotis/0000-0003-1605-9413
   Fouliras, Panagiotis/0000-0002-0879-7005
   Sarigiannidis, Panagiotis/0000-0001-6042-0355}},
Funding-Acknowledgement = {{European Unions Horizon 2020 research and innovation programme
   {[}787011]}},
Funding-Text = {{Manuscript received October 15, 2020; revised March 14, 2021 and April
   28, 2021; accepted April 29, 2021. Date of publication May 7, 2021; date
   of current version June 10, 2021. This project has received funding from
   the European Unions Horizon 2020 research and innovation programme under
   grant agreement No. 787011 (SPEAR). The associate editor coordinating
   the review of this article and approving it for publication was Q. Li.}},
Number-of-Cited-References = {{62}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{3}},
Journal-ISO = {{IEEE Trans. Netw. Serv. Manag.}},
Doc-Delivery-Number = {{SQ8YX}},
Unique-ID = {{WOS:000660636700003}},
OA = {{Green Published, Bronze}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000380441200025,
Author = {Nelson, Kevin and Corbin, George and Amnia, Mark and Kovacs, Matthew and
   Tobias, Jeremy and Blowers, Misty},
Book-Group-Author = {{IEEE}},
Title = {{Evaluating Model Drift in Machine Learning Algorithms}},
Booktitle = {{2015 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE FOR SECURITY AND
   DEFENSE APPLICATIONS (CISDA)}},
Year = {{2015}},
Pages = {{162-169}},
Note = {{IEEE Symposium on Computational Intelligence for Security and Defense
   Applications (CISDA), Verona, NY, MAY 26-26, 2015}},
Abstract = {{Machine learning is rapidly emerging as a valuable technology thanks to
   its ability to learn patterns from large data sets and solve problems
   that are impossible to model using conventional programming logic. As
   machine learning techniques become more mainstream, they are being
   applied to a wider range of application domains. These algorithms are
   now trusted to make critical decisions in secure and adversarial
   environments such as healthcare, fraud detection, and network security,
   in which mistakes can be incredibly costly. They are also a critical
   component to most modern autonomous systems. However, the data driven
   approach utilized by these machine learning methods can prove to be a
   weakness if the data on which the models rely are corrupted by either
   nefarious or accidental means. Models that utilize on-line learning or
   periodic retraining to learn new patterns and account for data
   distribution changes are particularly susceptible to corruption through
   model drift. In modeling this type of scenario, specially crafted data
   points are added to the training set over time to adversely influence
   the system, inducing model drift which leads to incorrect
   classifications. Our work is focused on exploring the resistance of
   various machine learning algorithms to such an approach. In this paper
   we present an experimental framework designed to measure the
   susceptibility of anomaly detection algorithms to model drift. We also
   exhibit our preliminary results using various machine learning
   algorithms commonly found in intrusion detection research.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Nelson, K (Corresponding Author), BAE Syst, Rome, NY 13440 USA.
   Nelson, Kevin; Corbin, George; Amnia, Mark; Kovacs, Matthew; Tobias, Jeremy, BAE Syst, Rome, NY 13440 USA.
   Blowers, Misty, Air Force Res Lab, Rome, NY USA.}},
ISBN = {{978-1-4673-7557-3}},
Keywords = {{adversarial machine learning; cyber security; intrusion detection
   systems; model drift}},
Keywords-Plus = {{INTRUSION DETECTION}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods; Engineering, Electrical \& Electronic}},
Number-of-Cited-References = {{19}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{3}},
Doc-Delivery-Number = {{BF1WS}},
Unique-ID = {{WOS:000380441200025}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000507577500057,
Author = {Bor, Martin C. and Marnerides, Angelos K. and Molineux, Andy and Wattam,
   Steve and Roedig, Utz},
Book-Group-Author = {{Assoc Comp Machinery}},
Title = {{Adversarial Machine Learning in Smart Energy Systems}},
Booktitle = {{E-ENERGY'19: PROCEEDINGS OF THE 10TH ACM INTERNATIONAL CONFERENCE ON
   FUTURE ENERGY SYSTEMS}},
Year = {{2019}},
Pages = {{413-415}},
Note = {{10th ACM International Conference on Future Energy Systems (e-Energy),
   Phoenix, AZ, JUN 25-28, 2019}},
Organization = {{Assoc Comp Machinery; State Grid GEINI N Amer; IBM Res Australia; Trend
   Micro; Assoc Comp Machinery Emerging Interest Grp Energy Syst \&
   Informat}},
Abstract = {{Smart Energy Systems represent a radical shift in the approach to energy
   generation and demand, driven by decentralisation of the energy system
   to large numbers of low-capacity devices. Managing this flexibility is
   often driven by machine learning, and requires real-time control and
   aggregation of these devices, involving a diverse set of companies and
   devices and creating a longer chain of trust. This poses a security
   risk, as it is sensitive to adversarial machine learning, whereby models
   are fooled through malicious input, either for financial gain or to
   cause system disruption. We show the feasibility of such an attack by
   analysing empirical data of a real system, and propose directions for
   future research related to detection and defence mechanisms for these
   kind of attacks.}},
Publisher = {{ASSOC COMPUTING MACHINERY}},
Address = {{1515 BROADWAY, NEW YORK, NY 10036-9998 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Bor, MC (Corresponding Author), Univ Lancaster, SCC, Lancaster, England.
   Bor, Martin C.; Marnerides, Angelos K., Univ Lancaster, SCC, Lancaster, England.
   Molineux, Andy; Wattam, Steve, Upside Energy Ltd, Manchester, Lancs, England.
   Roedig, Utz, Univ Coll Cork, Sch Comp Sci \& Informat Technol, Cork, Ireland.}},
DOI = {{10.1145/3307772.3330171}},
ISBN = {{978-1-4503-6671-7}},
Keywords = {{smart energy systems; intrusion detection; adversarial machine learning}},
Research-Areas = {{Computer Science; Energy \& Fuels}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods; Energy \& Fuels}},
Author-Email = {{m.bor@lancaster.ac.uk
   angelos.marnerides@lancaster.ac.uk
   andym@upsideenergy.co.uk
   stevew@upsideenergy.co.uk
   u.roedig@cs.ucc.ie}},
ORCID-Numbers = {{Marnerides, Angelos/0000-0002-7996-6216
   Bor, Martin/0000-0002-8694-1666}},
Funding-Acknowledgement = {{Innovate UK Knowledge Transfer Partnership (KTP) {[}10838]}},
Funding-Text = {{This work was supported by the Innovate UK Knowledge Transfer
   Partnership (KTP) Project partnership number 10838.}},
Number-of-Cited-References = {{13}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BO2QT}},
Unique-ID = {{WOS:000507577500057}},
OA = {{Green Accepted}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000389267400122,
Author = {Wang, Fei and Liu, Wei and Chawla, Sanjay},
Editor = {{Kumar, R and Toivonen, H and Pei, J and Huang, JZ and Wu, X}},
Title = {{On Sparse Feature Attacks in Adversarial Learning}},
Booktitle = {{2014 IEEE INTERNATIONAL CONFERENCE ON DATA MINING (ICDM)}},
Series = {{IEEE International Conference on Data Mining}},
Year = {{2014}},
Pages = {{1013-1018}},
Note = {{14th IEEE International Conference on Data Mining (IEEE ICDM), Shenzhen,
   PEOPLES R CHINA, DEC 14-17, 2014}},
Organization = {{Baidu; HUAWEI; PINGAN; IBM Res; KNIME; Alberta Innovates Ctr Machine
   Learning; IEEE; IEEE Comp Soc}},
Abstract = {{Adversarial learning is the study of machine learning techniques
   deployed in non-benign environments. Example applications include
   classifications for detecting spam email, network intrusion detection
   and credit card scoring. In fact as the gamut of application domains of
   machine learning grows, the possibility and opportunity for adversarial
   behavior will only increase.
   Till now, the standard assumption about modeling adversarial behavior
   has been to empower an adversary to change all features of the
   classifiers at will. The adversary pays a cost proportional to the size
   of ``attack{''}. We refer to this form of adversarial behavior as a
   dense feature attack.
   However, the aim of an adversary is not just to subvert a classifier but
   carry out data transformation in a way such that spam continues to
   appear like spam to the user as much as possible. We demonstrate that an
   adversary achieves this objective by carrying out a sparse feature
   attack. We design an algorithm to show how a classifier should be
   designed to be robust against sparse adversarial attacks. Our main
   insight is that sparse feature attacks are best defended by designing
   classifiers which use l(1) regularizers.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Wang, F (Corresponding Author), Univ Sydney, Sch Informat Technol, Sydney, NSW 2006, Australia.
   Wang, Fei; Chawla, Sanjay, Univ Sydney, Sch Informat Technol, Sydney, NSW 2006, Australia.
   Liu, Wei, Univ Technol Sydney, Adv Analyt Inst, Sydney, NSW, Australia.}},
DOI = {{10.1109/ICDM.2014.117}},
ISSN = {{1550-4786}},
ISBN = {{978-1-4799-4303-6}},
Keywords = {{Adversarial learning; Sparse modelling; l(1) regularizer}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Information
   Systems}},
Author-Email = {{fwan7956@uni.sydney.edu.au
   wei.liu@uts.edu.au
   sanjay.chawla@sydney.edu.au}},
Number-of-Cited-References = {{17}},
Times-Cited = {{25}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{4}},
Doc-Delivery-Number = {{BG4YF}},
Unique-ID = {{WOS:000389267400122}},
DA = {{2021-11-23}},
}

@article{ WOS:000673518500051,
Author = {Xie, Guoqi and Yang, Laurence T. and Yang, Yuanda and Luo, Haibo and Li,
   Renfa and Alazab, Mamoun},
Title = {{Threat Analysis for Automotive CAN Networks: A GAN Model-Based Intrusion
   Detection Technique}},
Journal = {{IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS}},
Year = {{2021}},
Volume = {{22}},
Number = {{7}},
Pages = {{4467-4477}},
Month = {{JUL}},
Abstract = {{With the rapid development of Internet of vehicles, connected vehicles,
   autonomous vehicles, and autonomous driving technologies, automotive
   Controller Area Networks (CAN) have suffered from numerous security
   threats. Deep learning models are the current mainstream intrusion
   detection techniques for threat analysis, and the state-of-the-art
   intrusion detection technique introduces the Generative Adversarial
   Networks (GAN) model to generate usable attacked samples to supplement
   the training samples, but it exists the limitations of rough CAN message
   block construction and fails to detect the data tampering threat. Based
   on the CAN communication matrix defined by the automotive Original
   Equipment Manufacturer (OEM) for a vehicle model, we propose an enhanced
   deep learning GAN model with elaborate CAN message blocks and the
   enhanced GAN discriminator. The elaborate CAN message blocks in the
   training samples can precisely reflect the real generated CAN message
   blocks in the detection phase. The GAN discriminator can detect whether
   each message has suffered from the data tampering threat. Experimental
   results illustrate that the enhanced deep learning GAN model has higher
   detection accuracy, recall, and F1 scores than the state-of-the-art deep
   learning GAN model under various attacks and threats.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Alazab, M (Corresponding Author), Charles Darwin Univ, Coll Engn IT \& Environm, Casuarina, NT 0810, Australia.
   Xie, Guoqi; Yang, Yuanda; Li, Renfa, Hunan Univ, Coll Comp Sci \& Elect Engn, Key Lab Embedded \& Network Comp Hunan Prov, Changsha 410082, Peoples R China.
   Yang, Laurence T., St Francis Xavier Univ, Dept Comp Sci, Antigonish, NS B2G 2W5, Canada.
   Luo, Haibo, Minjiang Univ, Coll Comp \& Control Engn, Fuzhou 350108, Peoples R China.
   Alazab, Mamoun, Charles Darwin Univ, Coll Engn IT \& Environm, Casuarina, NT 0810, Australia.}},
DOI = {{10.1109/TITS.2021.3055351}},
ISSN = {{1524-9050}},
EISSN = {{1558-0016}},
Keywords = {{Automotive networks; deep learning; intrusion detection; threat analysis}},
Research-Areas = {{Engineering; Transportation}},
Web-of-Science-Categories  = {{Engineering, Civil; Engineering, Electrical \& Electronic;
   Transportation Science \& Technology}},
Author-Email = {{xgqman@hnu.edu.cn
   ltyang@ieee.org
   yyd@hnu.edu.cn
   robhappy@mju.edu.cn
   lirenfa@hnu.edu.cn
   alazab.m@ieee.org}},
ORCID-Numbers = {{Xie, Guoqi/0000-0001-6625-0350
   Yang, Laurence T./0000-0002-7986-4244
   Alazab, Mamoun/0000-0002-1928-3704}},
Funding-Acknowledgement = {{National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}61932010, 61972139, 61672217, 61702172];
   Open Research Project of the Electronic Information and Control of
   Fujian University Engineering Research Center, Minjiang University,
   China {[}MJXY-KF-EIC1902]; Fundamental Research Funds for the Central
   Universities, Hunan University, China}},
Funding-Text = {{This work was supported in part by the National Natural Science
   Foundation of China under Grant 61932010, Grant 61972139, Grant
   61672217, and Grant 61702172; in part by the Open Research Project of
   the Electronic Information and Control of Fujian University Engineering
   Research Center, Minjiang University, China, under Grant
   MJXY-KF-EIC1902; and in part by the Fundamental Research Funds for the
   Central Universities, Hunan University, China.}},
Number-of-Cited-References = {{24}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{5}},
Usage-Count-Since-2013 = {{5}},
Journal-ISO = {{IEEE Trans. Intell. Transp. Syst.}},
Doc-Delivery-Number = {{TJ5JU}},
Unique-ID = {{WOS:000673518500051}},
DA = {{2021-11-23}},
}

@article{ WOS:000354468900005,
Author = {Tapiador, Juan E. and Orfila, Agustin and Ribagorda, Arturo and Ramos,
   Benjamin},
Title = {{Key-Recovery Attacks on KIDS, a Keyed Anomaly Detection System}},
Journal = {{IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING}},
Year = {{2015}},
Volume = {{12}},
Number = {{3}},
Pages = {{312-325}},
Month = {{MAY-JUN}},
Abstract = {{Most anomaly detection systems rely on machine learning algorithms to
   derive a model of normality that is later used to detect suspicious
   events. Some works conducted over the last years have pointed out that
   such algorithms are generally susceptible to deception, notably in the
   form of attacks carefully constructed to evade detection. Various
   learning schemes have been proposed to overcome this weakness. One such
   system is Keyed IDS (KIDS), introduced at DIMVA ``10. KIDS{''} core idea
   is akin to the functioning of some cryptographic primitives, namely to
   introduce a secret element (the key) into the scheme so that some
   operations are infeasible without knowing it. In KIDS the learned model
   and the computation of the anomaly score are both key-dependent, a fact
   which presumably prevents an attacker from creating evasion attacks. In
   this work we show that recovering the key is extremely simple provided
   that the attacker can interact with KIDS and get feedback about probing
   requests. We present realistic attacks for two different adversarial
   settings and show that recovering the key requires only a small amount
   of queries, which indicates that KIDS does not meet the claimed security
   properties. We finally revisit KIDS' central idea and provide heuristic
   arguments about its suitability and limitations.}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Tapiador, JE (Corresponding Author), Univ Carlos III Madrid, Dept Comp Sci, Madrid 28911, Spain.
   Tapiador, Juan E.; Orfila, Agustin; Ribagorda, Arturo; Ramos, Benjamin, Univ Carlos III Madrid, Dept Comp Sci, Madrid 28911, Spain.}},
DOI = {{10.1109/TDSC.2013.39}},
ISSN = {{1545-5971}},
EISSN = {{1941-0018}},
Keywords = {{Adversarial classification; anomaly detection; intrusion detection
   systems; secure machine learning}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Hardware \& Architecture; Computer Science,
   Information Systems; Computer Science, Software Engineering}},
Author-Email = {{jestevez@inf.uc3m.es
   adiaz@inf.uc3m.es
   arturo@inf.uc3m.es
   benja1@inf.uc3m.es}},
ResearcherID-Numbers = {{Tapiador, Juan/G-2304-2016}},
ORCID-Numbers = {{Tapiador, Juan/0000-0002-4573-3967}},
Number-of-Cited-References = {{22}},
Times-Cited = {{7}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{11}},
Journal-ISO = {{IEEE Trans. Dependable Secur. Comput.}},
Doc-Delivery-Number = {{CI0ZJ}},
Unique-ID = {{WOS:000354468900005}},
DA = {{2021-11-23}},
}

@article{ WOS:000525406600025,
Author = {Zhang, Xueqin and Zhou, Yue and Pei, Songwen and Zhuge, Jingjing and
   Chen, Jiahao},
Title = {{Adversarial Examples Detection for XSS Attacks Based on Generative
   Adversarial Networks}},
Journal = {{IEEE ACCESS}},
Year = {{2020}},
Volume = {{8}},
Pages = {{10989-10996}},
Abstract = {{Models based on deep learning are prone to misjudging the results when
   faced with adversarial examples. In this paper, we propose an MCTS-T
   algorithm for generating adversarial examples of cross-site scripting
   (XSS) attacks based on Monte Carlo tree search (MCTS) algorithm. The
   MCTS algorithm enables the generation model to provide a reward value
   that reflects the probability of generative examples bypassing the
   detector. To guarantee the antagonism and feasibility of the generative
   adversarial examples, the bypassing rules are restricted. The
   experimental results indicate that the missed detection rate of
   adversarial examples is significantly improved after the MCTS-T
   generation algorithm. Additionally, we construct a generative
   adversarial network (GAN) to optimize the detector and improve the
   detection rate when dealing with adversarial examples. After several
   epochs of adversarial training, the accuracy of detecting adversarial
   examples is significantly improved.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Zhang, XQ (Corresponding Author), East China Univ Sci \& Technol, Dept Elect \& Commun Engn, Shanghai 200237, Peoples R China.
   Pei, SW (Corresponding Author), Univ Shanghai Sci \& Technol, Dept Comp Sci \& Engn, Shanghai 200093, Peoples R China.
   Zhang, Xueqin; Zhou, Yue; Zhuge, Jingjing; Chen, Jiahao, East China Univ Sci \& Technol, Dept Elect \& Commun Engn, Shanghai 200237, Peoples R China.
   Pei, Songwen, Univ Shanghai Sci \& Technol, Dept Comp Sci \& Engn, Shanghai 200093, Peoples R China.}},
DOI = {{10.1109/ACCESS.2020.2965184}},
ISSN = {{2169-3536}},
Keywords = {{Network intrusion detection; generative adversarial network; Monte Carlo
   tree; convolutional neural networks}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{zxq@ecust.edu.cn
   swpei@usst.edu.cn}},
ORCID-Numbers = {{Zhou, Yue/0000-0002-4851-7493
   Zhang, Xueqin/0000-0001-7020-1033
   Chen, Jiahao/0000-0002-2082-4379}},
Funding-Acknowledgement = {{Natural Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) {[}NNSFC 61472139]}},
Funding-Text = {{This work was supported by the Natural Science Foundation of China under
   Grant NNSFC 61472139.}},
Number-of-Cited-References = {{19}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{8}},
Usage-Count-Since-2013 = {{17}},
Journal-ISO = {{IEEE Access}},
Doc-Delivery-Number = {{LC5YC}},
Unique-ID = {{WOS:000525406600025}},
OA = {{gold}},
DA = {{2021-11-23}},
}

@article{ WOS:000634224400001,
Author = {Kwon, Hyun and Lee, Jun},
Title = {{Diversity Adversarial Training against Adversarial Attack on Deep Neural
   Networks}},
Journal = {{SYMMETRY-BASEL}},
Year = {{2021}},
Volume = {{13}},
Number = {{3}},
Month = {{MAR}},
Abstract = {{This paper presents research focusing on visualization and pattern
   recognition based on computer science. Although deep neural networks
   demonstrate satisfactory performance regarding image and voice
   recognition, as well as pattern analysis and intrusion detection, they
   exhibit inferior performance towards adversarial examples. Noise
   introduction, to some degree, to the original data could lead
   adversarial examples to be misclassified by deep neural networks, even
   though they can still be deemed as normal by humans. In this paper, a
   robust diversity adversarial training method against adversarial attacks
   was demonstrated. In this approach, the target model is more robust to
   unknown adversarial examples, as it trains various adversarial samples.
   During the experiment, Tensorflow was employed as our deep learning
   framework, while MNIST and Fashion-MNIST were used as experimental
   datasets. Results revealed that the diversity training method has
   lowered the attack success rate by an average of 27.2 and 24.3\% for
   various adversarial examples, while maintaining the 98.7 and 91.5\%
   accuracy rates regarding the original data of MNIST and Fashion-MNIST.}},
Publisher = {{MDPI}},
Address = {{ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Lee, J (Corresponding Author), Hoseo Univ, Div Comp Informat \& Sci, Asan 31499, South Korea.
   Kwon, Hyun, Korea Mil Acad, Dept Elect Engn, Seoul 01805, South Korea.
   Lee, Jun, Hoseo Univ, Div Comp Informat \& Sci, Asan 31499, South Korea.}},
DOI = {{10.3390/sym13030428}},
Article-Number = {{428}},
EISSN = {{2073-8994}},
Keywords = {{machine learning; adversarial example; defense technology; deep neural
   network (DNN)}},
Keywords-Plus = {{ROBUSTNESS; EXAMPLE}},
Research-Areas = {{Science \& Technology - Other Topics}},
Web-of-Science-Categories  = {{Multidisciplinary Sciences}},
Author-Email = {{hkwon.cs@gmail.com
   junlee@game.hoseo.edu}},
ResearcherID-Numbers = {{Kwon, Hyun/M-1140-2018}},
ORCID-Numbers = {{Kwon, Hyun/0000-0003-1169-9892}},
Funding-Acknowledgement = {{Korea Military Academy (CyberWarfare Research Center); Hwarang-Dae
   Research Institute of Korea Military Academy}},
Funding-Text = {{This work was supported by 2021 (21-center-1) research fund of Korea
   Military Academy (CyberWarfare Research Center) and was supported by
   Hwarang-Dae Research Institute of Korea Military Academy.}},
Number-of-Cited-References = {{41}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{4}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{Symmetry-Basel}},
Doc-Delivery-Number = {{RE5WQ}},
Unique-ID = {{WOS:000634224400001}},
OA = {{gold}},
DA = {{2021-11-23}},
}

@article{ WOS:000446239400091,
Author = {Sharma, Rupam Kumar and Kalita, Hemanta Kr and Issac, Biju},
Title = {{Are machine learning based intrusion detection system always secure? An
   insight into tampered learning}},
Journal = {{JOURNAL OF INTELLIGENT \& FUZZY SYSTEMS}},
Year = {{2018}},
Volume = {{35}},
Number = {{3}},
Pages = {{3635-3651}},
Abstract = {{Machine Learning is successful in many applications including securing a
   network from unseen attack. The application of learning algorithm for
   detecting anomaly in a Network has been fundamental since few years.
   With increasing use of machine learning techniques it has become
   important to study to what extent it is good to be dependent on them.
   Altogether a different discipline called `Adversarial Learning' have
   come up as a separate dimension of study. The work in this paper is to
   test the robustness of online machine learning based IDS to carefully
   crafted packets by attacker called poison packets. The objective is to
   observe how a remote attacker can deviate the normal behavior of machine
   learning based classifier in the IDS by injecting the network with
   carefully crafted packets externally, that may seem normal by the
   classification algorithm and the instance made part of its future
   training set. This behavior eventually can lead to a poison learning by
   the classification algorithm in the long run, resulting in
   misclassification of true attack instances. This work explores one such
   approach with SOM and SVM as the online learning based classification
   algorithms.}},
Publisher = {{IOS PRESS}},
Address = {{NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Sharma, RK (Corresponding Author), NEHU, Dept Informat Techcnol, Shillong, Meghalayn, India.
   Sharma, Rupam Kumar; Kalita, Hemanta Kr, NEHU, Dept Informat Techcnol, Shillong, Meghalayn, India.
   Issac, Biju, Teesside Univ, Sch Comp Media \& Arts, Middlesbrough, Cleveland, England.}},
DOI = {{10.3233/JIFS-18202}},
ISSN = {{1064-1246}},
EISSN = {{1875-8967}},
Keywords = {{Adversarial learning; machine learning; poison learning; intrusion
   detection system; artificial intelligence; NSL-KDD dataset; SVM; support
   vectors}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{rupam.sharma@dbuniversity.ac.in}},
ResearcherID-Numbers = {{Kalita, Hemanta Kumar/AAS-3829-2021
   Issac, Biju/AAA-3802-2019
   Issac, Biju/E-2465-2011}},
ORCID-Numbers = {{Issac, Biju/0000-0002-1109-8715}},
Number-of-Cited-References = {{57}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{9}},
Journal-ISO = {{J. Intell. Fuzzy Syst.}},
Doc-Delivery-Number = {{GV6QR}},
Unique-ID = {{WOS:000446239400091}},
OA = {{Green Accepted}},
DA = {{2021-11-23}},
}

@article{ WOS:000638402100011,
Author = {de Araujo-Filho, Paulo Freitas and Kaddoum, Georges and Campelo,
   Divanilson R. and Santos, Aline Gondim and Macedo, David and Zanchettin,
   Cleber},
Title = {{Intrusion Detection for Cyber-Physical Systems Using Generative
   Adversarial Networks in Fog Environment}},
Journal = {{IEEE INTERNET OF THINGS JOURNAL}},
Year = {{2021}},
Volume = {{8}},
Number = {{8}},
Pages = {{6247-6256}},
Month = {{APR 15}},
Abstract = {{Cyber-attacks cyber-physical systems (CPSs) can lead to sensing and
   actuation misbehavior, severe damages to physical objects, and safety
   risks. Machine learning algorithms have been proposed for hindering
   cyber-attacks on CPSs, but the absence of labeled data from novel
   attacks makes their detection quite challenging. In this context,
   generative adversarial networks (GANs) are a promising unsupervised
   approach to detect cyber-attacks by implicitly modeling the system.
   However, the detection of cyber-attacks on CPSs has strict latency
   requirements, since the attacks need to be stopped before the system is
   compromised. In this article, we propose FID-GAN, a novel fog-based,
   unsupervised intrusion detection system (IDS) for CPSs using GANs. The
   IDS is proposed for a fog architecture, which brings computation
   resources closer to the end nodes and thus contributes to meeting
   low-latency requirements. In order to achieve higher detection rates,
   the proposed architecture computes a reconstruction loss based on the
   reconstruction of data samples mapped to the latent space. Other works
   that follow a similar approach struggle with the time required to
   compute the reconstruction loss, which renders them impractical for
   latency constrained applications. We address this problem by training an
   encoder that accelerates the reconstruction loss computation.
   Experiments show that the proposed solution achieves higher detection
   rates and is at least 5.5 times faster than a baseline approach in the
   three studied data sets.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{de Araujo, PF (Corresponding Author), Univ Quebec, Elect Engn Dept, Ecole Technol Super, Montreal, PQ H3C 1K3, Canada.
   de Araujo-Filho, Paulo Freitas; Kaddoum, Georges, Univ Quebec, Elect Engn Dept, Ecole Technol Super, Montreal, PQ H3C 1K3, Canada.
   de Araujo-Filho, Paulo Freitas; Campelo, Divanilson R.; Santos, Aline Gondim; Macedo, David; Zanchettin, Cleber, Univ Fed Pernambuco, Ctr Informat, BR-50740560 Recife, PE, Brazil.}},
DOI = {{10.1109/JIOT.2020.3024800}},
ISSN = {{2327-4662}},
Keywords = {{Gallium nitride; Computer architecture; Generators; Generative
   adversarial networks; Training; Sensors; Security; Cyber\&\#8211;
   physical systems (CPSs); generative adversarial networks (GANs);
   industrial security; intrusion detection systems (IDSs); machine
   learning}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{paulo.freitas-de-araujo-filho.1@ens.etsmtl.ca
   georges.kaddoum@etsmtl.ca
   dcampelo@cin.ufpe.br
   ags5@cin.ufpe.br
   dlm@cin.ufpe.br
   cz@cin.ufpe.br}},
ResearcherID-Numbers = {{Macedo, David/U-7135-2019
   Zanchettin, Cleber/C-3196-2017
   }},
ORCID-Numbers = {{Macedo, David/0000-0002-2527-4548
   Zanchettin, Cleber/0000-0001-6421-9747
   Campelo, Divanilson/0000-0001-8851-2665
   Freitas de Araujo Filho, Paulo/0000-0002-1178-2648}},
Funding-Acknowledgement = {{Tier 2 Canada Research Chair on the Next Generations of Wireless IoT
   Networks; Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior
   (CAPES)Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior
   (CAPES); Conselho Nacional de Desenvolvimento Cientifico e Tecnologico
   (CNPq)Conselho Nacional de Desenvolvimento Cientifico e Tecnologico
   (CNPQ)}},
Funding-Text = {{This work was supported in part by the Tier 2 Canada Research Chair on
   the Next Generations of Wireless IoT Networks, in part by the
   Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior (CAPES), and
   in part by the Conselho Nacional de Desenvolvimento Cientifico e
   Tecnologico (CNPq).}},
Number-of-Cited-References = {{43}},
Times-Cited = {{6}},
Usage-Count-Last-180-days = {{17}},
Usage-Count-Since-2013 = {{21}},
Journal-ISO = {{IEEE Internet Things J.}},
Doc-Delivery-Number = {{RK6KG}},
Unique-ID = {{WOS:000638402100011}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000655399100040,
Author = {Xiao, Junchao and Wu, Hao and Li, Xiangxue and Yuan, Linghu},
Editor = {{Wen, S and Zomaya, A and Yang, LT}},
Title = {{Practical IDS on In-vehicle Network Against Diversified Attack Models}},
Booktitle = {{ALGORITHMS AND ARCHITECTURES FOR PARALLEL PROCESSING, ICA3PP 2019, PT II}},
Series = {{Lecture Notes in Computer Science}},
Year = {{2020}},
Volume = {{11945}},
Pages = {{456-466}},
Note = {{19th International Conference on Algorithms and Architectures for
   Parallel Processing (ICA3PP), Melbourne, AUSTRALIA, DEC 09-11, 2019}},
Organization = {{Swinburne Univ Technol}},
Abstract = {{A vehicle bus is a specialized internal communication network that
   interconnects components inside a vehicle. The Controller Area Network
   (CAN bus), a robust vehicle bus standard, allows micro-controllers and
   devices to communicate with each other. The community has seen many
   security breach examples that exploit CAN functionalities and other
   in-vehicle flaws. Intrusion detection systems (IDSs) on in-vehicle
   network are advantageous in monitoring CAN traffic and suspicious
   activities. Whereas, existing IDSs on in-vehicle network only support
   one or two attack models, and identifying abnormal in-vehicle CAN
   traffic against diversified attack models with better performance is
   more expected as can be then implemented practically. In this paper, we
   propose an intrusion detection system that can detect many different
   attacks. The method analyzes the CAN traffic generated by the invehicle
   network in real time and identifies the abnormal state of the vehicle
   practically. Our proposal fuses the autoencoder trick to the SVM model.
   More precisely, we introduce to the system an autoencoder that learns to
   compress CAN traffic data into extracted features (which can be
   uncompressed to closely match the original data). Then, the support
   vector machine is trained on the features to detect abnormal traffic. We
   show detailed model parameter configuration by adopting several concrete
   attacks. Experimental results demonstrate better detection performance
   (than existing proposals).}},
Publisher = {{SPRINGER INTERNATIONAL PUBLISHING AG}},
Address = {{GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Li, XX (Corresponding Author), East China Normal Univ, Sch Software Engn, Shanghai, Peoples R China.
   Li, XX (Corresponding Author), Westone Cryptol Res Ctr, Beijing, Peoples R China.
   Xiao, Junchao, Sun Yat Sen Univ, Sch Syst Sci \& Engn, Guangzhou, Peoples R China.
   Xiao, Junchao; Li, Xiangxue; Yuan, Linghu, East China Normal Univ, Sch Software Engn, Shanghai, Peoples R China.
   Li, Xiangxue, Westone Cryptol Res Ctr, Beijing, Peoples R China.
   Wu, Hao, CNCERT CC, Beijing, Peoples R China.}},
DOI = {{10.1007/978-3-030-38961-1\_40}},
ISSN = {{0302-9743}},
EISSN = {{1611-3349}},
ISBN = {{978-3-030-38961-1; 978-3-030-38960-4}},
Keywords = {{In-vehicle network; Intrusion detection systems; Autoencoder}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Hardware \& Architecture; Computer Science, Software
   Engineering; Computer Science, Theory \& Methods}},
Author-Email = {{xxli@cs.ecnu.edu.cn}},
Funding-Acknowledgement = {{National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}61572192, 61971192]; National Cryptography
   Development Fund {[}MMJJ20180106]}},
Funding-Text = {{The paper is supported by the National Natural Science Foundation of
   China (Grant Nos. 61572192, 61971192) and the National Cryptography
   Development Fund (Grant No. MMJJ20180106).}},
Number-of-Cited-References = {{15}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BR5HX}},
Unique-ID = {{WOS:000655399100040}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000522245400084,
Author = {Zhang, Yongxuan and Yan, Jun},
Book-Group-Author = {{IEEE}},
Title = {{Domain-Adversarial Transfer Learning for Robust Intrusion Detection in
   the Smart Grid}},
Booktitle = {{2019 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, CONTROL, AND
   COMPUTING TECHNOLOGIES FOR SMART GRIDS (SMARTGRIDCOMM)}},
Year = {{2019}},
Note = {{IEEE International Conference on Communications, Control, and Computing
   Technologies for Smart Grids (SmartGridComm), Beijing, PEOPLES R CHINA,
   OCT 21-23, 2019}},
Organization = {{IEEE}},
Abstract = {{The smart grid faces growing cyber-physical attack threats aimed at the
   critical systems and processes communicating over the complex
   cyber-infrastructure. Thanks to the increasing availability of
   high-quality data and the success of deep learning algorithms, machine
   learning (ML)-based detection and classification have been increasingly
   effective and adopted against sophisticated attacks. However, many of
   these techniques rely on the assumptions that the training and testing
   datasets share the same distribution and the same class labels in a
   stationary environment. As such assumptions may fail to hold when the
   system dynamics shift and new threat variants emerge in a non-stationary
   environment, the capability of trained ML models to adapt in complex
   operating scenarios will be critical to their deployment in real-world
   smart grid communications. To this aim, this paper proposes a
   domain-adversarial transfer learning framework for robust intrusion
   detection against smart grid attacks. The framework introduces
   domain-adversarial training to create a mapping between the labeled
   source domain and the unlabeled target domain so that the classifiers
   can learn in a new feature space against unknown threats. The proposed
   framework with different baseline classifiers was evaluated using a
   smart grid cyber-attack dataset collected over a realistic
   hardware-in-the-loop security testbed. The results have demonstrated
   effective performance improvements of trained classifiers against unseen
   threats of different types and locations.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Zhang, YX (Corresponding Author), Concordia Univ, Dept Comp Sci \& Software Engn CSSE, Montreal, PQ, Canada.
   Zhang, Yongxuan, Concordia Univ, Dept Comp Sci \& Software Engn CSSE, Montreal, PQ, Canada.
   Yan, Jun, Concordia Univ, CIISE, Montreal, PQ, Canada.}},
ISBN = {{978-1-5386-8099-5}},
Research-Areas = {{Computer Science; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Cybernetics; Computer Science, Theory \& Methods;
   Telecommunications}},
Author-Email = {{z\_yongxu@encs.concordia.ca
   jun.yan@concordia.ca}},
Funding-Acknowledgement = {{Natural Sciences and Engineering Research Council of Canada
   (NSERC)Natural Sciences and Engineering Research Council of Canada
   (NSERC) {[}RGPIN-2018-06724]; Fonds de Recherche du Quebec -Nature et
   Technologies (FRQNT) {[}2019-NC-254971]}},
Funding-Text = {{This work was supported by the Natural Sciences and Engineering Research
   Council of Canada (NSERC) under RGPIN-2018-06724 and the Fonds de
   Recherche du Quebec -Nature et Technologies (FRQNT) under
   2019-NC-254971.}},
Number-of-Cited-References = {{23}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BO6UF}},
Unique-ID = {{WOS:000522245400084}},
DA = {{2021-11-23}},
}

@article{ WOS:000681991000001,
Author = {Dankwa, Stephen and Yang, Lu},
Title = {{Securing IoT Devices: A Robust and Efficient Deep Learning with a Mixed
   Batch Adversarial Generation Process for CAPTCHA Security Verification}},
Journal = {{ELECTRONICS}},
Year = {{2021}},
Volume = {{10}},
Number = {{15}},
Month = {{AUG}},
Abstract = {{The Internet of Things environment (e.g., smart phones, smart
   televisions, and smart watches) ensures that the end user experience is
   easy, by connecting lives on web services via the internet. Integrating
   Internet of Things devices poses ethical risks related to data security,
   privacy, reliability and management, data mining, and knowledge
   exchange. An adversarial machine learning attack is a good practice to
   adopt, to strengthen the security of text-based CAPTCHA (Completely
   Automated Public Turing test to tell Computers and Humans Apart), to
   withstand against malicious attacks from computer hackers, to protect
   Internet of Things devices and the end user's privacy. The goal of this
   current study is to perform security vulnerability verification on
   adversarial text-based CAPTCHA, based on attacker-defender scenarios.
   Therefore, this study proposed computation-efficient deep learning with
   a mixed batch adversarial generation process model, which attempted to
   break the transferability attack, and mitigate the problem of
   catastrophic forgetting in the context of adversarial attack defense.
   After performing K-fold cross-validation, experimental results showed
   that the proposed defense model achieved mean accuracies in the range of
   82-84\% among three gradient-based adversarial attack datasets.}},
Publisher = {{MDPI}},
Address = {{ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Dankwa, S; Yang, L (Corresponding Author), Univ Elect Sci \& Technol China, Sch Automat Engn, Chengdu 611371, Peoples R China.
   Dankwa, Stephen; Yang, Lu, Univ Elect Sci \& Technol China, Sch Automat Engn, Chengdu 611371, Peoples R China.}},
DOI = {{10.3390/electronics10151798}},
Article-Number = {{1798}},
EISSN = {{2079-9292}},
Keywords = {{security; privacy; IoT; artificial intelligence; adversarial machine
   learning; deep learning; convolutional neural network; attacks;
   denoising autoencoder; CAPTCHA}},
Keywords-Plus = {{INTRUSION DETECTION; NETWORK}},
Research-Areas = {{Computer Science; Engineering; Physics}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Physics, Applied}},
Author-Email = {{nabistephen@gmail.com
   yanglu@uestc.edu.cn}},
Funding-Acknowledgement = {{NSFCNational Natural Science Foundation of China (NSFC) {[}61871074]}},
Funding-Text = {{This research was partially supported by NSFC (no. 61871074).}},
Number-of-Cited-References = {{91}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{Electronics}},
Doc-Delivery-Number = {{TV8UJ}},
Unique-ID = {{WOS:000681991000001}},
OA = {{gold}},
DA = {{2021-11-23}},
}

@article{ WOS:000477727300001,
Author = {Yang, Jin and Li, Tao and Liang, Gang and He, Wenbo and Zhao, Yue},
Title = {{A Simple Recurrent Unit Model Based Intrusion Detection System With
   DCGAN}},
Journal = {{IEEE ACCESS}},
Year = {{2019}},
Volume = {{7}},
Pages = {{83286-83296}},
Abstract = {{Due to the complex and time-varying network environments, traditional
   methods are difficult to extract accurate features of intrusion behavior
   from the high-dimensional data samples and process the high-volume of
   these data efficiently. Even worse, the network intrusion samples are
   submerged into a large number of normal data packets, which leads to
   insufficient samples for model training; therefore it is accompanied by
   high false detection rates. To address the challenge of unbalanced
   positive and negative learning samples, we propose using deep
   convolutional generative adversarial networks (DCGAN), which allows
   features to be extracted directly from the rawdata, and then generates
   new training-sets by learning from the rawdata. Given the fact that the
   attack samples are usually intra-dependent time sequence data, we apply
   long short-term memory (LSTM) to automatically learn the features of
   network intrusion behaviors. However, it is hard to parallelize the
   learning/training of the LSTM network, since the LSTM algorithm depends
   on the result of the previous moment. To remove such dependency and
   enable intrusion detection in real time, we propose a simple recurrent
   unit based (SRU)-based model. The proposed model was verified by
   extensive experiments on the benchmark datasets KDD'99 and NSL-KDD,
   which effectively identifies normal and abnormal network activities. It
   achieves 99.73\% accuracy on the KDD'99 dataset and 99.62\% on the
   NSL-KDD dataset.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Liang, G (Corresponding Author), Sichuan Univ, Coll Cyber Secur, Dept Comp \& Software, Chengdu 610017, Sichuan, Peoples R China.
   Yang, Jin; Li, Tao; Liang, Gang, Sichuan Univ, Coll Cyber Secur, Dept Comp \& Software, Chengdu 610017, Sichuan, Peoples R China.
   He, Wenbo, McMaster Univ, Sci \& Technol Commun Secur Lab, Hamilton, ON L8S 4L8, Canada.
   Zhao, Yue, Sci \& Technol Commun Secur Lab, Chengdu 610041, Sichuan, Peoples R China.}},
DOI = {{10.1109/ACCESS.2019.2922692}},
ISSN = {{2169-3536}},
Keywords = {{Network security; deep learning; intrusion detection system (IDS);
   simple recurrent unit; deep convolutional generative adversarial
   networks}},
Keywords-Plus = {{PREDICTION}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{lianggang@scu.edu.cn}},
Funding-Acknowledgement = {{National Key Research and Development Program of China
   {[}2016YFB0800600]; Natural Science Foundation of ChinaNational Natural
   Science Foundation of China (NSFC) {[}61872254, U1736212]; Fundamental
   Research Funds for the Central UniversitiesFundamental Research Funds
   for the Central Universities {[}YJ201727]; Application Foundation
   Project of Sichuan Province Science and Technology Department
   {[}2018JY0913]}},
Funding-Text = {{This work was supported in part by the National Key Research and
   Development Program of China under Grant 2016YFB0800600, in part by the
   Natural Science Foundation of China under Grant 61872254 and Grant
   U1736212, in part by the Fundamental Research Funds for the Central
   Universities under Grant YJ201727, and in part by the Application
   Foundation Project of Sichuan Province Science and Technology Department
   under Grant 2018JY0913.}},
Number-of-Cited-References = {{34}},
Times-Cited = {{14}},
Usage-Count-Last-180-days = {{5}},
Usage-Count-Since-2013 = {{14}},
Journal-ISO = {{IEEE Access}},
Doc-Delivery-Number = {{IM1CY}},
Unique-ID = {{WOS:000477727300001}},
OA = {{gold}},
DA = {{2021-11-23}},
}

@article{ WOS:000496269400024,
Author = {Lee, JooHwa and Park, KeeHyun},
Title = {{AE-CGAN Model based High Performance Network Intrusion Detection System}},
Journal = {{APPLIED SCIENCES-BASEL}},
Year = {{2019}},
Volume = {{9}},
Number = {{20}},
Month = {{OCT}},
Abstract = {{In this paper, a high-performance network intrusion detection system
   based on deep learning is proposed for situations in which there are
   significant imbalances between normal and abnormal traffic. Based on the
   unsupervised learning models autoencoder (AE) and the generative
   adversarial networks (GAN) model during deep learning, the study aim is
   to solve the imbalance of data and intrusion detection of high
   performance. The AE-CGAN (autoencoder-conditional GAN) model is proposed
   to improve the performance of intrusion detection. This model
   oversamples rare classes based on the GAN model in order to solve the
   performance degradation caused by data imbalance after processing the
   characteristics of the data to a lower level using the autoencoder
   model. To measure the performance of the AE-CGAN model, data is
   classified using random forest (RF), a typical machine learning
   classification algorithm. In this experiment, we used the canadian
   institute for cybersecurity intrusion detection system (CICIDS)2017
   dataset, the latest public dataset of network intrusion detection system
   (NIDS), and compared the three models to confirm efficacy of the
   proposed model. We compared the performance of three types of models.
   These included single-RF, a classification model using only a
   classification algorithm, AE-RF which is processed by classifying data
   features, and the AE-CGAN model which is classified after solving the
   data feature processing and data imbalance. Experimental results showed
   that the performance of the AE-CGAN model proposed in this paper was the
   highest. In particular, when the data were unbalanced, the performances
   of recall and F1 score, which are more accurate performance indicators,
   were 93.29\% and 95.38\%, respectively. The AE-CGAN model showed much
   better performance.}},
Publisher = {{MDPI}},
Address = {{ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Park, K (Corresponding Author), Keimyung Univ, Dept Comp Engn, Daegu 42601, South Korea.
   Lee, JooHwa; Park, KeeHyun, Keimyung Univ, Dept Comp Engn, Daegu 42601, South Korea.}},
DOI = {{10.3390/app9204221}},
Article-Number = {{4221}},
EISSN = {{2076-3417}},
Keywords = {{NIDS; GAN; autoencoder; imbalanced data; deep learning; oversampling}},
Keywords-Plus = {{DEEP LEARNING APPROACH; SPARSE AUTOENCODER; FEATURE-EXTRACTION}},
Research-Areas = {{Chemistry; Engineering; Materials Science; Physics}},
Web-of-Science-Categories  = {{Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied}},
Author-Email = {{yezi1004@gmail.com
   khp@kmu.ac.kr}},
ORCID-Numbers = {{lee, joohwa/0000-0002-7855-261X}},
Funding-Acknowledgement = {{Basic Science Research Programs through the National Research Foundation
   of Korea (NRF) - Ministry of Education, Science and Technology; National
   Research Foundation of KoreaNational Research Foundation of Korea
   {[}NRF-2018R1D1A1B07043982]}},
Funding-Text = {{This research was funded by the Basic Science Research Programs through
   the National Research Foundation of Korea (NRF), grant number funded by
   the Ministry of Education, Science and Technology
   (No.NRF-2018R1D1A1B07043982) and The APC was funded by the National
   Research Foundation of Korea (NRF-2018R1D1A1B07043982).}},
Number-of-Cited-References = {{27}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{9}},
Usage-Count-Since-2013 = {{29}},
Journal-ISO = {{Appl. Sci.-Basel}},
Doc-Delivery-Number = {{JM5QU}},
Unique-ID = {{WOS:000496269400024}},
OA = {{gold}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000298615101044,
Author = {Biggio, Battista and Fumera, Giorgio and Roli, Fabio},
Book-Group-Author = {{IEEE}},
Title = {{Design of Robust Classifiers for Adversarial Environments}},
Booktitle = {{2011 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS
   (SMC)}},
Series = {{IEEE International Conference on Systems Man and Cybernetics Conference
   Proceedings}},
Year = {{2011}},
Pages = {{977-982}},
Note = {{IEEE International Conference on Systems, Man and Cybernetics (SMC),
   Anchorage, AK, OCT 09-12, 2011}},
Organization = {{IEEE; IEEE Syst, Man \& Cybernet Soc (IEEE SMC); IEEE Circuits \& Syst
   Soc (CAS); IEEE Engn, Med \& Biol Soc (EMB)}},
Abstract = {{In adversarial classification tasks like spam filtering, intrusion
   detection in computer networks, and biometric identity verification,
   malicious adversaries can design attacks which exploit vulnerabilities
   of machine learning algorithms to evade detection, or to force a
   classification system to generate many false alarms, making it useless.
   Several works have addressed the problem of designing robust classifiers
   against these threats, although mainly focusing on specific applications
   and kinds of attacks. In this work, we propose a model of data
   distribution for adversarial classification tasks, and exploit it to
   devise a general method for designing robust classifiers, focusing on
   generative classifiers. Our method is then evaluated on two case studies
   concerning biometric identity verification and spam filtering.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Biggio, B (Corresponding Author), Univ Cagliari, Dept Elect \& Elect Engn, I-09123 Cagliari, Italy.
   Biggio, Battista; Fumera, Giorgio; Roli, Fabio, Univ Cagliari, Dept Elect \& Elect Engn, I-09123 Cagliari, Italy.}},
ISSN = {{1062-922X}},
ISBN = {{978-1-4577-0653-0}},
Keywords = {{Pattern classification; adversarial classification; robust classifiers}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Computer Science, Information Systems}},
Author-Email = {{battista.biggio@diee.unica.it
   fumera@diee.unica.it
   roli@diee.unica.it}},
ResearcherID-Numbers = {{Biggio, Battista/M-5931-2016}},
ORCID-Numbers = {{Biggio, Battista/0000-0001-7752-509X}},
Number-of-Cited-References = {{20}},
Times-Cited = {{46}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{13}},
Doc-Delivery-Number = {{BYG71}},
Unique-ID = {{WOS:000298615101044}},
OA = {{Green Submitted}},
DA = {{2021-11-23}},
}

@article{ WOS:000466434300006,
Author = {Zhou, Yan and Kantarcioglu, Murat and Xi, Bowei},
Title = {{A survey of game theoretic approach for adversarial machine learning}},
Journal = {{WILEY INTERDISCIPLINARY REVIEWS-DATA MINING AND KNOWLEDGE DISCOVERY}},
Year = {{2019}},
Volume = {{9}},
Number = {{3}},
Month = {{MAY-JUN}},
Abstract = {{The field of machine learning is progressing at a faster pace than ever
   before. Many organizations leverage machine learning tools to extract
   useful information from a massive amount of data. In particular, machine
   learning finds its application in cybersecurity that begins to enter the
   age of automation. However, machine learning applications in
   cybersecurity face unique challenges other domains rarely do-attacks
   from active adversaries. Problems in areas such as intrusion detection,
   banking fraud detection, spam filtering, and malware detection have to
   face challenges of adversarial attacks that modify data so that
   malicious instances would evade detection by the learning systems. The
   adversarial learning problem naturally resembles a game between the
   learning system and the adversary. In such a game, both players would
   attempt to play their best strategies against each other while
   maximizing their own payoffs. To solve the game, each player would
   search for an optimal strategy against the opponent based on the
   prediction of the opponent's strategy choice. The problem becomes even
   more complicated in settings where the learning system may have to deal
   with many adversaries of unknown types. Applying game-theoretic
   approach, robust learning techniques have been developed to specifically
   address adversarial attacks and the preliminary results are promising.
   In this review, we summarize these results. This article is categorized
   under: Technologies > Machine Learning Fundamental Concepts of Data and
   Knowledge > Key Design Issues in Data Mining}},
Publisher = {{WILEY PERIODICALS, INC}},
Address = {{ONE MONTGOMERY ST, SUITE 1200, SAN FRANCISCO, CA 94104 USA}},
Type = {{Review}},
Language = {{English}},
Affiliation = {{Kantarcioglu, M (Corresponding Author), Univ Texas Dallas, Dept Comp Sci, 2601 N Floyd Rd, Richardson, TX 75080 USA.
   Zhou, Yan; Kantarcioglu, Murat, Univ Texas Dallas, Dept Comp Sci, 2601 N Floyd Rd, Richardson, TX 75080 USA.
   Xi, Bowei, Purdue Univ, Dept Stat, W Lafayette, IN 47907 USA.}},
DOI = {{10.1002/widm.1259}},
Article-Number = {{e1259}},
ISSN = {{1942-4787}},
EISSN = {{1942-4795}},
Keywords = {{adversarial machine learning; game theory}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods}},
Author-Email = {{muratk@utdallas.edu}},
Funding-Acknowledgement = {{ARO {[}W911NF-171-0356]}},
Funding-Text = {{ARO, Grant/Award Number: W911NF-171-0356}},
Number-of-Cited-References = {{32}},
Times-Cited = {{7}},
Usage-Count-Last-180-days = {{6}},
Usage-Count-Since-2013 = {{35}},
Journal-ISO = {{Wiley Interdiscip. Rev.-Data Mining Knowl. Discov.}},
Doc-Delivery-Number = {{HW1HP}},
Unique-ID = {{WOS:000466434300006}},
OA = {{Bronze}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000465405500079,
Author = {Kwon, Hyun and Yoon, Hyunsoo and Choi, Daeseon},
Book-Group-Author = {{IEEE}},
Title = {{Priority Adversarial Example in Evasion Attack on Multiple Deep Neural
   Networks}},
Booktitle = {{2019 1ST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE IN
   INFORMATION AND COMMUNICATION (ICAIIC 2019)}},
Year = {{2019}},
Pages = {{399-404}},
Note = {{1st International Conference on Artificial Intelligence in Information
   and Communication (ICAIIC), Okinawa, JAPAN, FEB 11-13, 2019}},
Organization = {{IEEE; IEEE Commun Soc; Korean Inst Commmun \& Informat Sci; ICICE Commun
   Soc; Elect \& Telecommunicat Res Inst; Korea Elect Technol Inst; Inst
   Informat \& Commun Technol Planning \& Evaluat; Samsung Elect; LG Elect;
   KT; SK Telecom; LG U+; Sensors; Multi Screen Serv Forum; Soc Safety Syst
   Forum; Kookmin Univ, Internet Energy Res Ctr; Kyungpook Natl Univ, Ctr
   ICT \& Automot Convergence; Kookmin Univ, LED Convergence Res Ctr;
   Kookmin Univ, Telemat Res Ctr; Kookmin Univ, Hybrid Device Based
   Circadian ICT Res Ctr}},
Abstract = {{Deep neural networks (DNNs) provide superior performance on machine
   learning tasks such as image recognition, speech recognition, pattern
   recognition, and intrusion detection. However, an adversarial example
   created by adding a little noise to the original data can lead to
   misclassification by the DNN, and the human eye cannot detect the
   difference from the original data. For example, if an attacker generates
   a modified left-turn road sign to be incorrectly categorized by a DNN,
   an autonomous vehicle with the DNN will incorrect classify the modified
   left-turn road sign as a right-turn sign, whereas a human will correctly
   classify the modified sign as a left-turn sign. Such an adversarial
   example is a serious threat to a DNN. Recently, a multi-target
   adversarial example was introduced that causes misclassification by
   several models within each target class using a single modified image.
   However, it has the vulnerability that as the number of target models
   increases, the overall attack success rate is reduced. Therefore, if
   there are several models that the attacker wishes to target, the
   attacker needs to control the attack success rate for each model by
   considering the attack priority for each model. In this paper, we
   propose a priority adversarial example that considers the attack
   priority for each model in cases targeting several models. The proposed
   method controls the attack success rate for each model by adjusting the
   weight of the attack function in the generation process, while
   maintaining minimum distortion. We used Tensorflow, a widely used
   machine learning library, and MNIST as the dataset. Experimental results
   show that the proposed method can control the attack success rate for
   each model by considering the attack priority of each model while
   maintaining minimum distortion (on average 3.95 and 2.45 in targeted and
   untargeted attacks, respectively).}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Kwon, H (Corresponding Author), Korea Adv Inst Sci \& Technol, Sch Comp, Daejeon, South Korea.
   Kwon, Hyun; Yoon, Hyunsoo, Korea Adv Inst Sci \& Technol, Sch Comp, Daejeon, South Korea.
   Choi, Daeseon, Kongju Natl Univ, Dept Med Informat, Gongju Si, South Korea.}},
ISBN = {{978-1-5386-7822-0}},
Keywords = {{deep neural network; adversarial example; multi-targeted adversarial
   example; attack priority}},
Research-Areas = {{Computer Science; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Telecommunications}},
Author-Email = {{khkh@kaist.ac.kr
   hyoon@kaist.ac.kr
   sunchoi@kongju.ac.kr}},
ResearcherID-Numbers = {{Kwon, Hyun/M-1140-2018}},
ORCID-Numbers = {{Kwon, Hyun/0000-0003-1169-9892}},
Funding-Acknowledgement = {{National Research Foundation (NRF) of KoreaNational Research Foundation
   of Korea {[}2016R1A4A1011761, 2017R1A2B4006026]; Institute for
   Information \& Communications Technology Promotion (IITP) - the Korean
   government (MSIT) {[}2016-0-00173]}},
Funding-Text = {{This work was supported by National Research Foundation (NRF) of Korea
   grants (2016R1A4A1011761 and 2017R1A2B4006026) and an Institute for
   Information \& Communications Technology Promotion (IITP) grant funded
   by the Korean government (MSIT) (No. 2016-0-00173).}},
Number-of-Cited-References = {{15}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BM5QM}},
Unique-ID = {{WOS:000465405500079}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000649734800100,
Author = {Huang, Weiqing and Peng, Xiao and Shi, Zhixin and Ma, Yuru},
Editor = {{Alamaniotis, M and Pan, S}},
Title = {{Adversarial Attack against LSTM-based DDoS Intrusion Detection System}},
Booktitle = {{2020 IEEE 32ND INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL
   INTELLIGENCE (ICTAI)}},
Series = {{Proceedings-International Conference on Tools With Artificial
   Intelligence}},
Year = {{2020}},
Pages = {{686-693}},
Note = {{32nd IEEE International Conference on Tools with Artificial Intelligence
   (ICTAI), ELECTR NETWORK, NOV 09-11, 2020}},
Organization = {{IEEE; IEEE Comp Soc; Biol \& Artificial Intelligence Fdn}},
Abstract = {{Nowadays, machine learning is a popular method for DDoS detection.
   However, machine learning algorithms are very vulnerable under the
   attacks of adversarial samples. Up to now, multiple methods of
   generating adversarial samples have been proposed. However, they cannot
   be applied to LSTM-based DDoS detection directly because of the discrete
   property and the utility requirement of its input samples. In this
   paper, we propose two methods to generate DDoS adversarial samples,
   named Genetic Attack (GA) and Probability Weighted Packet Saliency
   Attack (PWPSA) respectively. Both methods modify original input sample
   by inserting or replacing partial packets. In GA, we evolve a set of
   modified samples with genetic algorithm and find the evasive variant
   from it. In PWPSA, we modify original sample iteratively and use the
   position saliency as well as the packet score to determine insertion or
   replacement order at each step. Experimental results on CICIDS2017
   dataset show that both methods can bypass DDoS detectors with high
   success rate.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Shi, ZX (Corresponding Author), Chinese Acad Sci, Inst Informat Engn, Beijing, Peoples R China.
   Huang, Weiqing; Peng, Xiao; Shi, Zhixin; Ma, Yuru, Chinese Acad Sci, Inst Informat Engn, Beijing, Peoples R China.
   Huang, Weiqing; Peng, Xiao; Ma, Yuru, Univ Chinese Acad Sci, Sch Cyber Secur, Beijing, Peoples R China.}},
DOI = {{10.1109/ICTAI50040.2020.00110}},
ISSN = {{1082-3409}},
ISBN = {{978-1-7281-9228-4}},
Keywords = {{Adversarial samples; genetic algorithm; probability weighted; LSTM; DDoS
   detector}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{huangweiqing@iie.ac.cn
   pengxiao@iie.ac.cn
   shizhixin@iie.ac.cn
   mayuru@iie.ac.cn}},
Number-of-Cited-References = {{27}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{3}},
Doc-Delivery-Number = {{BR4AM}},
Unique-ID = {{WOS:000649734800100}},
DA = {{2021-11-23}},
}

@article{ WOS:000431850000013,
Author = {Angiulli, Fabrizio and Argento, Luciano and Furfaro, Angelo},
Title = {{Exploiting Content Spatial Distribution to Improve Detection of
   Intrusions}},
Journal = {{ACM TRANSACTIONS ON INTERNET TECHNOLOGY}},
Year = {{2018}},
Volume = {{18}},
Number = {{2, SI}},
Month = {{MAR}},
Abstract = {{We present PCkAD, a novel semisupervised anomaly-based IDS (Intrusion
   Detection System) technique, detecting application-level content-based
   attacks. Its peculiarity is to learn legitimate payloads by splitting
   packets into chunks and determining the within-packet distribution of
   n-grams. This strategy is resistant to evasion techniques as blending.
   We prove that finding the right legitimate content is NP-hard in the
   presence of chunks. Moreover, it improves the false-positive rate for a
   given detection rate with respect to the case where the spatial
   information is not considered. Comparison with well-known IDSs using
   n-grams highlights that PCkAD achieves state-of-the-art performances.}},
Publisher = {{ASSOC COMPUTING MACHINERY}},
Address = {{2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Angiulli, F (Corresponding Author), Univ Calabria, Dept Informat Modeling Elect \& Syst Engn, P Bucci 42, I-87036 Arcavacata Di Rende, CS, Italy.
   Angiulli, Fabrizio; Argento, Luciano; Furfaro, Angelo, Univ Calabria, Dept Informat Modeling Elect \& Syst Engn, P Bucci 42, I-87036 Arcavacata Di Rende, CS, Italy.}},
DOI = {{10.1145/3143422}},
Article-Number = {{25}},
ISSN = {{1533-5399}},
EISSN = {{1557-6051}},
Keywords = {{Intrusion detection systems; semisupervised learning; n-grams; anomaly
   detection}},
Keywords-Plus = {{DETECTION SYSTEM; CLASSIFIER; SECURITY; ATTACK}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Software
   Engineering}},
Author-Email = {{f.angiulli@dimes.unical.it
   l.argento@dimes.unical.it
   a.furfaro@dimes.unical.it}},
ResearcherID-Numbers = {{Furfaro, Angelo/N-2923-2019
   Furfaro, Angelo/I-4050-2012
   }},
ORCID-Numbers = {{Furfaro, Angelo/0000-0003-2537-8918
   Furfaro, Angelo/0000-0003-2537-8918
   Argento, Luciano/0000-0001-8869-5035
   Angiulli, Fabrizio/0000-0002-9860-7569}},
Funding-Acknowledgement = {{``National Operative Programme for Research and Competitiveness{''},
   Technological District on Cyber Security - Italian Ministry of
   Education, University and Research; Italian Ministry of Economic
   DevelopmentMinistry of Economic Development, Italy}},
Funding-Text = {{This work has been partially supported by the ``National Operative
   Programme for Research and Competitiveness{''} 2007 2013, Technological
   District on Cyber Security, funded by the Italian Ministry of Education,
   University and Research, and the Italian Ministry of Economic
   Development.}},
Number-of-Cited-References = {{52}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{ACM Trans. Internet. Technol.}},
Doc-Delivery-Number = {{GF3JD}},
Unique-ID = {{WOS:000431850000013}},
DA = {{2021-11-23}},
}

@article{ WOS:000585624500001,
Author = {Zhang, Guoling and Wang, Xiaodan and Li, Rui and Song, Yafei and He,
   Jiaxing and Lai, Jie},
Title = {{Network Intrusion Detection Based on Conditional Wasserstein Generative
   Adversarial Network and Cost-Sensitive Stacked Autoencoder}},
Journal = {{IEEE ACCESS}},
Year = {{2020}},
Volume = {{8}},
Pages = {{190431-190447}},
Abstract = {{In the field of intrusion detection, there is often a problem of data
   imbalance, and more and more unknown types of attacks make detection
   difficult. To resolve above issues, this article proposes a network
   intrusion detection model called CWGAN-CSSAE, which combines improved
   conditional Wasserstein Generative Adversarial Network (CWGAN) and
   cost-sensitive stacked autoencoders (CSSAE). First of all, the CWGAN
   network that introduces gradient penalty and L2 regularization is used
   to generate specified minority attack samples to reduce the class
   imbalance of the training dataset. Secondly, the stacked autoencoder is
   used to intelligently extract the deep abstract features of the network
   data. Finally, a cost-sensitive loss function is constructed to give a
   large misclassification cost to a minority of attack samples. Thus,
   effective detection of network intrusion attacks can be realized. The
   experimental results based on KDDTest(+), KDDTest-21, and UNSW-NB15
   datasets show that the CWGAN-CSSAE network intrusion detection model
   improves the detection accuracy of minority attacks and unknown attacks.
   In addition, the method in this article is compared with other existing
   intrusion detection methods, excellent results have been achieved in
   performance indicators such as accuracy and F1 score. The accuracy on
   the above datasets reached 90.34\%, 80.78\% and 93.27\% respectively.
   The accuracy of U2R on the KDDTest(+) and KDDTest21 datasets both
   reached 42.50\%. The accuracy of R2L on the KDDTest(+) and KDDTest-21
   datasets reached 54.39\% and 52.51\%, respectively. And the F1 score on
   the above datasets reached 91.01\%, 87.18\% and 93.99\% respectively.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Wang, XD (Corresponding Author), Air Force Engn Univ, Coll Air \& Missile Def, Xian 710051, Peoples R China.
   Zhang, Guoling; Wang, Xiaodan; Li, Rui; Song, Yafei; He, Jiaxing; Lai, Jie, Air Force Engn Univ, Coll Air \& Missile Def, Xian 710051, Peoples R China.}},
DOI = {{10.1109/ACCESS.2020.3031892}},
ISSN = {{2169-3536}},
Keywords = {{Intrusion detection; conditional Wasserstein GAN; stacked autoencoder;
   imbalanced classification; cost-sensitive; regularization; deep learning}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{afeu\_wang@163.com}},
ORCID-Numbers = {{Lai, Jie/0000-0002-1028-8162
   SONG, Yafei/0000-0003-0962-0671
   Li, Rui/0000-0003-1770-906X}},
Funding-Acknowledgement = {{National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}61876189, 61806219, 61503407, 61703426,
   61273275]; Young Talent Fund of the University Association for Science
   and Technology, Shanxi, China {[}20190108]}},
Funding-Text = {{This work was supported in part by the National Natural Science
   Foundation of China under Grant 61876189, Grant 61806219, Grant
   61503407, Grant 61703426, and Grant 61273275; and in part by the Young
   Talent Fund of the University Association for Science and Technology,
   Shanxi, China, under Grant 20190108.}},
Number-of-Cited-References = {{47}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{10}},
Usage-Count-Since-2013 = {{12}},
Journal-ISO = {{IEEE Access}},
Doc-Delivery-Number = {{OL9BA}},
Unique-ID = {{WOS:000585624500001}},
OA = {{gold}},
DA = {{2021-11-23}},
}

@article{ WOS:000680892400013,
Author = {Ma, Xiangyu and Shi, Wei},
Title = {{AESMOTE: Adversarial Reinforcement Learning With SMOTE for Anomaly
   Detection}},
Journal = {{IEEE TRANSACTIONS ON NETWORK SCIENCE AND ENGINEERING}},
Year = {{2021}},
Volume = {{8}},
Number = {{2}},
Pages = {{943-956}},
Month = {{APR-JUN}},
Abstract = {{Intrusion Detection Systems (IDSs) play a vital role in securing today's
   Data-Centric Networks. In a dynamic environment such as the Internet of
   Things (IoT), which is vulnerable to various types of attacks, fast and
   robust solutions are in demand to handle fast-changing threats and thus
   the everincreasing difficulty of detection. In this paper, we present a
   novel framework for the detection of anomalies, which, in particular,
   supports intrusion detection. The anomaly-detection framework we propose
   combines reinforcement learning with class-imbalance techniques. Our
   goal is not only to exploit the autolearning ability of the
   reinforcement-learning loop but also to address the dataset imbalance
   problem, which is pervasive in existing learning-based solutions. We
   introduce an adapted SMOTE to address the class-imbalance problem while
   remodelling the behaviors of the environment agent for better
   performance. Experiments are conducted on NSL-KDD datasets. Comparative
   evaluations and their results are presented and analyzed. Using
   techniques such as SMOTE, ROS, NearMiss1 and NearMiss2, performance
   measures obtained from our simulations have led us to recognize specific
   performance trends. In particular, the proposed model AESMOTE
   outperforms AE-RL in several cases. Experiment results show an Accuracy
   greater than 0.82 and a F1 greater than 0.824.}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Ma, XY (Corresponding Author), Carleton Univ, Sch Informat Technol, Ottawa, ON K1S 5B6, Canada.
   Ma, Xiangyu; Shi, Wei, Carleton Univ, Sch Informat Technol, Ottawa, ON K1S 5B6, Canada.}},
DOI = {{10.1109/TNSE.2020.3004312}},
ISSN = {{2327-4697}},
Keywords = {{adversarial strategy; anomaly detection; class-imbalance; deep
   reinforcement learning; dynamic training; feature-selection}},
Research-Areas = {{Engineering; Mathematics}},
Web-of-Science-Categories  = {{Engineering, Multidisciplinary; Mathematics, Interdisciplinary
   Applications}},
Author-Email = {{johnnyma@cmail.carleton.ca
   weishi@cunet.carleton.ca}},
Funding-Acknowledgement = {{Natural Sciences and Engineering Research Council of Canada
   (NSERC)Natural Sciences and Engineering Research Council of Canada
   (NSERC) {[}RGPIN-2015-05390]}},
Funding-Text = {{Manuscript received April 1, 2020; revised May 16, 2020; accepted June
   7, 2020. Date of publication June 24, 2020; date of current version July
   7, 2021. We gratefully acknowledge the financial support from the
   Natural Sciences and Engineering Research Council of Canada (NSERC)
   under Grants No. RGPIN-2015-05390. Recommended for acceptance by Dr.
   Xiaojiang Du (Corresponding author: Xiangyu Ma.)}},
Number-of-Cited-References = {{36}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{6}},
Usage-Count-Since-2013 = {{6}},
Journal-ISO = {{IEEE Trans. Netw. Sci. Eng.}},
Doc-Delivery-Number = {{TU2SY}},
Unique-ID = {{WOS:000680892400013}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000459819200076,
Author = {Kwon, Hyun and Kim, Yongchul and Yoon, Hyunsoo and Choi, Daeseon},
Book-Group-Author = {{IEEE}},
Title = {{Fooling a Neural Network in Military Environments: Random Untargeted
   Adversarial Example}},
Booktitle = {{2018 IEEE MILITARY COMMUNICATIONS CONFERENCE (MILCOM 2018)}},
Series = {{IEEE Military Communications Conference}},
Year = {{2018}},
Pages = {{456-461}},
Note = {{IEEE Military Communications Conference (MILCOM), Los Angeles, CA, OCT
   29-31, 2018}},
Organization = {{IEEE; AFCEA; IEEE Commun Soc}},
Abstract = {{Deep neural networks (DNNs) show superior performance in machine
   learning tasks such as image recognition, speech recognition, intrusion
   detection, and pattern analysis. However, an adversarial example,
   created by adding a little noise to the original sample, can cause
   misclassification by the DNN. As adversarial examples are a serious
   threat to DNNs, there has been much research into the generation of
   adversarial examples designed for attacking DNNs. The adversarial
   example attack is divided into two categories: targeted adversarial
   example and untargeted adversarial example. The targeted adversarial
   example attack causes machines to misinterpret an object as the
   attacker's desired class. In contrast, the untargeted adversarial
   example causes machines to misinterpret an object as an incorrect class.
   In this paper, we focus on an untargeted adversarial example scenario
   because it has less distortion from the original sample and a faster
   learning time than a targeted adversarial example scenario. However,
   there is a pattern problem in generating untargeted adversarial
   examples: Because of the similarity between the original class and
   specific classes, it may be possible for the defending system to
   determine the original class by analyzing the output classes of the
   untargeted adversarial examples. To overcome this problem, we propose a
   new method for generating untargeted adversarial examples, one that uses
   an arbitrary class in the generation process. For experimental datasets,
   we used MNIST and CIFAR10, and the Tensorflow library was employed as
   the machine learning library. Through our experiment, we show that the
   proposed method can generate random untargeted adversarial examples that
   do not focus on a specific class for a given original class, while
   keeping distortion to a minimum (1.99 and 42.32 on MNIST and CIFAR10,
   respectively) and maintaining a 100\% attack success rate.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Kwon, H (Corresponding Author), Korea Adv Inst Sci \& Technol, Sch Comp, Daejeon, South Korea.
   Kwon, Hyun; Yoon, Hyunsoo, Korea Adv Inst Sci \& Technol, Sch Comp, Daejeon, South Korea.
   Kim, Yongchul, Korea Mil Acad, Dept Elect Engn, Seoul, South Korea.
   Choi, Daeseon, Kongju Natl Univ, Dept Med Informat, Gongju Si, South Korea.}},
ISSN = {{2155-7578}},
ISBN = {{978-1-5386-7185-6}},
Keywords = {{Deep neural network; adversarial example; untargeted adversarial
   example; random selection}},
Research-Areas = {{Telecommunications}},
Web-of-Science-Categories  = {{Telecommunications}},
Author-Email = {{khkh@kaist.ac.kr
   kyc6454@kma.ac.kr
   hyoon@kaist.ac.kr
   sunchoi@kongju.ac.kr}},
ResearcherID-Numbers = {{Kwon, Hyun/M-1140-2018}},
ORCID-Numbers = {{Kwon, Hyun/0000-0003-1169-9892}},
Funding-Acknowledgement = {{National Research Foundation (NRF) of Korea - Korean government (MSIT)
   {[}2016R1A4A1011761, 2017R1A2B4006026]; Institute for Information \&
   Communications Technology Promotion (IITP) - Korean government (MSIT)
   {[}2016-0-00173]}},
Funding-Text = {{This work was supported by National Research Foundation (NRF) of Korea
   grants funded by the Korean government (MSIT) (2016R1A4A1011761 and
   2017R1A2B4006026) and an Institute for Information \& Communications
   Technology Promotion (IITP) grant funded by the Korean government (MSIT)
   (No. 2016-0-00173).}},
Number-of-Cited-References = {{21}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BM1HT}},
Unique-ID = {{WOS:000459819200076}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000530687800045,
Author = {Ge, Mengmeng and Fu, Xiping and Syed, Naeem and Baig, Zubair and Teo,
   Gideon and Robles-Kelly, Antonio},
Book-Group-Author = {{IEEE}},
Title = {{Deep Learning-based Intrusion Detection for IoT Networks}},
Booktitle = {{2019 IEEE 24TH PACIFIC RIM INTERNATIONAL SYMPOSIUM ON DEPENDABLE
   COMPUTING (PRDC 2019)}},
Series = {{IEEE Pacific Rim International Symposium on Dependable Computing}},
Year = {{2019}},
Pages = {{256-265}},
Note = {{IEEE 24th Pacific Rim International Symposium on Dependable Computing
   (PRDC), Kyoto, JAPAN, DEC 01-03, 2019}},
Organization = {{IEEE; IEEE Comp Soc; Tokyo Metropolitan Univ; Hiroshima Univ; Kyoto
   Sangyo Univ; Nihon Univ; IEEE Comp Soc, Tech Comm Dependable Comp \&
   Fault Tolerance}},
Abstract = {{Internet of Things (IoT) has an immense potential for a plethora of
   applications ranging from healthcare automation to defence networks and
   the power grid. The security of an IoT network is essentially paramount
   to the security of the underlying computing and communication
   infrastructure. However, due to constrained resources and limited
   computational capabilities, IoT networks are prone to various attacks.
   Thus, safeguarding the IoT network from adversarial attacks is of vital
   importance and can be realised through planning and deployment of
   effective security controls; one such control being an intrusion
   detection system. In this paper, we present a novel intrusion detection
   scheme for IoT networks that classifies traffic flow through the
   application of deep learning concepts. We adopt a newly published IoT
   dataset and generate generic features from the field information in
   packet level. We develop a feed-forward neural networks model for binary
   and multi-class classification including denial of service, distributed
   denial of service, reconnaissance and information theft attacks against
   IoT devices. Results obtained through the evaluation of the proposed
   scheme via the processed dataset illustrate a high classification
   accuracy.}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Ge, MM (Corresponding Author), Deakin Univ, Sch Informat Technol, Geelong, Vic, Australia.
   Ge, Mengmeng; Baig, Zubair; Robles-Kelly, Antonio, Deakin Univ, Sch Informat Technol, Geelong, Vic, Australia.
   Fu, Xiping, Telstra Network Serv NZ Ltd, Christchurch, New Zealand.
   Syed, Naeem, Edith Cowan Univ, Sch Sci, Joondalup, WA, Australia.
   Teo, Gideon, Univ Canterbury, Sch Math \& Stat, Christchurch, New Zealand.}},
DOI = {{10.1109/PRDC47002.2019.00056}},
ISSN = {{1555-094X}},
ISBN = {{978-1-7281-4961-5}},
Keywords = {{Internet of Things; Intrusion Detection; Feed-Forward Neural Networks;
   Denial of Service Attacks}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods; Engineering, Electrical \&
   Electronic}},
Author-Email = {{mengmeng.ge@deakin.edu.au
   fxpfxp0607@gmail.com
   n.syed@ecu.edu.au
   zubair.baig@deakin.edu.au
   teogideon@gmail.com
   antonio.robles-kelly@deakin.edu.au}},
ResearcherID-Numbers = {{Baig, Zubair/P-7767-2015}},
ORCID-Numbers = {{Syed, Naeem Firdous/0000-0003-2450-4337
   Baig, Zubair/0000-0002-9245-2703}},
Number-of-Cited-References = {{18}},
Times-Cited = {{7}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BO9CC}},
Unique-ID = {{WOS:000530687800045}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000668563500164,
Author = {Sapre, Suchet and Islam, Khondkar and Ahmadi, Pouyan},
Book-Group-Author = {{IEEE}},
Title = {{A Comprehensive Data Sampling Analysis Applied to the Classification of
   Rare IoT Network Intrusion Types}},
Booktitle = {{2021 IEEE 18TH ANNUAL CONSUMER COMMUNICATIONS \& NETWORKING CONFERENCE
   (CCNC)}},
Series = {{IEEE Consumer Communications and Networking Conference}},
Year = {{2021}},
Note = {{IEEE 18th Annual Consumer Communications and Networking Conference
   (CCNC), ELECTR NETWORK, JAN 09-13, 2021}},
Organization = {{IEEE; IEEE Commun Soc}},
Abstract = {{With the rapid growth of Internet of Things (IoT) network intrusion
   attacks, there is a critical need for sophisticated and comprehensive
   intrusion detection systems (IDSs). Classifying infrequent intrusion
   types such as root-to-local (R2L) and user-to-root (U2R) attacks is a
   reoccurring problem for IDSs. In this study, various data sampling and
   class balancing techniques-Generative Adversarial Network (GAN)-based
   over-sampling, k-nearest-neighbor (kNN) oversampling, NearMiss-1
   undersampling, and class weights-were used to resolve the severe class
   imbalance affecting U2R and R2L attacks in the NSL-KDD intrusion
   detection dataset. Artificial Neural Networks (ANNs) were trained on the
   adjusted datasets, and their performances were evaluated with a
   multitude of classification metrics. Here, we show that using no data
   sampling technique (baseline), GAN-based oversampling, and NearMiss-1
   undersampling, all with class weights, displayed high performances in
   identifying R2L and U2R attacks. Of these, the baseline with class
   weights had the highest overall performance with an F1-score of 0.11 and
   0.22 for the identification of U2R and R2L attacks, respectively.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Sapre, S (Corresponding Author), George Mason Univ, Dept Informat Sci \& Technol, Fairfax, VA 22030 USA.
   Sapre, Suchet; Islam, Khondkar; Ahmadi, Pouyan, George Mason Univ, Dept Informat Sci \& Technol, Fairfax, VA 22030 USA.}},
DOI = {{10.1109/CCNC49032.2021.9369617}},
ISSN = {{2331-9852}},
ISBN = {{978-1-7281-9794-4}},
Keywords = {{Machine Learning; Internet of Things; NSL-KDD; Intrusion Detection;
   Generative Adversarial Networks; Data Sampling}},
Research-Areas = {{Computer Science; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Hardware \& Architecture; Telecommunications}},
Author-Email = {{ssapre@gmu.edu
   kislam2@gmu.edu
   pahmadi@gmu.edu}},
Number-of-Cited-References = {{9}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BR7NG}},
Unique-ID = {{WOS:000668563500164}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000343005600004,
Author = {Nelson, Kevin and Corbin, George and Blowers, Misty},
Editor = {{Blowers, M and Williams, J}},
Title = {{Evaluating data distribution and drift vulnerabilities of machine
   learning algorithms in secure and adversarial environments}},
Booktitle = {{MACHINE INTELLIGENCE AND BIO-INSPIRED COMPUTATION: THEORY AND
   APPLICATIONS VIII}},
Series = {{Proceedings of SPIE}},
Year = {{2014}},
Volume = {{9119}},
Note = {{Conference on Machine Intelligence and Bio-inspired Computation - Theory
   and Applications VIII, Baltimore, MA, MAY 08-09, 2014}},
Organization = {{SPIE}},
Abstract = {{Machine learning is continuing to gain popularity due to its ability to
   solve problems that are difficult to model using conventional computer
   programming logic. Much of the current and past work has focused on
   algorithm development, data processing, and optimization. Lately, a
   subset of research has emerged which explores issues related to
   security. This research is gaining traction as systems employing these
   methods are being applied to both secure and adversarial environments.
   One of machine learning's biggest benefits, its data-driven versus
   logic-driven approach, is also a weakness if the data on which the
   models rely are corrupted. Adversaries could maliciously influence
   systems which address drift and data distribution changes using
   re-training and online learning. Our work is focused on exploring the
   resilience of various machine learning algorithms to these data-driven
   attacks. In this paper, we present our initial findings using Monte
   Carlo simulations, and statistical analysis, to explore the maximal
   achievable shift to a classification model, as well as the required
   amount of control over the data.}},
Publisher = {{SPIE-INT SOC OPTICAL ENGINEERING}},
Address = {{1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Nelson, K (Corresponding Author), BAE Syst, 581 Phoenix Dr, Rome, NY 13441 USA.
   Nelson, Kevin; Corbin, George, BAE Syst, 581 Phoenix Dr, Rome, NY 13441 USA.
   Blowers, Misty, Air Force Res Lab, 525 Brooks Rd, Rome, NY 13441 USA.}},
DOI = {{10.1117/12.2053045}},
Article-Number = {{911904}},
ISSN = {{0277-786X}},
EISSN = {{1996-756X}},
ISBN = {{978-1-62841-056-3}},
Keywords = {{Adversarial Machine Learning; Intrusion Detection; Monte Carlo; Hidden
   Markov Models}},
Research-Areas = {{Computer Science; Engineering; Optics}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic; Optics}},
Number-of-Cited-References = {{17}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BB3RM}},
Unique-ID = {{WOS:000343005600004}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000520120600003,
Author = {Wang, Jing-Tong and Wang, Chih-Hung},
Book-Group-Author = {{IEEE}},
Title = {{High Performance WGAN-GP based Multiple-category Network Anomaly
   Classification System}},
Booktitle = {{2019 INTERNATIONAL CONFERENCE ON CYBER SECURITY FOR EMERGING
   TECHNOLOGIES (CSET)}},
Year = {{2019}},
Note = {{International Conference on Cyber Security for Emerging Technologies
   (CSET), Doha, QATAR, OCT 27-29, 2019}},
Abstract = {{Due to the increasing of smart devices, the detection of anomalous
   traffic on Internet is getting more essential. Many previous intrusion
   detection studies which focused on the classification between normal or
   anomaly events can be used to enhance the system security by launching
   alarms as the intrusions being detected. Although many intrusion
   detection systems which has been developed can achieve high detection
   rates, they are still difficult to perform well on some attacks that
   have never been seen before. In this paper, the performance of
   multiple-category classification on NSL-KDD dataset is evaluated using
   Wasserstein Generative Adversarial Network - gradient penalty (WGAN-GP)
   to enhance training effectiveness. The experimental result showed that
   the proposed method obtained the accuracy rates of 88.2\% and 80.8\% on
   binary and five category classification problems respectively.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Wang, CH (Corresponding Author), Natl Chiayi Univ, Dept Comp Sci \& Informat Engn, Chiayi, Taiwan.
   Wang, Jing-Tong; Wang, Chih-Hung, Natl Chiayi Univ, Dept Comp Sci \& Informat Engn, Chiayi, Taiwan.}},
ISBN = {{978-1-7281-4538-9}},
Keywords = {{anomaly detection; classification; machine learning; WGAN-GP; NSL-KDD}},
Keywords-Plus = {{INTRUSION DETECTION SYSTEM}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods}},
Author-Email = {{s1060420@mail.ncyu.edu.tw
   wangch@mail.ncyu.edu.tw}},
Funding-Acknowledgement = {{Ministry of Science and Technology of TaiwanMinistry of Science and
   Technology, Taiwan {[}MOST 106-2221-E-415-003-MY2, MOST
   107-2218-E-110-014]; Taiwan Information Security Center at National Sun
   Yat-sen University (TWISC@NSYSU)}},
Funding-Text = {{This work was supported by Ministry of Science and Technology of Taiwan
   Grants MOST 106-2221-E-415-003-MY2, MOST 107-2218-E-110-014 and Taiwan
   Information Security Center at National Sun Yat-sen University
   (TWISC@NSYSU).}},
Number-of-Cited-References = {{25}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BO6IQ}},
Unique-ID = {{WOS:000520120600003}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000706529000064,
Author = {Haque, Nur Imtiazul and Rahman, Mohammad Ashiqur and Shahriar, Hossain},
Editor = {{Chan, WK and Claycomb, B and Takakura, H and Yang, JJ and Teranishi, Y and Towey, D and Segura, S and Shahriar, H and Reisman, S and Ahamed, SI}},
Title = {{Ensemble-based Efficient Anomaly Detection for Smart Building Control
   Systems}},
Booktitle = {{2021 IEEE 45TH ANNUAL COMPUTERS, SOFTWARE, AND APPLICATIONS CONFERENCE
   (COMPSAC 2021)}},
Series = {{Proceedings International Computer Software and Applications Conference}},
Year = {{2021}},
Pages = {{504-513}},
Note = {{45th Annual International IEEE-Computer-Society Computers, Software, and
   Applications Conference (COMPSAC), ELECTR NETWORK, JUL 12-16, 2021}},
Organization = {{IEEE; IEEE Comp Soc}},
Abstract = {{Modern building control systems integrate the internet of things (IoT)
   for real-time monitoring of the building's demand and manage the
   heating, ventilation, and air conditioning (HVAC) cost-efficiently and
   reliably. However, adversarial alterations of the sensor data can
   disrupt the occupants' comfort or increase energy consumption. Several
   intrusion detection systems (IDSs) are proposed to detect the tempering
   of the sensor measurements. However, these approaches either demonstrate
   a high false alarm rate or fail to detect anomalies, putting the HVAC
   control or the building occupants in a vulnerable condition. This paper
   proposes a novel intrusion detection technique amalgamating two
   unsupervised machine learning techniques, namely autoencoder(AE) and
   one-class support vector machine (OCSVM), for identifying abnormality in
   smart building sensor measurements. Our experimental analysis shows that
   the AE model-based anomaly detector demonstrates satisfactory
   performance for lowering false alarms but fails to detect a number of
   anomalous samples. In contrast, the OCSVM-based anomaly detection model
   performs significantly well for anomaly detection while raises a lot of
   false alarms. Our proposed ensembled AE-OCSVM model combines both
   models' benefits, resulting in significant reductions of false positive
   and false negative rates compared to the existing smart building IDSs.
   We evaluate the proposed intrusion detection system on the commercial
   occupancy dataset (COD) and find that the proposed IDS model can achieve
   a 99.6\% F1-score.}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Haque, NI (Corresponding Author), Florida Int Univ, Analyt Cyber Def ACyD Lab, Miami, FL 33199 USA.
   Haque, Nur Imtiazul; Rahman, Mohammad Ashiqur, Florida Int Univ, Analyt Cyber Def ACyD Lab, Miami, FL 33199 USA.
   Shahriar, Hossain, Kennesaw State Univ, Dept Informat Technol, Kennesaw, GA 30144 USA.}},
DOI = {{10.1109/COMPSAC51774.2021.00075}},
ISSN = {{0730-3157}},
ISBN = {{978-1-6654-2463-9}},
Keywords = {{Machine learning; unsupervised learning; intrusion detection}},
Keywords-Plus = {{ONE-CLASS SVM; FRAMEWORK}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering}},
Author-Email = {{nhaqu004@fiu.edu
   marahman@fiu.edu
   hshahria@kennesaw.edu}},
Number-of-Cited-References = {{32}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BS2RI}},
Unique-ID = {{WOS:000706529000064}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000435293600037,
Author = {Kumar, Sanjay and Viinikainen, Ari and Hamalainen, Timo},
Book-Group-Author = {{IEEE}},
Title = {{A network-based framework for mobile threat detection}},
Booktitle = {{2018 1ST INTERNATIONAL CONFERENCE ON DATA INTELLIGENCE AND SECURITY
   (ICDIS 2018)}},
Year = {{2018}},
Pages = {{227-233}},
Note = {{1st International Conference on Data Intelligence and Security (ICDIS),
   TX, APR 08-10, 2018}},
Organization = {{Univ Texas Rio Grande Valley, Comp Sci Dept; IEEE Corpus Christi Sect}},
Abstract = {{Mobile malware attacks increased three folds in the past few years and
   continued to expand with the growing number of mobile users. Adversary
   uses a variety of evasion techniques to avoid detection by traditional
   systems, which increase the diversity of malicious applications. Thus,
   there is a need for an intelligent system that copes with this issue.
   This paper proposes a machine learning (ML) based framework to counter
   rapid evolution of mobile threats. This model is based on flow-based
   features, that will work on the network side. This model is designed
   with adversarial input in mind. The model uses 40 time-asked network
   flow features, extracted from the real-time traffic of malicious and
   benign applications. The proposed model not only to detects the known
   and unknown mobile threats but also deals with the changing behavior of
   the attackers by triggering the retraining phase. The proposed framework
   can be used by the mobile operators to protect their subscribers. We
   used several supervised ML algorithms to build the model and got an
   average accuracy of up to 99.8\%.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Kumar, S (Corresponding Author), Univ Jyvaskyla, Fac Informat Technol, Jyvaskyla, Finland.
   Kumar, Sanjay; Viinikainen, Ari; Hamalainen, Timo, Univ Jyvaskyla, Fac Informat Technol, Jyvaskyla, Finland.}},
DOI = {{10.1109/ICDIS.2018.00044}},
ISBN = {{978-1-5386-5762-1}},
Keywords = {{Intrusion Detection; Mobile Threats; Machine Learning; Concept-drift;
   Anomaly detection}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods; Engineering, Electrical \&
   Electronic}},
Author-Email = {{sanjay.k.kumar@jyu.fi
   ari.viinikainen@jyu.fi
   timo.t.hamalainen@jyu.fi}},
ORCID-Numbers = {{Hamalainen, Timo/0000-0002-4168-9102}},
Number-of-Cited-References = {{31}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BK3OF}},
Unique-ID = {{WOS:000435293600037}},
OA = {{Green Accepted}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000621584100024,
Author = {Kabir, Md Ahsanul and Luo, Xiao},
Book-Group-Author = {{IEEE}},
Title = {{Unsupervised Learning for Network Flow based Anomaly Detection in the
   Era of Deep Learning}},
Booktitle = {{2020 IEEE SIXTH INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING SERVICE
   AND APPLICATIONS (BIGDATASERVICE 2020)}},
Year = {{2020}},
Pages = {{166-169}},
Note = {{6th IEEE International Conference on Big Data Computing Service and
   Applications (IEEE BigDataService), Oxford, ENGLAND, AUG 03-06, 2020}},
Organization = {{IEEE; IEEE Comp Soc}},
Abstract = {{In this research, we investigate and evaluate four unsupervised learning
   algorithms: K-Means and Self Organizing Maps (SOM), deep autoencoding
   Gaussian mixture model (DAGMM), and adversarially learned anomaly
   detection (ALAD) on two benchmark data sets towards network flow-based
   anomaly detection. We explore different parameters and neural network
   settings of the learning algorithms, respectively. The returned results
   show that DAGMM gains the lowest false-positive rate and a relatively
   high detection rate on one of the data set, whereas SOM achieves the
   best results on the other data set. By comparing the detection rates of
   all algorithms on attacks that have no instance in the training set, and
   we find that K-Means works the better than the other three. Whereas the
   comparison on the attacks that have few instances in the training set
   shows that the ALAD works much better than the others since it uses the
   adversarial sample generation mechanism. We conclude that to achieve the
   best performance, integration of the traditional and deep-learning
   algorithms for network flow-based intrusion detection is critical.}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Kabir, MA (Corresponding Author), Indiana Univ Purdue Univ, Indianapolis, IN 46202 USA.
   Kabir, Md Ahsanul; Luo, Xiao, Indiana Univ Purdue Univ, Indianapolis, IN 46202 USA.}},
DOI = {{10.1109/BigDataService49289.2020.00032}},
ISBN = {{978-1-7281-7022-0}},
Keywords = {{Unsupervised Learning; Intrusion Detection; Network Flow; Deep Learning}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory \& Methods}},
Author-Email = {{mdkabir@iu.edu
   luo25@iupui.edu}},
Number-of-Cited-References = {{14}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BQ8TA}},
Unique-ID = {{WOS:000621584100024}},
DA = {{2021-11-23}},
}

@article{ WOS:000675759800003,
Author = {Liu, Xiaodong and Li, Tong and Zhang, Runzi and Wu, Di and Liu, Yongheng
   and Yang, Zhen},
Title = {{A GAN and Feature Selection-Based Oversampling Technique for Intrusion
   Detection}},
Journal = {{SECURITY AND COMMUNICATION NETWORKS}},
Year = {{2021}},
Volume = {{2021}},
Month = {{JUL 6}},
Abstract = {{In recent years, there have been numerous cyber security issues that
   have caused considerable damage to the society. The development of
   efficient and reliable Intrusion Detection Systems (IDSs) is an
   effective countermeasure against the growing cyber threats. In modern
   high-bandwidth, large-scale network environments, traditional IDSs
   suffer from a high rate of missed and false alarms. Researchers have
   introduced machine learning techniques into intrusion detection with
   good results. However, due to the scarcity of attack data, such methods'
   training sets are usually unbalanced, affecting the analysis
   performance. In this paper, we survey and analyze the design principles
   and shortcomings of existing oversampling methods. Based on the
   findings, we take the perspective of imbalance and high dimensionality
   of datasets in the field of intrusion detection and propose an
   oversampling technique based on Generative Adversarial Networks (GAN)
   and feature selection. Specifically, we model the complex
   high-dimensional distribution of attacks based on Gradient Penalty
   Wasserstein GAN (WGAN-GP) to generate additional attack samples. We then
   select a subset of features representing the entire dataset based on
   analysis of variance, ultimately generating a rebalanced low-dimensional
   dataset for machine learning training. To evaluate the effectiveness of
   our proposal, we conducted experiments based on the NSL-KDD, UNSW-NB15,
   and CICIDS-2017 datasets. The experimental results show that our method
   can effectively improve the detection performance of machine learning
   models and outperform the baselines.}},
Publisher = {{WILEY-HINDAWI}},
Address = {{ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Li, T (Corresponding Author), Beijing Univ Technol, Fac Informat Technol, Beijing, Peoples R China.
   Li, T (Corresponding Author), Minist Educ, Engn Res Ctr Intelligent Percept \& Autonomous Con, Beijing, Peoples R China.
   Liu, Xiaodong; Li, Tong; Wu, Di; Liu, Yongheng; Yang, Zhen, Beijing Univ Technol, Fac Informat Technol, Beijing, Peoples R China.
   Li, Tong; Yang, Zhen, Minist Educ, Engn Res Ctr Intelligent Percept \& Autonomous Con, Beijing, Peoples R China.
   Zhang, Runzi, NSFOCUS Technol Grp Co Ltd, Beijing 100089, Peoples R China.
   Zhang, Runzi, Tsinghua Univ, Dept Automat, Beijing 100089, Peoples R China.}},
DOI = {{10.1155/2021/9947059}},
Article-Number = {{9947059}},
ISSN = {{1939-0114}},
EISSN = {{1939-0122}},
Keywords-Plus = {{SMOTE}},
Research-Areas = {{Computer Science; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Telecommunications}},
Author-Email = {{liuxdong@emails.bjut.edu.cn
   litong@bjut.edu.cn
   zhangrunzi@nsfocus.com
   wuxiaodou@emails.bjut.edu.cn
   lyh081@emails.bjut.edu.cn
   yangzhen@bjut.edu.cn}},
Funding-Acknowledgement = {{National Natural Science of Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}61902010, 61671030]; CCF-NSFocus Fund
   {[}2020003]; Beijing Excellent Talent Funding-Youth Project
   {[}2018000020124G039]; Beijing Municipal Education CommissionBeijing
   Municipal Commission of Education {[}KM202110005025]}},
Funding-Text = {{This work was partially supported by the National Natural Science of
   Foundation of China (nos. 61902010 and 61671030), CCF-NSFocus Funding
   (no.2020003), Beijing Excellent Talent Funding-Youth Project
   (no.2018000020124G039), and Project of Beijing Municipal Education
   Commission (no.KM202110005025).}},
Number-of-Cited-References = {{43}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{15}},
Usage-Count-Since-2013 = {{15}},
Journal-ISO = {{Secur. Commun. Netw.}},
Doc-Delivery-Number = {{TM7XD}},
Unique-ID = {{WOS:000675759800003}},
OA = {{gold, Green Published}},
DA = {{2021-11-23}},
}

@article{ WOS:000688442400014,
Author = {Novaes, Matheus P. and Carvalho, Luiz F. and Lloret, Jaime and Proenca,
   Jr., Mario Lemes},
Title = {{Adversarial Deep Learning approach detection and defense against DDoS
   attacks in SDN environments}},
Journal = {{FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE}},
Year = {{2021}},
Volume = {{125}},
Pages = {{156-167}},
Month = {{DEC}},
Abstract = {{Over the last few years, Software Defined Networking (SDN) paradigm has
   become an emerging architecture to design future networks and to meet
   new application demands. SDN provides resources for improving network
   control and management by separating control and data plane, and the
   logical control is centralized in a controller. However, the centralized
   control logic can be an ideal target for malicious attacks, mainly
   Distributed Denial of Service (DDoS) attacks. Recently, Deep Learning
   has become a powerful technique applied in cybersecurity, and many
   Network Intrusion Detection (NIDS) have been proposed in recent
   researches. Some studies have indicated that deep neural networks are
   sensitive in detecting adversarial attacks. Adversarial attacks are
   instances with certain perturbations that cause deep neural networks to
   misclassify. In this paper, we proposed a detection and defense system
   based on Adversarial training in SDN, which uses Generative Adversarial
   Network (GAN) framework for detecting DDoS attacks and applies
   adversarial training to make the system less sensitive to adversarial
   attacks. The proposed system includes well-defined modules that enable
   continuous traffic monitoring using IP flow analysis, enabling the
   anomaly detection system to act in near-real-time. We conducted the
   experiments on two distinct scenarios, with emulated data and the public
   dataset CICDDoS 2019. Experimental results demonstrated that the system
   efficiently detected up-to-date common types of DDoS attacks compared to
   other approaches. (C) 2021 Elsevier B.V. All rights reserved.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Lloret, J (Corresponding Author), Univ Politecn Valencia, Integrated Management Coastal Res Inst, Valencia, Spain.
   Novaes, Matheus P., State Univ Londrina UEL, Elect Engn Dept, Londrina, Parana, Brazil.
   Carvalho, Luiz F., Fed Technol Univ Parana UTFPR, Comp Engn Dept, Apucarana, Parana, Brazil.
   Lloret, Jaime, Univ Politecn Valencia, Integrated Management Coastal Res Inst, Valencia, Spain.
   Proenca, Mario Lemes, Jr., State Univ Londrina UEL, Comp Sci Dept, Londrina, Parana, Brazil.}},
DOI = {{10.1016/j.future.2021.06.047}},
ISSN = {{0167-739X}},
EISSN = {{1872-7115}},
Keywords = {{Adversarial attacks; DDoS; Deep Learning; GAN; SDN}},
Keywords-Plus = {{ANOMALY DETECTION; DETECTION SYSTEMS; NEURAL-NETWORKS; MITIGATION;
   INTRUSION}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods}},
Author-Email = {{jlloret@dcom.upv.es}},
ResearcherID-Numbers = {{Lloret, Jaime/H-3994-2013
   Proenca Jr., Mario Lemes/B-8340-2016}},
ORCID-Numbers = {{Lloret, Jaime/0000-0002-0862-0533
   Proenca Jr., Mario Lemes/0000-0002-0492-322X}},
Funding-Acknowledgement = {{National Council for Scientific and Technological Development (CNPq) of
   BrazilConselho Nacional de Desenvolvimento Cientifico e Tecnologico
   (CNPQ) {[}310668/2019-0]; SETI, Brazil/Fundacao Araucaria; Minsterio de
   Economia y Competitividad, Spain {[}TIN2017-84802-C2-1-P]}},
Funding-Text = {{This work has been partially supported by the National Council for
   Scientific and Technological Development (CNPq) of Brazil under Grant of
   Project 310668/2019-0 and by SETI, Brazil/Fundacao Araucaria due to the
   concession of scholarships; by the ``Ministerio de Economia y
   Competitividad, Spain{''}in the ``Programa Estatal de Fomento de la
   Investigacion Cientifica y Tecnica de Excelencia, Subprograma Estatal de
   Generacion de Conocimiento{''}within the project under Grant
   TIN2017-84802-C2-1-P.}},
Number-of-Cited-References = {{65}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{15}},
Usage-Count-Since-2013 = {{15}},
Journal-ISO = {{Futur. Gener. Comp. Syst.}},
Doc-Delivery-Number = {{UF2XT}},
Unique-ID = {{WOS:000688442400014}},
DA = {{2021-11-23}},
}

@article{ WOS:000571646600001,
Author = {Dasgupta, Dipankar and Akhtar, Zahid and Sen, Sajib},
Title = {{Machine learning in cybersecurity: a comprehensive survey}},
Journal = {{JOURNAL OF DEFENSE MODELING AND SIMULATION-APPLICATIONS METHODOLOGY
   TECHNOLOGY-JDMS}},
Abstract = {{Today's world is highly network interconnected owing to the
   pervasiveness of small personal devices (e.g., smartphones) as well as
   large computing devices or services (e.g., cloud computing or online
   banking), and thereby each passing minute millions of data bytes are
   being generated, processed, exchanged, shared, and utilized to yield
   outcomes in specific applications. Thus, securing the data, machines
   (devices), and user's privacy in cyberspace has become an utmost concern
   for individuals, business organizations, and national governments. In
   recent years, machine learning (ML) has been widely employed in
   cybersecurity, for example, intrusion or malware detection and
   biometric-based user authentication. However, ML algorithms are
   vulnerable to attacks both in the training and testing phases, which
   usually leads to remarkable performance decreases and security breaches.
   Comparatively, limited studies have been conducted to understand the
   essence and degree of the vulnerabilities of ML techniques against
   security threats and their defensive mechanisms. It is imperative to
   systematize recent works related to cybersecurity using ML to seek the
   attention of researchers, scientists, and engineers. Therefore, in this
   paper, we provide a comprehensive survey of the works that have been
   carried out most recently (from 2013 to 2018) on ML in cybersecurity,
   describing the basics of cyber-attacks and corresponding defenses, the
   basics of the most commonly used ML algorithms, and proposed ML and data
   mining schemes for cybersecurity in terms of features, dimensionality
   reduction, and classification/detection techniques. In this context,
   this article also provides an overview of adversarial ML, including the
   security characteristics of deep learning methods. Finally, open issues
   and challenges in cybersecurity are highlighted and potential future
   research directions are discussed.}},
Publisher = {{SAGE PUBLICATIONS INC}},
Address = {{2455 TELLER RD, THOUSAND OAKS, CA 91320 USA}},
Type = {{Article; Early Access}},
Language = {{English}},
Affiliation = {{Dasgupta, D (Corresponding Author), Univ Memphis, Dept Comp Sci, 333 Dunn Hall, Memphis, TN 38152 USA.
   Dasgupta, Dipankar; Sen, Sajib, Univ Memphis, Ctr Informat Assurance CfIA, Memphis, TN 38152 USA.
   Akhtar, Zahid, State Univ New York SUNY Polytech Inst, Dept Network \& Comp Secur, Utica, NY USA.}},
DOI = {{10.1177/1548512920951275}},
Early Access Date = {{SEP 2020}},
Article-Number = {{1548512920951275}},
ISSN = {{1548-5129}},
EISSN = {{1557-380X}},
Keywords = {{Cybersecurity; machine learning; intrusion detection; deep neural
   network; adversarial examples; adversarial learning; defensive
   techniques}},
Keywords-Plus = {{INTRUSION DETECTION SYSTEM; FALSE DATA INJECTION; ANOMALY DETECTION;
   GAME-THEORY; ATTACKS; PERSPECTIVES; CHALLENGES; THREATS}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Multidisciplinary}},
Author-Email = {{dasgupta@memphis.edu}},
Number-of-Cited-References = {{255}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{4}},
Usage-Count-Since-2013 = {{17}},
Journal-ISO = {{J. Def. Model. Simul.-Appl. Methodol. Technol.-JDMS}},
Doc-Delivery-Number = {{NR6BL}},
Unique-ID = {{WOS:000571646600001}},
DA = {{2021-11-23}},
}

@article{ WOS:000567548200001,
Author = {Li, Wenjuan and Tian, Fei and Li, Jin and Xiang, Yang},
Title = {{Evaluating intrusion sensitivity allocation with supervised learning in
   collaborative intrusion detection}},
Journal = {{CONCURRENCY AND COMPUTATION-PRACTICE \& EXPERIENCE}},
Abstract = {{Network intrusions are a big security threat to current computer
   networks. For protection, collaborative intrusion detection networks
   (CIDNs) are developed attempting to reach better detection performance
   than a single detector, by allowing a set of detectors to switch data or
   information with each other. However, there is a need to implement
   suitable trust management schemes, with the aim to safeguard such
   distributed detection networks against insider threats. In the
   literature, previous studies have indicated that the notion of intrusion
   sensitivity can be used to enhance the effectiveness of trust
   management, by highlighting the feedback from expert nodes. In addition,
   machine learning can be used to assign the value of intrusion
   sensitivity automatically. In this work, we evaluate the performance of
   typical supervised learning classifiers in allocating the value of
   intrusion sensitivity, and figure out some limitations under different
   data sets. Then we investigate the impact of intrusion sensitivity in a
   real network environment under adversarial conditions. The results
   demonstrate that a wrongly assigned sensitivity value may greatly
   degrade the detection effectiveness of insider attacks. There is a
   significant need to choose a suitable classifier in allocating the value
   of intrusion sensitivity in practice.}},
Publisher = {{WILEY}},
Address = {{111 RIVER ST, HOBOKEN 07030-5774, NJ USA}},
Type = {{Article; Early Access}},
Language = {{English}},
Affiliation = {{Xiang, Y (Corresponding Author), Guangzhou Univ, Inst Artificial Intelligence \& Blockchain, Guangzhou, Guangdong, Peoples R China.
   Li, Wenjuan; Li, Jin; Xiang, Yang, Guangzhou Univ, Inst Artificial Intelligence \& Blockchain, Guangzhou, Guangdong, Peoples R China.
   Li, Wenjuan, Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.
   Tian, Fei, Telecom Inst, Res Ctr, Shenzhen, Peoples R China.}},
DOI = {{10.1002/cpe.5957}},
Early Access Date = {{SEP 2020}},
Article-Number = {{e5957}},
ISSN = {{1532-0626}},
EISSN = {{1532-0634}},
Keywords = {{collaborative intrusion detection; insider threat; intrusion
   sensitivity; supervised learning; trust management}},
Keywords-Plus = {{MALICIOUS NODES; TRUST; ATTACKS; FRAMEWORK; IOT}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Software Engineering; Computer Science, Theory \&
   Methods}},
Author-Email = {{yxiang@swin.edu.au}},
ORCID-Numbers = {{Li, Wenjuan/0000-0003-3745-5669}},
Funding-Acknowledgement = {{Guangzhou University Research Project {[}RD2020076]; National Natural
   Science Foundation of ChinaNational Natural Science Foundation of China
   (NSFC) {[}61772405, 61802077]}},
Funding-Text = {{Guangzhou University Research Project, Grant/Award Number: RD2020076;
   National Natural Science Foundation of China, Grant/Award Numbers:
   61772405, 61802077}},
Number-of-Cited-References = {{44}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{6}},
Journal-ISO = {{Concurr. Comput.-Pract. Exp.}},
Doc-Delivery-Number = {{NL6UN}},
Unique-ID = {{WOS:000567548200001}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000717067800005,
Author = {Hosseinzadehtaher, Mohsen and Khan, Ahmad and Shadmand, Mohammad B. and
   Abu-Rub, Haitham},
Book-Group-Author = {{IEEE}},
Title = {{Anomaly Detection in Distribution Power System based on a Condition
   Monitoring Vector and Ultra- Short Demand Forecasting}},
Booktitle = {{2020 IEEE CYBERPELS (CYBERPELS)}},
Year = {{2020}},
Note = {{IEEE CyberPELS (CyberPELS) Conference, Miami, FL, OCT 13, 2020}},
Organization = {{IEEE}},
Abstract = {{This paper presents a proactive intrusion detection system (IDS) for
   smart distribution power systems. The considered attack scenario is
   manipulation of the advanced measuring infrastructures (AMIs) readings
   and/or smart inverters data. These manipulated data from the grid edge
   devices mislead the grid operator for making proper operational planning
   decisions. In a stealthy attack model, where the attacker compromises
   significant number of these smart devices, serious demand-supply
   unbalance can occur that may result in major blackouts. The proposed IDS
   is based on a condition monitoring vector (CMV) equipped with a learned
   ultra-short-term demand forecasting (USTDF) mechanism. This
   cybersecurity approach is able to verify smart devices readings. In the
   proposed method, the instantaneous difference of collected AMIs and
   other smart devices data with the ultra-short term forecasted demand is
   defined as the CMV. This vector probes a pre-defined error band for
   identifying the compromised smart devices. The learned USTDF mechanism
   is based on the distribution grid historical load profile and the
   temperature data for the goal area. An accurate multi-dimensional
   regression model is developed and learned for forecasting the load
   behavior in this area. Finally, the suspicious areas are flagged or
   become separated from the main grid by the network operator based on the
   proposed CMV outcomes and the output of decision-making module. The
   proposed IDS aims to enhance the cybersecurity of the smart devices at
   the grid-edge that plays major role in ensuring the resiliency of the
   grid. The theoretical analyses are verified by several case studies.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Hosseinzadehtaher, M (Corresponding Author), Univ Illinois, Dept Elect \& Comp Engn, Chicago, IL 60607 USA.
   Hosseinzadehtaher, Mohsen; Khan, Ahmad; Shadmand, Mohammad B., Univ Illinois, Dept Elect \& Comp Engn, Chicago, IL 60607 USA.
   Abu-Rub, Haitham, Texas A\&M Univ Qatar, Dept Elect \& Comp Engn, Doha, Qatar.}},
ISBN = {{978-1-7281-9591-9}},
Keywords = {{intrusion detection system; smart meters; smart inverters; AMI;
   cybersecurity}},
Keywords-Plus = {{DATA INJECTION ATTACKS; STATE ESTIMATION; MODEL}},
Author-Email = {{mhosse5@uic.edu
   ahmad20@uic.edu
   shadmand@uic.edu
   haitham.abu-rub@qatar.tamu.edu}},
Funding-Acknowledgement = {{Qatar National Research Fund (QNRF is a member of Qatar Foundation)
   {[}NPRP12S-02260190158]}},
Funding-Text = {{This publication was made possible by NPRP12S-02260190158 from the Qatar
   National Research Fund (QNRF is a member of Qatar Foundation). The
   statements made herein are solely the responsibility of the authors.}},
Number-of-Cited-References = {{20}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BS4AH}},
Unique-ID = {{WOS:000717067800005}},
DA = {{2021-11-23}},
}

@article{ WOS:000660636700060,
Author = {Sadeghzadeh, Amir Mahdi and Shiravi, Saeed and Jalili, Rasool},
Title = {{Adversarial Network Traffic: Towards Evaluating the Robustness of
   Deep-Learning-Based Network Traffic Classification}},
Journal = {{IEEE TRANSACTIONS ON NETWORK AND SERVICE MANAGEMENT}},
Year = {{2021}},
Volume = {{18}},
Number = {{2}},
Pages = {{1962-1976}},
Month = {{JUN}},
Abstract = {{Network traffic classification is used in various applications such as
   network traffic management, policy enforcement, and intrusion detection
   systems. Although most applications encrypt their network traffic and
   some of them dynamically change their port numbers, Machine Learning
   (ML) and especially Deep Learning (DL)-based classifiers have shown
   impressive performance in network traffic classification. In this
   article, we evaluate the robustness of DL-based network traffic
   classifiers against Adversarial Network Traffic (ANT). ANT causes
   DL-based network traffic classifiers to predict incorrectly using
   Universal Adversarial Perturbation (UAP) generating methods. Since there
   is no need to buffer network traffic before sending ANT, it is generated
   live. We partition the input space of the DL-based network traffic
   classification into three categories: packet classification, flow
   content classification, and flow time series classification. To generate
   ANT, we propose three new attacks injecting UAP into network traffic.
   AdvPad attack injects a UAP into the content of packets to evaluate the
   robustness of packet classifiers. AdvPay attack injects a UAP into the
   payload of a dummy packet to evaluate the robustness of flow content
   classifiers. AdvBurst attack injects a specific number of dummy packets
   with crafted statistical features based on a UAP into a selected burst
   of a flow to evaluate the robustness of flow time series classifiers.
   The results indicate injecting a little UAP into network traffic, highly
   decreases the performance of DL-based network traffic classifiers in all
   categories.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Jalili, R (Corresponding Author), Sharif Univ Technol, Dept Comp Engn, Tehran 1136511155, Iran.
   Sadeghzadeh, Amir Mahdi; Shiravi, Saeed; Jalili, Rasool, Sharif Univ Technol, Dept Comp Engn, Tehran 1136511155, Iran.}},
DOI = {{10.1109/TNSM.2021.3052888}},
ISSN = {{1932-4537}},
Keywords = {{IP networks; Robustness; Payloads; Perturbation methods; Training;
   Protocols; Feature extraction; Network traffic classification;
   adversarial network traffic; deep learning; adversarial example;
   adversarial machine learning}},
Keywords-Plus = {{APP IDENTIFICATION}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems}},
Author-Email = {{amsadeghzadeh@ce.sharif.edu
   saeedshiravi@ce.sharif.edu
   jalili@sharif.edu}},
Number-of-Cited-References = {{29}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{8}},
Usage-Count-Since-2013 = {{8}},
Journal-ISO = {{IEEE Trans. Netw. Serv. Manag.}},
Doc-Delivery-Number = {{SQ8YX}},
Unique-ID = {{WOS:000660636700060}},
OA = {{Green Submitted}},
DA = {{2021-11-23}},
}

@article{ WOS:000511197000027,
Author = {Usama, Muhammad and Qadir, Junaid and Al-Fuqaha, Ala and Hamdi, Mounir},
Title = {{The Adversarial Machine Learning Conundrum: Can the Insecurity of ML
   Become the Achilles' Heel of Cognitive Networks?}},
Journal = {{IEEE NETWORK}},
Year = {{2020}},
Volume = {{34}},
Number = {{1}},
Pages = {{196-203}},
Month = {{JAN-FEB}},
Abstract = {{The holy grail of networking is to create cognitive networks that
   organize, manage, and drive themselves. Such a vision now seems
   attainable thanks in large part to the progress in the field of machine
   learning (ML), which has now already disrupted a number of industries
   and revolutionized practically all fields of research. But are the ML
   models foolproof and robust to security attacks to be in charge of
   managing the network? Unfortunately, many modern ML models are easily
   misled by simple and easily-crafted adversarial perturbations, which
   does not bode well for the future of ML-based cognitive networks unless
   ML vulnerabilities for the cognitive networking environment are
   identified, addressed, and fixed. The purpose of this article is to
   highlight the problem of unsecure ML and to sensitize the readers to the
   danger of adversarial ML by showing how an easily crafted adversarial ML
   example can compromise the operations of the cognitive self-driving
   network. In this article, we demonstrate adversarial attacks on two
   simple yet representative cognitive networking applications (namely,
   intrusion detection and network traffic classification). We also provide
   some guidelines to design secure ML models for cognitive networks that
   are robust to adversarial attacks on the ML pipeline of cognitive
   networks.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Usama, M (Corresponding Author), Informat Technol Univ ITU Punjab, Lahore, Pakistan.
   Usama, Muhammad; Qadir, Junaid, Informat Technol Univ ITU Punjab, Lahore, Pakistan.
   Al-Fuqaha, Ala; Hamdi, Mounir, Hamad Bin Khafifa Univ, Coll Sci \& Engn, Doha, Qatar.}},
DOI = {{10.1109/MNET.001.1900197}},
ISSN = {{0890-8044}},
EISSN = {{1558-156X}},
Keywords = {{Security; Task analysis; Telemetry; Data models; Perturbation methods;
   Training}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Hardware \& Architecture; Computer Science,
   Information Systems; Engineering, Electrical \& Electronic;
   Telecommunications}},
ResearcherID-Numbers = {{Qadir, Junaid/Q-6329-2019
   }},
ORCID-Numbers = {{Qadir, Junaid/0000-0001-9466-2475
   Al-Fuqaha, Ala/0000-0002-0903-1204
   Hamdi, Mounir/0000-0002-9766-0085}},
Number-of-Cited-References = {{15}},
Times-Cited = {{6}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{3}},
Journal-ISO = {{IEEE Netw.}},
Doc-Delivery-Number = {{KI2RE}},
Unique-ID = {{WOS:000511197000027}},
OA = {{Green Submitted}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000380556700213,
Author = {Li, Bo},
Editor = {{Cui, P and Dy, J and Aggarwal, C and Zhou, ZH and Tuzhilin, A and Xiong, H and Wu, X}},
Title = {{Secure Learning and Mining in Adversarial Environments}},
Booktitle = {{2015 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW)}},
Year = {{2015}},
Pages = {{1538-1539}},
Note = {{IEEE 15th International Conference on Data Mining Workshops (ICDMW),
   Atlantic, NJ, NOV 14-17, 2015}},
Organization = {{Baidu; Stony Brook Univ; Pinnacle; NSF; IEEE; Rutgers; KD Nuggets;
   Cisco; Drawbridge; IEEE Comp Soc}},
Abstract = {{Machine learning and data mining have become ubiquitous tools in modern
   computing applications and large enterprise systems benefit from its
   adaptability and intelligent ability to infer patterns that can be used
   for prediction or decision-making. Great success has been achieved by
   applying machine learning and data mining to the security settings for
   large dataset, such as in intrusion detection, virus detection,
   biometric identity recognition, and spam filtering. However, the
   strengths of the learning systems, such as the adaptability and ability
   to infer patterns, can also become their vulnerabilities when there are
   adversarial manipulations during the learning and predicting process.
   Considering the fact that the traditional learning strategies could
   potentially introduce security faults into the learning systems, robust
   machine learning techniques against the sophisticated adversaries need
   to be studied, which is referred to as secure learning and mining
   through this abstract. Based on the goal of secure learning and mining,
   I aim to analyze the behavior of learning systems in adversarial
   environments by studying different kinds of attacks against the learning
   systems. Then design robust learning algorithms to counter the
   corresponding malicious behaviors based on the evaluation and prediction
   of the adversaries' goal and capabilities. The interactions between the
   defender and attackers are modeled as different forms of games,
   therefore game theoretic analysis are applied to evaluate and predict
   the constraints for both participants to deal with the real world large
   dataset.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Li, B (Corresponding Author), Vanderbilt Univ, Elect Engn \& Comp Sci, Nashville, TN 37235 USA.
   Li, Bo, Vanderbilt Univ, Elect Engn \& Comp Sci, Nashville, TN 37235 USA.}},
DOI = {{10.1109/ICDMW.2015.44}},
ISBN = {{978-1-4673-8493-3}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods; Engineering, Electrical \& Electronic}},
Number-of-Cited-References = {{4}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BF3MK}},
Unique-ID = {{WOS:000380556700213}},
DA = {{2021-11-23}},
}

@article{ WOS:000656455700001,
Author = {Siddiqui, Abdul Jabbar and Boukerche, Azzedine},
Title = {{A Novel Lightweight Defense Method Against Adversarial Patches-Based
   Attacks on Automated Vehicle Make and Model Recognition Systems}},
Journal = {{JOURNAL OF NETWORK AND SYSTEMS MANAGEMENT}},
Year = {{2021}},
Volume = {{29}},
Number = {{4}},
Month = {{OCT}},
Abstract = {{In smart cities, connected and automated surveillance systems play an
   essential role in ensuring safety and security of life, property,
   critical infrastructures and cyberphysical systems. The recent trend of
   such surveillance systems has been to embrace the use of advanced deep
   learning models such as convolutional neural networks for the task of
   detection, monitoring or tracking. In this paper, we focus on the
   security of an automated surveillance system that is responsible for
   vehicle make and model recognition (VMMR). We introduce an adversarial
   attack against such VMMR systems through adversarially learnt patches.
   We demonstrate the effectiveness of the developed adversarial patches
   against VMMR through experimental evaluations on a real-world vehicle
   surveillance dataset. The developed adversarial patches achieve
   reductions of up to 48\% in VMMR recall scores. In addition, we propose
   a lightweight defense method called SIHFR (stands for Symmetric
   ImageHalf Flip and Replace) to eliminate the effect of adversarial
   patches on VMMR performance. Through experimental evaluations, we
   investigate the robustness of the proposed defense method under varying
   patch placement strategies and patch sizes. The proposed defense method
   adds a minimal overhead of less than 2ms per image (on average) and
   succeeds in enhancing VMMR performance by up to 69.28\%. It is hoped
   that this work shall guide future studies to develop smart city VMMR
   surveillance systems that are robust to cyber-physical attacks based on
   adversarially learnt patches.}},
Publisher = {{SPRINGER}},
Address = {{ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Siddiqui, AJ (Corresponding Author), Univ Ottawa, Sch Elect Engn \& Comp Sci, PARADISE Lab, Ottawa, ON, Canada.
   Siddiqui, Abdul Jabbar; Boukerche, Azzedine, Univ Ottawa, Sch Elect Engn \& Comp Sci, PARADISE Lab, Ottawa, ON, Canada.}},
DOI = {{10.1007/s10922-021-09608-6}},
Article-Number = {{41}},
ISSN = {{1064-7570}},
EISSN = {{1573-7705}},
Keywords = {{Cyber-physical systems security; Adversarial attacks; Vehicle
   recognition; Adversarial patches; Adversarial robustness}},
Keywords-Plus = {{INTRUSION DETECTION; COMPUTER; SECURITY}},
Research-Areas = {{Computer Science; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Telecommunications}},
Author-Email = {{aj.siddiqui@uottawa.ca
   boukerch@site.uottawa.ca}},
Funding-Acknowledgement = {{Canada Research Chairs ProgramCanada Research Chairs; Natural Sciences
   and Engineering Research Council of Canada (NSERC)'s CREATE TRANSIT
   Program}},
Funding-Text = {{This study was partially funded by Canada Research Chairs Program and
   Natural Sciences and Engineering Research Council of Canada (NSERC)'s
   CREATE TRANSIT Program.}},
Number-of-Cited-References = {{35}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{17}},
Usage-Count-Since-2013 = {{17}},
Journal-ISO = {{J. Netw. Syst. Manag.}},
Doc-Delivery-Number = {{SK8HA}},
Unique-ID = {{WOS:000656455700001}},
DA = {{2021-11-23}},
}

@article{ WOS:000455514800002,
Author = {Li, Jian-hua},
Title = {{Cyber security meets artificial intelligence: a survey}},
Journal = {{FRONTIERS OF INFORMATION TECHNOLOGY \& ELECTRONIC ENGINEERING}},
Year = {{2018}},
Volume = {{19}},
Number = {{12, SI}},
Pages = {{1462-1474}},
Month = {{DEC}},
Abstract = {{There is a wide range of interdisciplinary intersections between cyber
   security and artificial intelligence (AI). On one hand, AI technologies,
   such as deep learning, can be introduced into cyber security to
   construct smart models for implementing malware classification and
   intrusion detection and threating intelligence sensing. On the other
   hand, AI models will face various cyber threats, which will disturb
   their sample, learning, and decisions. Thus, AI models need specific
   cyber security defense and protection technologies to combat adversarial
   machine learning, preserve privacy in machine learning, secure federated
   learning, etc. Based on the above two aspects, we review the
   intersection of AI and cyber security. First, we summarize existing
   research efforts in terms of combating cyber attacks using AI, including
   adopting traditional machine learning methods and existing deep learning
   solutions. Then, we analyze the counterattacks from which AI itself may
   suffer, dissect their characteristics, and classify the corresponding
   defense methods. Finally, from the aspects of constructing encrypted
   neural network and realizing a secure federated deep learning, we
   expatiate the existing research on how to build a secure AI system.}},
Publisher = {{ZHEJIANG UNIV}},
Address = {{EDITORIAL BOARD, 20 YUGU RD, HANGZHOU, 310027, PEOPLES R CHINA}},
Type = {{Review}},
Language = {{English}},
Affiliation = {{Li, JH (Corresponding Author), Shanghai Jiao Tong Univ, Sch Cyber Secur, Shanghai 200240, Peoples R China.
   Li, Jian-hua, Shanghai Jiao Tong Univ, Sch Cyber Secur, Shanghai 200240, Peoples R China.}},
DOI = {{10.1631/FITEE.1800573}},
ISSN = {{2095-9184}},
EISSN = {{2095-9230}},
Keywords = {{Cyber security; Artificial intelligence (AI); Attack detection;
   Defensive techniques}},
Keywords-Plus = {{INTRUSION DETECTION; DEEP; EFFICIENT; INTERNET; SYSTEM}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Software
   Engineering; Engineering, Electrical \& Electronic}},
Author-Email = {{lijh888@sjtu.edu.cn}},
Funding-Acknowledgement = {{National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}61431008, 61571300]}},
Funding-Text = {{Project supported by the National Natural Science Foundation of China
   (Nos. 61431008 and 61571300)}},
Number-of-Cited-References = {{66}},
Times-Cited = {{20}},
Usage-Count-Last-180-days = {{27}},
Usage-Count-Since-2013 = {{110}},
Journal-ISO = {{Front. Inform. Technol. Elect. Eng.}},
Doc-Delivery-Number = {{HH1YC}},
Unique-ID = {{WOS:000455514800002}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000546175300022,
Author = {Li, Pan and Zhao, Wentao and Liu, Qiang and Liu, Xiao and Yu, Linyuan},
Editor = {{Chellappan, S and Cheng, W and Li, W}},
Title = {{Poisoning Machine Learning Based Wireless IDSs via Stealing Learning
   Model}},
Booktitle = {{WIRELESS ALGORITHMS, SYSTEMS, AND APPLICATIONS (WASA 2018)}},
Series = {{Lecture Notes in Computer Science}},
Year = {{2018}},
Volume = {{10874}},
Pages = {{261-273}},
Note = {{13th International Conference on Wireless Algorithms, Systems, and
   Applications (WASA), Tianjin, PEOPLES R CHINA, JUN 20-22, 2018}},
Abstract = {{Recently, machine learning-based wireless intrusion detection systems
   (IDSs) have been demonstrated to have high detection accuracy in
   malicious traffic detection. However, many researchers argue that a
   variety of attacks are significantly challenging the security of machine
   learning techniques themselves. In this paper, we study two different
   types of security threats which can effectively degrade the performance
   of machine learning based wireless IDSs. First, we propose an Adaptive
   SMOTE (A-SMOTE) algorithm which can adaptively generate new training
   data points based on few existing ones with labels. Then, we introduce a
   stealing model attack by training a substitute model using deep neural
   networks (DNNs) based on the augmented training data in order to imitate
   the machine learning model embedded in targeted systems. After that, we
   present a novel poisoning strategy to attack against the substitute
   machine learning model, resulting in a set of adversarial samples that
   can be used to degrade the performance of targeted systems. Experiments
   on three real data sets collected from wired and wireless networks have
   demonstrated that the proposed stealing model and poisoning attacks can
   effectively degrade the performance of IDSs using different machine
   learning algorithms.}},
Publisher = {{SPRINGER INTERNATIONAL PUBLISHING AG}},
Address = {{GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Zhao, WT; Liu, Q (Corresponding Author), Natl Univ Def Technol, Changsha 410073, Hunan, Peoples R China.
   Li, Pan; Zhao, Wentao; Liu, Qiang; Liu, Xiao; Yu, Linyuan, Natl Univ Def Technol, Changsha 410073, Hunan, Peoples R China.}},
DOI = {{10.1007/978-3-319-94268-1\_22}},
ISSN = {{0302-9743}},
EISSN = {{1611-3349}},
ISBN = {{978-3-319-94268-1; 978-3-319-94267-4}},
Keywords-Plus = {{INTRUSION DETECTION}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Hardware \&
   Architecture; Computer Science, Information Systems; Computer Science,
   Software Engineering; Computer Science, Theory \& Methods}},
Author-Email = {{wtzhao@nudt.edu.cn
   qiangliu06@nudt.edu.cn}},
Number-of-Cited-References = {{18}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BP3BM}},
Unique-ID = {{WOS:000546175300022}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000611750900026,
Author = {Li, Wenjuan and Meng, Weizhi and Kwok, Lam For},
Editor = {{Heng, SH and Lopez, J}},
Title = {{Evaluating Intrusion Sensitivity Allocation with Support Vector Machine
   for Collaborative Intrusion Detection}},
Booktitle = {{INFORMATION SECURITY PRACTICE AND EXPERIENCE, ISPEC 2019}},
Series = {{Lecture Notes in Computer Science}},
Year = {{2019}},
Volume = {{11879}},
Pages = {{453-463}},
Note = {{15th International Conference on Information Security Practice and
   Experience (ISPEC), Univ Tunku Abdul Rahman, Kuala Lumpur, MALAYSIA, NOV
   26-28, 2019}},
Organization = {{Huawei Int}},
Abstract = {{The aim of collaborative intrusion detection networks (CIDNs) is to
   provide better detection performance over a single IDS, through allowing
   IDS nodes to exchange data or information with each other. Nevertheless,
   CIDNs may be vulnerable to insider attacks, and there is a great need
   for deploying appropriate trust management schemes to protect CIDNs in
   practice. In this work, we advocate the effectiveness of intrusion
   sensitivity-based trust management model and describe an engineering way
   to automatically allocate the sensitivity values by using a support
   vector machine (SVM) classifier. To explore the allocation performance,
   we compare our classifier with several traditional supervised algorithms
   in the evaluation. We further investigate the performance of our
   enhanced trust management scheme in a real network environment under
   adversarial scenarios, and the experimental results indicate that our
   approach can be more effective in detecting insider attacks as compared
   with similar approaches.}},
Publisher = {{SPRINGER INTERNATIONAL PUBLISHING AG}},
Address = {{GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Meng, WZ (Corresponding Author), Tech Univ Denmark, Dept Appl Math \& Comp Sci, Lyngby, Denmark.
   Li, Wenjuan; Kwok, Lam For, City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
   Meng, Weizhi, Tech Univ Denmark, Dept Appl Math \& Comp Sci, Lyngby, Denmark.}},
DOI = {{10.1007/978-3-030-34339-2\_26}},
ISSN = {{0302-9743}},
EISSN = {{1611-3349}},
ISBN = {{978-3-030-34339-2; 978-3-030-34338-5}},
Keywords = {{Collaborative intrusion detection; Intrusion sensitivity; Supervised
   learning; Trust management; Insider threat}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Theory \&
   Methods}},
Author-Email = {{weme@dtu.dk}},
ORCID-Numbers = {{Li, Wenjuan/0000-0003-3745-5669}},
Funding-Acknowledgement = {{National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}61802077]}},
Funding-Text = {{This work was partially supported by National Natural Science Foundation
   of China (No. 61802077).}},
Number-of-Cited-References = {{22}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BQ6HE}},
Unique-ID = {{WOS:000611750900026}},
OA = {{Green Published}},
DA = {{2021-11-23}},
}

@article{ WOS:000495394100005,
Author = {Yan, Qiao and Wang, Mingde and Huang, Wenyao and Luo, Xupeng and Yu, F.
   Richard},
Title = {{Automatically synthesizing DoS attack traces using generative
   adversarial networks}},
Journal = {{INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS}},
Year = {{2019}},
Volume = {{10}},
Number = {{12}},
Pages = {{3387-3396}},
Month = {{DEC}},
Abstract = {{Artificial intelligence (AI) technology ruling people is still the scene
   in the science fiction film, but hackers using AI technology against
   existing security measures is an inescapable trend. Network intrusion
   detection systems (NIDS) based deep learning such as convolutional
   neural network (CNN) have reached a very high detection rate. But we
   propose DoS-WGAN, a common architecture that uses the Wasserstein
   generative adversarial networks (WGAN) with gradient penalty technology
   to evade network traffic Classifiers. To camouflage offensive denial of
   service (DoS) attack traffic as normal network traffic, DoS-WGAN
   automatically synthesizes attack traces that can defeat a existing
   NIDS/network security defense for DoS cases. Information entropy is used
   to measure the dispersing performance of generated DoS attack traffic.
   The generated DoS attack traffic is so similar to the normal traffic
   that detection algorithm cannot distinguish between them. When we input
   the generated DoS attack traffic to a NIDS based on CNN in our
   experiments, the detection rate drops to 47.6\% from 97.3\%. To make the
   training more stable, we integrate the Standardized Euclidean distance
   and the information entropy to evaluate the training process. We believe
   that AI technology will play a particularly important role in the game
   of network attack and defense.}},
Publisher = {{SPRINGER HEIDELBERG}},
Address = {{TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Yan, Q (Corresponding Author), Shenzhen Univ, Coll Comp Sci \& Software Engn, Shenzhen, Peoples R China.
   Yan, Qiao; Wang, Mingde; Huang, Wenyao; Luo, Xupeng, Shenzhen Univ, Coll Comp Sci \& Software Engn, Shenzhen, Peoples R China.
   Yu, F. Richard, Carleton Univ, Coll Syst \& Comp Engn, Ottawa, ON, Canada.}},
DOI = {{10.1007/s13042-019-00925-6}},
ISSN = {{1868-8071}},
EISSN = {{1868-808X}},
Keywords = {{Network intrusion detection systems; Generative adversarial networks;
   Wasserstein-GAN}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{yanq@szu.edu.cn
   2160230428@email.szu.edu.cn
   richard.yu@carleton.ca}},
ResearcherID-Numbers = {{YAN, QIAO/AAN-2319-2020
   Yu, F. Richard/B-3182-2018
   }},
ORCID-Numbers = {{YAN, QIAO/0000-0003-0412-0416
   Yu, F. Richard/0000-0003-1006-7594
   mingde, wang/0000-0002-7332-2989}},
Funding-Acknowledgement = {{National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}61672358]; Basic Research Program of
   Shenzhen, China under its Suppress Distributed Denial of Service Attacks
   in IoT Program {[}JCYJ20170302154032530]}},
Funding-Text = {{We thank the anonymous reviewers of this work for their helpful
   feedback. This research is supported in part by a grant from the
   National Natural Science Foundation of China (no. 61672358). This
   research is also supported in part by a grant from Basic Research
   Program of Shenzhen, China under its Suppress Distributed Denial of
   Service Attacks in IoT Program (no. JCYJ20170302154032530). All opinions
   expressed in this paper are solely those of the authors.}},
Number-of-Cited-References = {{31}},
Times-Cited = {{8}},
Usage-Count-Last-180-days = {{4}},
Usage-Count-Since-2013 = {{37}},
Journal-ISO = {{Int. J. Mach. Learn. Cybern.}},
Doc-Delivery-Number = {{JL2XC}},
Unique-ID = {{WOS:000495394100005}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000540643900019,
Author = {Araujo, Frederico and Ayoade, Gbadebo and Al-Naami, Khaled and Gao, Yang
   and Hamlen, Kevin W. and Khan, Latifur},
Book-Group-Author = {{ACM}},
Title = {{Improving Intrusion Detectors by Crook-sourcing}},
Booktitle = {{35TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSA)}},
Year = {{2019}},
Pages = {{245-256}},
Note = {{35th Annual Computer Security Applications Conference (ACSA), San Juan,
   PREF\_CTRY\_STATE, DEC 09-13, 2019}},
Organization = {{Appl Comp Secur Associates; Natl Sci Fdn; Charles Koch Inst}},
Abstract = {{Conventional cyber defenses typically respond to detected attacks by
   rejecting them as quickly and decisively as possible; but aborted
   attacks are missed learning opportunities for intrusion detection. A
   method of reimagining cyber attacks as free sources of live training
   data for machine learning-based intrusion detection systems (IDSes) is
   proposed and evaluated. Rather than aborting attacks against legitimate
   services, adversarial interactions are selectively prolonged to maximize
   the defender's harvest of useful threat intelligence. Enhancing web
   services with deceptive attack-responses in this way is shown to be a
   powerful and practical strategy for improved detection, addressing
   several perennial challenges for machine learning-based IDS in the
   literature, including scarcity of training data, the high labeling
   burden for (semi-)supervised learning, encryption opacity, and concept
   differences between honeypot attacks and those against genuine services.
   By reconceptualizing software security patches as feature extraction
   engines, the approach conscripts attackers as free penetration testers,
   and coordinates multiple levels of the software stack to achieve fast,
   automatic, and accurate labeling of live web data streams.
   Prototype implementations are showcased for two feature set models to
   extract security-relevant network- and system-level features from
   servers hosting enterprise-grade web applications. The evaluation
   demonstrates that the extracted data can be fed back into a
   network-level IDS for exceptionally accurate, yet lightweight attack
   detection.}},
Publisher = {{ASSOC COMPUTING MACHINERY}},
Address = {{1515 BROADWAY, NEW YORK, NY 10036-9998 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Araujo, F (Corresponding Author), IBM Res, Yorktown Hts, NY 10598 USA.
   Araujo, Frederico, IBM Res, Yorktown Hts, NY 10598 USA.
   Ayoade, Gbadebo; Al-Naami, Khaled; Gao, Yang; Hamlen, Kevin W.; Khan, Latifur, Univ Texas Dallas, Richardson, TX 75083 USA.}},
DOI = {{10.1145/3359789.3359822}},
ISBN = {{978-1-4503-7628-0}},
Keywords = {{datasets; neural networks; intrusion detection; honeypots}},
Keywords-Plus = {{SYSTEMS}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Theory \&
   Methods}},
ResearcherID-Numbers = {{Khan, Latifur/AAE-8134-2021
   }},
ORCID-Numbers = {{Khan, Latifur/0000-0002-9300-1576}},
Funding-Acknowledgement = {{ONROffice of Naval Research {[}N00014-17-1-2995]; NSANational Security
   Agency {[}H98230-15-1-0271]; AFOSRUnited States Department of DefenseAir
   Force Office of Scientific Research (AFOSR) {[}FA9550-14-1-0173]; NSF
   FAIN awards {[}DGE-1931800, OAC-1828467, DGE1723602]; NSFNational
   Science Foundation (NSF) {[}DMS-1737978, MRI-1828467]; IBM faculty
   awardInternational Business Machines (IBM); HP grant; Eugene McDermott
   family}},
Funding-Text = {{The research reported herein was supported in part by ONR award
   N00014-17-1-2995; NSA award H98230-15-1-0271; AFOSR award
   FA9550-14-1-0173; an endowment from the Eugene McDermott family; NSF
   FAIN awards DGE-1931800, OAC-1828467, and DGE1723602; NSF awards
   DMS-1737978 and MRI-1828467; an IBM faculty award (Research); and an HP
   grant. Any opinions, recommendations, or conclusions expressed are those
   of the authors and not necessarily of the aforementioned supporters.}},
Number-of-Cited-References = {{80}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BP1RJ}},
Unique-ID = {{WOS:000540643900019}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000546175300008,
Author = {Dong, Yifan and Zhu, Peidong and Liu, Qiang and Chen, Yingwen and Xun,
   Peng},
Editor = {{Chellappan, S and Cheng, W and Li, W}},
Title = {{Degrading Detection Performance of Wireless IDSs Through Poisoning
   Feature Selection}},
Booktitle = {{WIRELESS ALGORITHMS, SYSTEMS, AND APPLICATIONS (WASA 2018)}},
Series = {{Lecture Notes in Computer Science}},
Year = {{2018}},
Volume = {{10874}},
Pages = {{90-102}},
Note = {{13th International Conference on Wireless Algorithms, Systems, and
   Applications (WASA), Tianjin, PEOPLES R CHINA, JUN 20-22, 2018}},
Abstract = {{Machine learning algorithms have been increasingly adopted in Intrusion
   Detection Systems (IDSs) and achieved demonstrable results, but few
   studies have considered intrinsic vulnerabilities of these algorithms in
   adversarial environment. In our work, we adopt poisoning attack to
   influence the accuracy of wireless IDSs that adopt feature selection
   algorithms. Specifically, we adopt the gradient poisoning method to
   generate adversarial examples which induce classifier to select a
   feature subset to make the classification error rate biggest. We
   consider the box-constrained problem and use Lagrange multiplier and
   backtracking line search to find the feasible gradient. To evaluate our
   method, we experimentally demonstrate that our attack method can
   influence machine learning, including filter and embedded feature
   selection algorithms using three benchmark network public datasets and a
   wireless sensor network dataset, i.e., KDD99, NSL-KDD, Kyoto 2006+ and
   WSN-DS. Our results manifest that gradient poisoning method causes a
   significant drop in the classification accuracy of IDSs about 20\%.}},
Publisher = {{SPRINGER INTERNATIONAL PUBLISHING AG}},
Address = {{GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Zhu, PD; Liu, Q (Corresponding Author), Natl Univ Def Technol, Changsha 410073, Peoples R China.
   Zhu, PD (Corresponding Author), Changsha Univ, Changsha 410022, Peoples R China.
   Dong, Yifan; Zhu, Peidong; Liu, Qiang; Chen, Yingwen; Xun, Peng, Natl Univ Def Technol, Changsha 410073, Peoples R China.
   Zhu, Peidong, Changsha Univ, Changsha 410022, Peoples R China.}},
DOI = {{10.1007/978-3-319-94268-1\_8}},
ISSN = {{0302-9743}},
EISSN = {{1611-3349}},
ISBN = {{978-3-319-94268-1; 978-3-319-94267-4}},
Keywords = {{Gradient poisoning; IDS; Feature selection; Adversarial examples}},
Keywords-Plus = {{INTRUSION; REGRESSION}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Hardware \&
   Architecture; Computer Science, Information Systems; Computer Science,
   Software Engineering; Computer Science, Theory \& Methods}},
Author-Email = {{dongyifan16@nudt.edu.cn
   pdzhu@nudt.edu.cn
   qiangliu06@nudt.edu.cn
   csywchen@gmail.com
   xunpeng12@nudt.edu.cn}},
Funding-Acknowledgement = {{National Nature Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}61572514, 61702539]}},
Funding-Text = {{This work is supported by the National Nature Science Foundation of
   China under Grant Nos. 61572514 and 61702539.}},
Number-of-Cited-References = {{19}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BP3BM}},
Unique-ID = {{WOS:000546175300008}},
DA = {{2021-11-23}},
}

@article{ WOS:000683628700001,
Author = {Rajasoundaran, S. and Kumar, S. V. N. Santhosh and Selvi, M. and
   Ganapathy, Sannasi and Rakesh, R. and Kannan, Arupathraj},
Title = {{Machine learning based volatile block chain construction for secure
   routing in decentralized military sensor networks}},
Journal = {{WIRELESS NETWORKS}},
Year = {{2021}},
Volume = {{27}},
Number = {{7}},
Pages = {{4513-4534}},
Month = {{OCT}},
Abstract = {{Wireless Sensor Networks (WSNs) contain multiple wireless sensor nodes
   deployed around the geographical locations. The WSN used in military
   applications need more security and hence the deployment of trustworthy
   nodes and links in WSN provides more secure data transmission in
   Decentralized Military Sensor Networks (DMSNs). Moreover, the DMSNs work
   with different set of significance constraints including higher security
   requirements. The design of DMSNs targets surveillance tasks, intruder
   tracking tasks, army resource maintenance tasks and communication
   security requirements. Therefore, building a secure and dynamic DMSN
   against multiple threats is a challenging task. In addition, security
   principles developed for DMSN cause excessive energy consumption.
   Moreover, DMSN has completely open distributed architecture without
   having any base stations. Under this situation, the need for effective
   and secured data communication can be achieved with the help of a secure
   routing protocol. Block chains are generally used for making secure
   financial transactions. However, the routing protocols used in DMSN can
   support autonomous routing transactions from one node to other node. In
   this situation, block chain enabled routing procedures can ensure the
   trustworthiness of any data that is forwarded through different sensor
   nodes. Hence, a new Generative Adversarial Networks (GAN) based Block
   Chain enabled secured Routing Protocol (GBCRP) is proposed in this paper
   which authenticates and validates the ongoing routing procedures of
   DMSN. Moreover, a new intrusion detection system is also proposed in
   this work using GAN which is deployed in the nodes of the DMSN for
   enhancing the security of communication. Since block chain based routing
   protocols do not provide security, the GBCRP works for creating volatile
   block chains using decentralized authentication principles and effective
   intrusion detection. The proposed system uses a Fully Decentralized
   Generative Adversarial Network (FDGAN) for monitoring the secure routing
   transactions by the development of an intrusion detection system. The
   results obtained from this work show that the proposed GBCRP providing
   better secured routing compared to the existing systems with respect to
   security, energy consumption and routing metrics.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Kumar, SVNS (Corresponding Author), Vellore Inst Technol, Sch Informat Technol \& Engn, Vellore campus, Bhopal, India.
   Rajasoundaran, S.; Rakesh, R., Vellore Inst Technol, Sch Comp Sci \& Engn, Bhopal Campus, Bhopal, India.
   Kumar, S. V. N. Santhosh, Vellore Inst Technol, Sch Informat Technol \& Engn, Vellore campus, Bhopal, India.
   Selvi, M.; Kannan, Arupathraj, Vellore Inst Technol, Sch Comp Sci \& Engn, Vellore campus, Bhopal, India.
   Ganapathy, Sannasi, Vellore Inst Technol, Sch Comp Sci \& Engn, Chennai Campus, Bhopal, India.}},
DOI = {{10.1007/s11276-021-02748-2}},
Early Access Date = {{AUG 2021}},
ISSN = {{1022-0038}},
EISSN = {{1572-8196}},
Keywords = {{Machine learning; Block chain; Authentication; WSN; Routing; Intrusion
   detection; Military and security}},
Keywords-Plus = {{EFFECTIVE COMMUNICATION; INTRUSION DETECTION; ALGORITHM}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{raja.soundaran@vitbhopal.ac.in
   santhoshkumar.svn@vit.ac.in
   selvi.m@vit.ac.in
   ganapathy.s@vit.ac.in
   rakesh.r@vitbhopal.ac.in
   kannan.a@vit.ac.in}},
Number-of-Cited-References = {{54}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{4}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{Wirel. Netw.}},
Doc-Delivery-Number = {{UX0WM}},
Unique-ID = {{WOS:000683628700001}},
DA = {{2021-11-23}},
}

@article{ WOS:000500480200001,
Author = {Sethi, Kamalakanta and Rupesh, E. Sai and Kumar, Rahul and Bera,
   Padmalochan and Madhav, Y. Venu},
Title = {{A context-aware robust intrusion detection system: a reinforcement
   learning-based approach}},
Journal = {{INTERNATIONAL JOURNAL OF INFORMATION SECURITY}},
Year = {{2020}},
Volume = {{19}},
Number = {{6}},
Pages = {{657-678}},
Month = {{DEC}},
Abstract = {{Detection and prevention of intrusions in enterprise networks and
   systems is an important, but challenging problem due to extensive growth
   and usage of networks that are constantly facing novel attacks. An
   intrusion detection system (IDS) monitors the network traffic and
   system-level applications to detect malicious activities in the network.
   However, most of the existing IDSs are incapable of providing higher
   accuracy and less false positive rate (FPR). Therefore, there is a need
   for adaptive techniques to detect network intrusions that maintain a
   balance between accuracy and FPR. In this paper, we present a
   context-adaptive IDS that uses multiple independent deep reinforcement
   learning agents distributed across the network for accurate detection
   and classification of new and complex attacks. We have done extensive
   experimentation using three benchmark datasets including NSL-KDD,
   UNSW-NB15 and AWID on our model that shows better accuracy and less FPR
   compared to the state-of-the-art systems. Further, we analysed the
   robustness of our model against adversarial attack and observed only a
   small decrease in accuracy as compared to the existing models. To
   further improve the robustness of the system, we implemented the concept
   of denoising autoencoder. Also, we have shown the usability of our
   system in real-life application with changes in the attack pattern.}},
Publisher = {{SPRINGER}},
Address = {{ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Sethi, K (Corresponding Author), Indian Inst Technol, Bhubaneswar 752050, Odisha, India.
   Sethi, Kamalakanta; Rupesh, E. Sai; Kumar, Rahul; Bera, Padmalochan; Madhav, Y. Venu, Indian Inst Technol, Bhubaneswar 752050, Odisha, India.}},
DOI = {{10.1007/s10207-019-00482-7}},
Early Access Date = {{DEC 2019}},
ISSN = {{1615-5262}},
EISSN = {{1615-5270}},
Keywords = {{Adversarial attack; Context; Denoising autoencoder; FPR; IDS; Deep
   reinforcement learning (DRL) agent; NSL-KDD; AWID; UNSW-NB15}},
Keywords-Plus = {{KDD99}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory \& Methods}},
Author-Email = {{ks23@iitbbs.ac.in
   se10@iitbbs.ac.in
   rk36@iitbbs.ac.in
   plb@iitbbs.ac.in
   yvm10@iitbbs.ac.in}},
Number-of-Cited-References = {{64}},
Times-Cited = {{5}},
Usage-Count-Last-180-days = {{4}},
Usage-Count-Since-2013 = {{21}},
Journal-ISO = {{Int. J. Inf. Secur.}},
Doc-Delivery-Number = {{OG9KF}},
Unique-ID = {{WOS:000500480200001}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000538328100281,
Author = {Raju, Godwin and Zavarsky, Pavol and Makanju, Adetokunbo and Malik,
   Yasir},
Book-Group-Author = {{ACM}},
Title = {{Vulnerability Assessment of Machine Learning Based Malware
   Classification Models}},
Booktitle = {{PROCEEDINGS OF THE 2019 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE
   COMPANION (GECCCO'19 COMPANION)}},
Year = {{2019}},
Pages = {{1615-1618}},
Note = {{Genetic and Evolutionary Computation Conference (GECCO), Prague, CZECH
   REPUBLIC, JUL 13-17, 2019}},
Organization = {{Assoc Comp Machinery; Assoc Comp Machinery, Special Interest Grp Genet
   \& Evolutionary Computat}},
Abstract = {{The primary focus of the machine learning model is to train a system to
   achieve self-reliance. However, due to the absence of the inbuilt
   security functions the learning phase itself is not secured which allows
   attacker to exploit the security vulnerabilities in the machine learning
   model. When a malicious adversary manipulates the input data, it
   exploits vulnerabilities of machine learning algorithms which can
   compromise the entire system. In this research study, we are conducting
   a vulnerability assessment of the malware classification model by
   injecting the datasets with an adversarial example to degrade the
   quality of classification obtained currently by a trained model. The
   objective is to find the security gaps that are exploitable in the
   model. The vulnerability assessment is done by introducing the malware
   classification model to an AML environment using the Black-Box attack.
   The simulation provided an insight into the inputs injected into the
   classifiers and proves the inherent security vulnerability exists in the
   classification model.}},
Publisher = {{ASSOC COMPUTING MACHINERY}},
Address = {{1515 BROADWAY, NEW YORK, NY 10036-9998 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Malik, Y (Corresponding Author), New York Inst Technol, Vancouver, BC, Canada.
   Raju, Godwin; Zavarsky, Pavol, Concordia Univ Edmonton, Edmonton, AB, Canada.
   Makanju, Adetokunbo; Malik, Yasir, New York Inst Technol, Vancouver, BC, Canada.}},
DOI = {{10.1145/3319619.3326897}},
ISBN = {{978-1-4503-6748-6}},
Keywords = {{Machine Learning; Adversarial Machine Learning; Black-Box Attack;
   Poisoning Attack; Intrusion Detection System; Malware Classification}},
Research-Areas = {{Mathematics}},
Web-of-Science-Categories  = {{Mathematics, Interdisciplinary Applications}},
Author-Email = {{graju@concordia.ab.ca
   pavol.zavarsky@concordia.ab.ca
   amakanju@nyit.edu
   ymalik@nyit.edu}},
Number-of-Cited-References = {{13}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BP0XM}},
Unique-ID = {{WOS:000538328100281}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000574771800050,
Author = {Mohammadi, Bahram and Sabokrou, Mohammad},
Editor = {{Andersson, K and Tan, HP and Oteafy, S}},
Title = {{End-to-End Adversarial Learning for Intrusion Detection in Computer
   Networks}},
Booktitle = {{PROCEEDINGS OF THE IEEE LCN: 2019 44TH ANNUAL IEEE CONFERENCE ON LOCAL
   COMPUTER NETWORKS (LCN 2019)}},
Series = {{Conference on Local Computer Networks}},
Year = {{2019}},
Pages = {{270-273}},
Note = {{44th Annual IEEE Conference on Local Computer Networks (IEEE LCN),
   Osnabruck, GERMANY, OCT 14-17, 2019}},
Organization = {{IEEE; IEEE Comp Soc; IEEE Comp Soc Tech Comm Comp Commun}},
Abstract = {{This paper presents a simple yet efficient method for an anomaly-based
   Intrusion Detection System (IDS). In reality, IDSs can be defined as a
   one-class classification system, where the normal traffic is the target
   class. The high diversity of network attacks in addition to the need for
   generalization, motivate us to propose a semi-supervised method.
   Inspired by the successes of Generative Adversarial Networks (GANs) for
   training deep models in semi-unsupervised setting, we have proposed an
   end-to-end deep architecture for IDS. The proposed architecture is
   composed of two deep networks, each of which trained by competing with
   each other to understand the underlying concept of the normal traffic
   class. The key idea of this paper is to compensate the lack of anomalous
   traffic by approximately obtain them from normal flows. In this case,
   our method is not biased towards the available intrusions in the
   training set leading to more accurate detection. The proposed method has
   been evaluated on NSL-KDD dataset. The results confirm that our method
   outperforms the other state-of-the-art approaches.}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Mohammadi, B (Corresponding Author), Sharif Univ Technol, Tehran, Iran.
   Mohammadi, Bahram, Sharif Univ Technol, Tehran, Iran.
   Sabokrou, Mohammad, Inst Res Fundamental Sci IPM, Tehran, Iran.}},
ISSN = {{0742-1303}},
ISBN = {{978-1-7281-1028-8}},
Keywords-Plus = {{SYSTEM}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Hardware \& Architecture; Computer Science, Theory \&
   Methods}},
Author-Email = {{bmohammadi@alum.sharif.edu
   sabokro@ipm.ir}},
Number-of-Cited-References = {{17}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BQ0XH}},
Unique-ID = {{WOS:000574771800050}},
OA = {{Green Submitted}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000684258200036,
Author = {Erba, Alessandro and Taormina, Riccardo and Galelli, Stefano and
   Pogliani, Marcello and Carminati, Michele and Zanero, Stefano and
   Tippenhauer, Nils Ole},
Book-Group-Author = {{ASSOC COMP MACHINERY}},
Title = {{Constrained Concealment Attacks against Reconstruction-based Anomaly
   Detectors in Industrial Control Systems}},
Booktitle = {{36TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2020)}},
Series = {{Annual Computer Security Applications Conference - Proceedings}},
Year = {{2020}},
Pages = {{480-495}},
Note = {{36th Annual Computer Security Applications Virtual Conference (ACSAC),
   ELECTR NETWORK, DEC 07-11, 2020}},
Organization = {{Appl Comp Secur Associates; IBM}},
Abstract = {{Recently, reconstruction-based anomaly detection was proposed as an
   effective technique to detect attacks in dynamic industrial control
   networks. Unlike classical network anomaly detectors that observe the
   network traffic, reconstruction-based detectors operate on the measured
   sensor data, leveraging physical process models learned a priori.
   In this work, we investigate different approaches to evade prior-work
   reconstruction-based anomaly detectors by manipulating sensor data so
   that the attack is concealed. We find that replay attacks (commonly
   assumed to be very strong) show bad performance (i.e., increasing the
   number of alarms) if the attacker is constrained to manipulate less than
   95\% of all features in the system, as hidden correlations between the
   features are not replicated well. To address this, we propose two novel
   attacks that manipulate a subset of the sensor readings, leveraging
   learned physical constraints of the system. Our attacks feature two
   different attacker models: A white box attacker, which uses an
   optimization approach with a detection oracle, and a black box attacker,
   which uses an autoencoder to translate anomalous data into normal data.
   We evaluate our implementation on two different datasets from the water
   distribution domain, showing that the detector's Recall drops from 0.68
   to 0.12 by manipulating 4 sensors out of 82 in WADI dataset. In
   addition, we show that our black box attacks are transferable to
   different detectors: They work against autoencoder-, LSTM-, and
   CNN-based detectors. Finally, we implement and demonstrate our attacks
   on a real industrial testbed to demonstrate their feasibility in
   real-time.}},
Publisher = {{ASSOC COMPUTING MACHINERY}},
Address = {{1515 BROADWAY, NEW YORK, NY 10036-9998 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Erba, A (Corresponding Author), CISPA Helmholtz Ctr Informat Secur, Saarbrucken, Germany.
   Erba, Alessandro; Tippenhauer, Nils Ole, CISPA Helmholtz Ctr Informat Secur, Saarbrucken, Germany.
   Taormina, Riccardo, Delft Univ Technol, Delft, Netherlands.
   Galelli, Stefano, Singapore Univ Technol \& Design, Singapore, Singapore.
   Erba, Alessandro; Pogliani, Marcello; Carminati, Michele; Zanero, Stefano, Politecn Milan, Milan, Italy.
   Erba, Alessandro, Saarland Univ, Saarbrucken Grad Sch Comp Sci, Saarbrucken, Germany.
   Erba, Alessandro, SUTD, Singapore, Singapore.}},
DOI = {{10.1145/3427228.3427660}},
ISSN = {{1063-9527}},
ISBN = {{978-1-4503-8858-0}},
Keywords = {{Industrial Control System; Intrusion Detection; Deep Learning;
   Adversarial Machine Learning; Evasion Attack; Classifier Evasion; Mean
   Squared Error; Autoencoder; Multivariate Time Series}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Theory \&
   Methods}},
Author-Email = {{alessandro.erba@cispa.saarland
   r.taormina@tudelft.nl
   stefano\_galelli@sutd.edu.sg
   marcello.pogliani@polimi.it
   michele.carminati@polimi.it
   stefano.zanero@polimi.it
   tippenhauer@cispa.saarland}},
ResearcherID-Numbers = {{Zanero, Stefano/B-3063-2009
   }},
ORCID-Numbers = {{Zanero, Stefano/0000-0003-4710-5283
   Carminati, Michele/0000-0001-8284-6074}},
Funding-Acknowledgement = {{National Research Foundation (NRF), Singapore, under its National
   Cybersecurity RD ProgrammeNational Research Foundation, Singapore
   {[}NRF2014NCR-NCR001-40]; European Union's Horizon 2020 research and
   innovation programme under the Marie Sklodowska-Curie grant {[}690972]}},
Funding-Text = {{Several authors were supported by the National Research Foundation
   (NRF), Singapore, under its National Cybersecurity R\&D Programme (Award
   No. NRF2014NCR-NCR001-40). Politecnico di Milano received funding for
   this project from the European Union's Horizon 2020 research and
   innovation programme under the Marie Sklodowska-Curie grant agreement
   nr. 690972.}},
Number-of-Cited-References = {{61}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BS0SY}},
Unique-ID = {{WOS:000684258200036}},
OA = {{Green Submitted, Green Published}},
DA = {{2021-11-23}},
}

@article{ WOS:000607679500001,
Author = {Liu, Ximeng and Xie, Lehui and Wang, Yaopeng and Zou, Jian and Xiong,
   Jinbo and Ying, Zuobin and Vasilakos, Athanasios V.},
Title = {{Privacy and Security Issues in Deep Learning: A Survey}},
Journal = {{IEEE ACCESS}},
Year = {{2021}},
Volume = {{9}},
Pages = {{4566-4593}},
Abstract = {{Deep Learning (DL) algorithms based on artificial neural networks have
   achieved remarkable success and are being extensively applied in a
   variety of application domains, ranging from image classification,
   automatic driving, natural language processing to medical diagnosis,
   credit risk assessment, intrusion detection. However, the privacy and
   security issues of DL have been revealed that the DL model can be stolen
   or reverse engineered, sensitive training data can be inferred, even a
   recognizable face image of the victim can be recovered. Besides, the
   recent works have found that the DL model is vulnerable to adversarial
   examples perturbed by imperceptible noised, which can lead the DL model
   to predict wrongly with high confidence. In this paper, we first briefly
   introduces the four types of attacks and privacy-preserving techniques
   in DL. We then review and summarize the attack and defense methods
   associated with DL privacy and security in recent years. To demonstrate
   that security threats really exist in the real world, we also reviewed
   the adversarial attacks under the physical condition. Finally, we
   discuss current challenges and open problems regarding privacy and
   security issues in DL.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Zou, J (Corresponding Author), Fuzhou Univ, Coll Math \& Comp Sci, Fuzhou 350108, Peoples R China.
   Zou, J (Corresponding Author), Fuzhou Univ, Fujian Prov Key Lab Informat Secur Network Syst, Fuzhou 350108, Peoples R China.
   Liu, Ximeng; Xie, Lehui; Wang, Yaopeng; Zou, Jian; Vasilakos, Athanasios V., Fuzhou Univ, Coll Math \& Comp Sci, Fuzhou 350108, Peoples R China.
   Liu, Ximeng; Xie, Lehui; Wang, Yaopeng; Zou, Jian, Fuzhou Univ, Fujian Prov Key Lab Informat Secur Network Syst, Fuzhou 350108, Peoples R China.
   Xiong, Jinbo, Fujian Normal Univ, Coll Math \& Informat, Fujian Prov Key Lab Network Secur \& Cryptol, Fuzhou 350117, Peoples R China.
   Ying, Zuobin, Nanyang Technol Univ, Sch Elect \& Elect Engn, Singapore 639798, Singapore.
   Vasilakos, Athanasios V., Univ Technol Sydney, Sch Elect \& Data Engn, Sydney, NSW 2007, Australia.
   Vasilakos, Athanasios V., Lulea Univ Technol, Dept Comp Sci Elect \& Space Engn, S-97187 Lulea, Sweden.}},
DOI = {{10.1109/ACCESS.2020.3045078}},
ISSN = {{2169-3536}},
Keywords = {{Deep learning; DL privacy; DL security; model extraction attack; model
   inversion attack; adversarial attack; poisoning attack; adversarial
   defense; privacy-preserving}},
Keywords-Plus = {{DIFFERENTIAL EVOLUTION; NEURAL-NETWORKS; EFFICIENT; ATTACKS}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{zoujian@fzu.edu.cn}},
ResearcherID-Numbers = {{Xiong, Jinbo/C-6911-2015
   }},
ORCID-Numbers = {{Ying, Zuobin/0000-0002-1658-4931
   Xie, Lehui/0000-0003-3194-1447
   Xiong, Jinbo/0000-0001-9985-1953
   Vasilakos, Athanasios/0000-0003-1902-9877
   Liu, Ximeng/0000-0002-4238-3295}},
Funding-Acknowledgement = {{National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}U1804263, 61702105]}},
Funding-Text = {{This work was supported by the National Natural Science Foundation of
   China under Grant U1804263 and Grant 61702105.}},
Number-of-Cited-References = {{217}},
Times-Cited = {{9}},
Usage-Count-Last-180-days = {{6}},
Usage-Count-Since-2013 = {{9}},
Journal-ISO = {{IEEE Access}},
Doc-Delivery-Number = {{PS1GU}},
Unique-ID = {{WOS:000607679500001}},
OA = {{gold}},
DA = {{2021-11-23}},
}

@article{ WOS:000695027300013,
Author = {Sethi, Kamalakanta and Madhav, Y. Venu and Kumar, Rahul and Bera,
   Padmalochan},
Title = {{Attention based multi-agent intrusion detection systems using
   reinforcement learning}},
Journal = {{JOURNAL OF INFORMATION SECURITY AND APPLICATIONS}},
Year = {{2021}},
Volume = {{61}},
Month = {{SEP}},
Abstract = {{Designing an effective network intrusion system (IDS) is a challenging
   problem because of the emergence of a large number of novel attacks and
   heterogeneous network applications. The existing IDSs fail to adapt to
   the changing attack patterns and unseen attacks that lead to inaccurate
   detection of network vulnerabilities and system performance degradation.
   Therefore, there is a need to design robust, scalable, efficient, and
   adaptive IDS for networks. This paper presents a novel deep
   reinforcement learning-based IDS that employs Deep Q-Network logic in
   multiple distributed agents and uses attention mechanisms to efficiently
   detect and classify advanced network attacks. Our proposed multi-agent
   IDS is designed as a distributed attack detection platform where agents
   work in a coordinated manner to provide scalable, fault-tolerant,
   multi-view architecture guided security system. We have tested our model
   with extensive experimentation on two benchmark datasets: NSL-KDD and
   CICIDS2017. It shows improved performance in terms of higher accuracy,
   precision, recall, F1-Score, and low false-positive rate (FPR) in
   comparison to the state-of-the-art IDS works. On the other hand, many
   machine learning systems are found vulnerable to adversarial attacks.
   Thus, we evaluated our model's robustness against a practical black-box
   adversarial attack and observed only a little degradation in
   performance. We integrated the concept of denoising autoencoder (DAE)
   with our model to further improve its robustness. Finally, we discuss
   the usability of our system in real-life applications against zero-day
   attack patterns.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Sethi, K (Corresponding Author), Indian Inst Technol Bhubaneswar, Bhubaneswar, India.
   Sethi, Kamalakanta; Madhav, Y. Venu; Kumar, Rahul; Bera, Padmalochan, Indian Inst Technol Bhubaneswar, Bhubaneswar, India.}},
DOI = {{10.1016/j.jisa.2021.102923}},
Article-Number = {{102923}},
ISSN = {{2214-2126}},
EISSN = {{2214-2134}},
Keywords = {{Intrusion detection systems (IDS); Attention mechanism; Deep Q-Networks;
   Adversarial attack; Context; Denoising autoencoder decoder (DAE);
   Precision; Recall; F1-score; FPR; NSL-KDD; CICIDS2017}},
Keywords-Plus = {{RANDOM FOREST; CLASSIFIERS; FRAMEWORK; MACHINE; MODEL}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems}},
Author-Email = {{ks23@iitbbs.ac.in
   yvm10@iitbbs.ac.in
   rk36@iitbbs.ac.in
   plb@iitbbs.ac.in}},
Number-of-Cited-References = {{70}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{J. Inf. Secur. Appl.}},
Doc-Delivery-Number = {{UO9RY}},
Unique-ID = {{WOS:000695027300013}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000635425100004,
Author = {Yilmaz, Ibrahim and Masum, Rahat and Siraj, Ambareen},
Book-Group-Author = {{IEEE Comp Soc}},
Title = {{Addressing Imbalanced Data Problem with Generative Adversarial Network
   For Intrusion Detection}},
Booktitle = {{2020 IEEE 21ST INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND
   INTEGRATION FOR DATA SCIENCE (IRI 2020)}},
Year = {{2020}},
Pages = {{25-30}},
Note = {{21st IEEE International Conference on Information Reuse and Integration
   for Data Science (IEEE IRI), ELECTR NETWORK, AUG 11-13, 2020}},
Organization = {{IEEE; IEEE Comp Soc; Soc Informat Reuse \& Integrat}},
Abstract = {{Machine learning techniques help to understand underlying patterns in
   datasets to develop defense mechanisms against cyber attacks. Multilayer
   Perceptron (MLP) technique is a machine learning technique used in
   detecting attack vs. benign data. However, it is difficult to construct
   any effective model when there are imbalances in the dataset that
   prevent proper classification of attack samples in data. In this
   research, we use UGR'16 dataset to conduct data wrangling initially.
   This technique helps to prepare a test set from the original dataset to
   train the neural network model effectively. We experimented with a
   series of inputs of varying sizes (i.e. 10000, 50000, 1 million) to
   observe the performance of the MLP neural network model with
   distribution of features over accuracy. Later, we use Generative
   Adversarial Network (GAN) model that produces samples of different
   attack labels (e.g. blacklist, anomaly spam, ssh scan) for balancing the
   dataset. These samples are generated based on data from the UGR'16
   dataset. Further experiments with MLP neural network model shows that a
   balanced attack sample dataset, made possible with GAN, produces more
   accurate results than an imbalanced one.}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Yilmaz, I (Corresponding Author), Tennessee Technol Univ, Dept Comp Sci, Cookeville, TN 38505 USA.
   Yilmaz, Ibrahim; Masum, Rahat; Siraj, Ambareen, Tennessee Technol Univ, Dept Comp Sci, Cookeville, TN 38505 USA.}},
DOI = {{10.1109/IRI49571.2020.00012}},
ISBN = {{978-1-7281-1054-7}},
Keywords = {{Neural Network (NN); Imbalanced Dataset; Generative Adversarial Network
   (GAN); Adversarial Samples; Network security}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Interdisciplinary Applications; Computer
   Science, Software Engineering; Engineering, Electrical \& Electronic}},
Author-Email = {{iyilmaz42@students.tntech.edu
   rmasum42@students.tntech.edu
   asiraj@tntech.edu}},
Number-of-Cited-References = {{26}},
Times-Cited = {{5}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BR1TM}},
Unique-ID = {{WOS:000635425100004}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000455146801023,
Author = {Wang, Chu and Zhang, Yan-Ming and Liu, Cheng-Lin},
Book-Group-Author = {{IEEE}},
Title = {{Anomaly Detection via Minimum Likelihood Generative Adversarial Networks}},
Booktitle = {{2018 24TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION (ICPR)}},
Series = {{International Conference on Pattern Recognition}},
Year = {{2018}},
Pages = {{1121-1126}},
Note = {{24th International Conference on Pattern Recognition (ICPR), Chinese
   Acad Sci, Inst Automat, Beijing, PEOPLES R CHINA, AUG 20-24, 2018}},
Organization = {{Int Assoc Pattern Recognit; Chinese Assoc Automat}},
Abstract = {{Anomaly detection aims to detect abnormal events by a model of
   normality. It plays an important role in many domains such as network
   intrusion detection, criminal activity identity and so on. With the
   rapidly growing size of accessible training data and high computation
   capacities, deep learning based anomaly detection has become more and
   more popular. In this paper, a new domain-based anomaly detection method
   based on generative adversarial networks (GAN) is proposed. Minimum
   likelihood regularization is proposed to make the generator produce more
   anomalies and prevent it from converging to normal data distribution.
   Proper ensemble of anomaly scores is shown to improve the stability of
   discriminator effectively. The proposed method has achieved significant
   improvement than other anomaly detection methods on Cifar10 and UCI
   datasets.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Wang, C (Corresponding Author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.
   Wang, Chu; Zhang, Yan-Ming; Liu, Cheng-Lin, Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.
   Liu, Cheng-Lin, CAS Ctr Excellence Brain Sci \& Intelligence Techn, Beijing, Peoples R China.
   Liu, Cheng-Lin, Univ Chinese Acad Sci, Beijing, Peoples R China.}},
ISSN = {{1051-4651}},
ISBN = {{978-1-5386-3788-3}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{chu.wang@ia.ac.cn
   ymzhang@nlpr.ia.ac.cn
   liucl@nlpr.ia.ac.cn}},
Funding-Acknowledgement = {{National Natural Science Foundation of China (NSFC)National Natural
   Science Foundation of China (NSFC) {[}61721004, 61773376]}},
Funding-Text = {{This work has been supported by the National Natural Science Foundation
   of China (NSFC) grants 61721004 and 61773376.}},
Number-of-Cited-References = {{30}},
Times-Cited = {{6}},
Usage-Count-Last-180-days = {{4}},
Usage-Count-Since-2013 = {{7}},
Doc-Delivery-Number = {{BL7LC}},
Unique-ID = {{WOS:000455146801023}},
OA = {{Green Submitted}},
DA = {{2021-11-23}},
}

@article{ WOS:000467523400002,
Author = {Moustafa, Nour and Choo, Kim-Kwang Raymond and Radwan, Ibrahim and
   Camtepe, Seyit},
Title = {{Outlier Dirichlet Mixture Mechanism: Adversarial Statistical Learning
   for Anomaly Detection in the Fog}},
Journal = {{IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY}},
Year = {{2019}},
Volume = {{14}},
Number = {{8}},
Pages = {{1975-1987}},
Month = {{AUG}},
Abstract = {{Current anomaly detection systems (ADSs) apply statistical and machine
   learning algorithms to discover zero-day attacks, but such algorithms
   are vulnerable to advanced persistent threat actors. In this paper, we
   propose an adversarial statistical learning mechanism for anomaly
   detection, outlier Dirichlet mixture-based ADS (ODM-ADS), which has
   three new capabilities. First, it can self-adapt against data poisoning
   attacks that inject malicious instances in the training phase for
   disrupting the learning process. Second, it establishes a statistical
   legitimate profile and considers variations from the baseline of the
   profile as anomalies using a proposed outlier function. Third, to deal
   with dynamic and large-scale networks such as Internet of Things and
   cloud and fog computing, we suggest a framework for deploying the
   mechanism as Software as a Service in the fog nodes. The fog enables the
   proposed mechanism to concurrently process streaming data at the edge of
   the network. The ODM-ADS mechanism is evaluated using both NSL-KDD and
   UNSW-NB15 datasets, whose findings indicate that ODM-ADS outperforms
   seven other peer algorithms in terms of accuracy, detection rates, false
   positive rates, and computational time.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Choo, KKR (Corresponding Author), Univ Texas San Antonio, Dept Informat Syst \& Cyber Secur, San Antonio, TX 78249 USA.
   Moustafa, Nour, Univ New South Wales, Sch Engn \& Informat Technol, ADFA, Canberra, ACT 2612, Australia.
   Choo, Kim-Kwang Raymond, Univ Texas San Antonio, Dept Informat Syst \& Cyber Secur, San Antonio, TX 78249 USA.
   Choo, Kim-Kwang Raymond, Univ Texas San Antonio, Dept Elect \& Comp Engn, San Antonio, TX 78249 USA.
   Choo, Kim-Kwang Raymond, Univ South Australia, Sch Informat Technol \& Math Sci, Adelaide, SA 5095, Australia.
   Radwan, Ibrahim, Australian Natl Univ, Coll Engn \& Comp Sci, Canberra, ACT 0200, Australia.
   Radwan, Ibrahim, Australian Natl Univ, Coll Business \& Econ, Canberra, ACT 0200, Australia.
   Camtepe, Seyit, CSIRO, Data61, Marsfield, NSW 2122, Australia.}},
DOI = {{10.1109/TIFS.2018.2890808}},
ISSN = {{1556-6013}},
EISSN = {{1556-6021}},
Keywords = {{Adversarial statistical/machine learning; outlier detection; Dirichlet
   mixture model; anomaly detection; fog computing}},
Keywords-Plus = {{INTRUSION DETECTION SYSTEM; CLOUD; SECURITY; PREVENTION; ATTACKS; MODELS}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods; Engineering, Electrical \&
   Electronic}},
Author-Email = {{nour.moustafa@unsw.edu.au
   raymond.choo@fulbrightmail.org
   ibrahim.radwan@anu.edu.au
   seyit.camtepe@data61.csiro.au}},
ResearcherID-Numbers = {{Moustafa, Nour/Z-1160-2018
   Choo, Kim-Kwang Raymond/A-3634-2009
   Camtepe, Seyit A./E-6113-2013
   }},
ORCID-Numbers = {{Moustafa, Nour/0000-0001-6127-9349
   Choo, Kim-Kwang Raymond/0000-0001-9208-5336
   Camtepe, Seyit A./0000-0001-6353-8359
   Radwan, Ibrahim/0000-0002-8170-5058}},
Funding-Acknowledgement = {{Cloud Technology Endowed Professorship}},
Funding-Text = {{The work of K.-K. R. Choo was supported by the Cloud Technology Endowed
   Professorship. The associate editor coordinating the review of this
   manuscript and approving it for publication was Prof. Xiaodong Lin.}},
Number-of-Cited-References = {{66}},
Times-Cited = {{38}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{46}},
Journal-ISO = {{IEEE Trans. Inf. Forensic Secur.}},
Doc-Delivery-Number = {{HX6OQ}},
Unique-ID = {{WOS:000467523400002}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000557325500005,
Author = {Valizadeh, Saeed and van Dijk, Marten},
Book-Group-Author = {{Assoc Comp Machinery}},
Title = {{MalPro: A Learning-based Malware Propagation and Containment Modeling}},
Booktitle = {{CCSW'19: PROCEEDINGS OF THE 2019 ACM SIGSAC CONFERENCE ON CLOUD
   COMPUTING SECURITY WORKSHOP}},
Year = {{2019}},
Pages = {{45-56}},
Note = {{10th ACM SIGSAC Conference on Cloud Computing Security Workshop (CCSW),
   London, ENGLAND, NOV 11, 2019}},
Organization = {{ACM SIGSAC; Assoc Comp Machinery}},
Abstract = {{In this paper, we investigate the importance of a defense system's
   learning rates to fight against the self-propagating class of malware
   such as worms and bots. To this end, we introduce a new propagation
   model based on the interactions between an adversary (and its agents)
   who wishes to construct a zombie army of a specific size, and a defender
   taking advantage of standard security tools and technologies such as
   honeypots (HPs) and intrusion detection and prevention systems (IDPSes)
   in the network environment. As time goes on, the defender can
   incrementally learn from the collected/observed attack samples (e.g.,
   malware payloads), and therefore being able to generate attack
   signatures. The generated signatures then are used for filtering next
   attack traffic and thus containing the attacker's progress in its
   malware propagation mission. Using simulation and numerical analysis, we
   evaluate the efficacy of signature generation algorithms and in general
   any learning-based scheme in bringing an adversary's maneuvering in the
   environment to a halt as an adversarial containment strategy.}},
Publisher = {{ASSOC COMPUTING MACHINERY}},
Address = {{1515 BROADWAY, NEW YORK, NY 10036-9998 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Valizadeh, S (Corresponding Author), Univ Connecticut, Dept Comp Sci \& Engn, Storrs, CT 06269 USA.
   Valizadeh, Saeed, Univ Connecticut, Dept Comp Sci \& Engn, Storrs, CT 06269 USA.
   van Dijk, Marten, Univ Connecticut, Dept Elect \& Comp Engn, Storrs, CT 06269 USA.}},
DOI = {{10.1145/3338466.3358920}},
ISBN = {{978-1-4503-6826-1}},
Keywords = {{Botnet; Malware; Propagation Modeling; Self-replicating Code; Worm;
   Intrusion Detection and Prevention System; Honeypot; Cloud Security;
   Learning-based Model; Security Games}},
Keywords-Plus = {{SIGNATURES}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods}},
Author-Email = {{saeed.val@uconn.edu
   marten.van\_dijk@uconn.edu}},
ResearcherID-Numbers = {{van Dijk, Marten/ABC-2807-2020
   }},
ORCID-Numbers = {{van Dijk, Marten/0000-0001-9388-8050}},
Funding-Acknowledgement = {{NSFNational Science Foundation (NSF) {[}CNS-1413996]}},
Funding-Text = {{This work was funded by NSF grant CNS-1413996 ``MACS: A Modular Approach
   to Cloud Security.{''}}},
Number-of-Cited-References = {{37}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BP5PA}},
Unique-ID = {{WOS:000557325500005}},
DA = {{2021-11-23}},
}

@article{ WOS:000579969400001,
Author = {Radoglou Grammatikis, Panagiotis and Sarigiannidis, Panagiotis and
   Efstathopoulos, Georgios and Panaousis, Emmanouil},
Title = {{ARIES: A Novel Multivariate Intrusion Detection System for Smart Grid}},
Journal = {{SENSORS}},
Year = {{2020}},
Volume = {{20}},
Number = {{18}},
Month = {{SEP}},
Abstract = {{The advent of the Smart Grid (SG) raises severe cybersecurity risks that
   can lead to devastating consequences. In this paper, we present a novel
   anomaly-based Intrusion Detection System (IDS), called ARIES (smArt gRid
   Intrusion dEtection System), which is capable of protecting efficiently
   SG communications. ARIES combines three detection layers that are
   devoted to recognising possible cyberattacks and anomalies against (a)
   network flows, (b) Modbus/Transmission Control Protocol (TCP) packets
   and (c) operational data. Each detection layer relies on a Machine
   Learning (ML) model trained using data originating from a power plant.
   In particular, the first layer (network flow-based detection) performs a
   supervised multiclass classification, recognising Denial of Service
   (DoS), brute force attacks, port scanning attacks and bots. The second
   layer (packet-based detection) detects possible anomalies related to the
   Modbus packets, while the third layer (operational data based detection)
   monitors and identifies anomalies upon operational data (i.e., time
   series electricity measurements). By emphasising on the third layer, the
   ARIES Generative Adversarial Network (ARIES GAN) with novel error
   minimisation functions was developed, considering mainly the
   reconstruction difference. Moreover, a novel reformed conditional input
   was suggested, consisting of random noise and the signal features at any
   given time instance. Based on the evaluation analysis, the proposed GAN
   network overcomes the efficacy of conventional ML methods in terms of
   Accuracy and the F1 score.}},
Publisher = {{MDPI}},
Address = {{ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Sarigiannidis, P (Corresponding Author), Univ Western Macedonia, Dept Elect \& Comp Engn, Kozani 50100, Greece.
   Radoglou Grammatikis, Panagiotis; Sarigiannidis, Panagiotis, Univ Western Macedonia, Dept Elect \& Comp Engn, Kozani 50100, Greece.
   Efstathopoulos, Georgios, Imperial Off, 0INF, London E6 2JG, England.
   Panaousis, Emmanouil, Univ Greenwich, Old Royal Naval Coll, Dept Comp \& Informat Syst, London SE10 9LS, England.}},
DOI = {{10.3390/s20185305}},
Article-Number = {{5305}},
EISSN = {{1424-8220}},
Keywords = {{cybersecurity; Intrusion Detection System; Machine Learning; Modbus;
   SCADA; Smart Grid}},
Keywords-Plus = {{DISCRIMINANT-ANALYSIS; NETWORKS; SECURITY; THREATS}},
Research-Areas = {{Chemistry; Engineering; Instruments \& Instrumentation}},
Web-of-Science-Categories  = {{Chemistry, Analytical; Engineering, Electrical \& Electronic;
   Instruments \& Instrumentation}},
Author-Email = {{pradoglou@uowm.gr
   psarigiannidis@uowm.gr
   george@0infinity.net
   e.panaousis@gre.ac.uk}},
ResearcherID-Numbers = {{Panaousis, Emmanouil/X-4402-2019
   Panaousis, Emmanouil/A-1444-2016
   Radoglou-Grammatikis, Panagiotis/AAF-4162-2021
   Panaousis, Manos/AAX-4684-2021
   Sarigiannidis, Panagiotis/O-5246-2017}},
ORCID-Numbers = {{Panaousis, Emmanouil/0000-0001-7306-4062
   Radoglou-Grammatikis, Panagiotis/0000-0003-1605-9413
   Sarigiannidis, Panagiotis/0000-0001-6042-0355}},
Funding-Acknowledgement = {{European UnionEuropean Commission {[}787011]}},
Funding-Text = {{This project has received funding from the European Union's Horizon 2020
   research and innovation programme under grant agreement No. 787011
   (SPEAR).}},
Number-of-Cited-References = {{67}},
Times-Cited = {{5}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{8}},
Journal-ISO = {{Sensors}},
Doc-Delivery-Number = {{OD6NY}},
Unique-ID = {{WOS:000579969400001}},
OA = {{Green Published, Green Accepted, gold, Green Submitted}},
DA = {{2021-11-23}},
}

@article{ WOS:000467297800003,
Author = {Berman, Daniel S. and Buczak, Anna L. and Chavis, Jeffrey S. and
   Corbett, Cherita L.},
Title = {{A Survey of Deep Learning Methods for Cyber Security}},
Journal = {{INFORMATION}},
Year = {{2019}},
Volume = {{10}},
Number = {{4}},
Month = {{APR}},
Abstract = {{This survey paper describes a literature review of deep learning (DL)
   methods for cyber security applications. A short tutorial-style
   description of each DL method is provided, including deep autoencoders,
   restricted Boltzmann machines, recurrent neural networks, generative
   adversarial networks, and several others. Then we discuss how each of
   the DL methods is used for security applications. We cover a broad array
   of attack types including malware, spam, insider threats, network
   intrusions, false data injection, and malicious domain names used by
   botnets.}},
Publisher = {{MDPI}},
Address = {{ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND}},
Type = {{Review}},
Language = {{English}},
Affiliation = {{Buczak, AL (Corresponding Author), JHU, Appl Phys Lab, APL1, Laurel, MD 20910 USA.
   Berman, Daniel S.; Buczak, Anna L.; Chavis, Jeffrey S.; Corbett, Cherita L., JHU, Appl Phys Lab, APL1, Laurel, MD 20910 USA.}},
DOI = {{10.3390/info10040122}},
Article-Number = {{122}},
EISSN = {{2078-2489}},
Keywords = {{cyber analytics; deep learning; deep neural networks; deep autoencoders;
   deep belief networks; restricted Boltzmann machines; convolutional
   neural networks}},
Keywords-Plus = {{NETWORK INTRUSION DETECTION; ATTACK DETECTION; BELIEF NETWORKS;
   NEURAL-NETWORKS; REPRESENTATIONS; CLASSIFICATION; INTERNET}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems}},
Author-Email = {{daniel.berman@jhuapl.edu
   anna.buczak@jhuapl.edu
   jeffrey.chavis@jhuapl.edu
   cherita.corbett@jhuapl.edu}},
ResearcherID-Numbers = {{Alghamdi, Mohammed Ibrahim/I-3651-2018}},
Number-of-Cited-References = {{156}},
Times-Cited = {{87}},
Usage-Count-Last-180-days = {{20}},
Usage-Count-Since-2013 = {{48}},
Journal-ISO = {{Information}},
Doc-Delivery-Number = {{HX3ND}},
Unique-ID = {{WOS:000467297800003}},
OA = {{Green Submitted, gold}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000465774301023,
Author = {Alshamrani, Adel and Chowdhary, Ankur and Mjihil, Oussama and Myneni,
   Sowmya and Huang, Dijiang},
Book-Group-Author = {{IEEE}},
Title = {{Combining Dynamic and Static Attack Information for Attack Tracing and
   Event Correlation}},
Booktitle = {{2018 IEEE GLOBAL COMMUNICATIONS CONFERENCE (GLOBECOM)}},
Series = {{IEEE Global Communications Conference}},
Year = {{2018}},
Note = {{IEEE Global Conference on Communications (GLOBECOM) / Workshop on
   Wireless Networking and Control for UAV, Abu Dhabi, U ARAB EMIRATES, DEC
   09-13, 2018}},
Organization = {{IEEE}},
Abstract = {{Many sophisticated attacks, e.g. Advanced Persistent Threats (APTs),
   have emerged with a variety of different attack forms. APT employs a
   wide range of sophisticated reconnaissance and information-gathering
   tools, as well as attack tools and methods. The diversity and
   stealthiness of APT make it a challenging threat to current networking
   systems. The attackers are very skilled and try to hide in a system
   undetected for a long period of time with the incentive to steal and
   collect invaluable Current commonly used solutions (firewalls, Intrusion
   Detection Systems, proxies, etc.) show the limited efficiency of
   detecting APT. Thus, in this paper, we design a solution that is based
   on multi-source data combination to learn the adversarial behavior of
   suspicious users as well as to optimally select a proper countermeasure.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Alshamrani, A (Corresponding Author), Arizona State Univ, Tempe, AZ 85281 USA.
   Alshamrani, Adel; Chowdhary, Ankur; Mjihil, Oussama; Myneni, Sowmya; Huang, Dijiang, Arizona State Univ, Tempe, AZ 85281 USA.
   Mjihil, Oussama, Hassan 1st Univ, FST, Settat, Morocco.}},
ISSN = {{2334-0983}},
ISBN = {{978-1-5386-4727-1}},
Keywords = {{Advanced Persistent Threats; Intrusion Detection Systems; Attack Graph}},
Research-Areas = {{Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic; Telecommunications}},
Author-Email = {{aalsham4@asu.edu
   achaud16@asu.edu
   oussama.mjihil@asu.edu
   smyneni2@asu.edu
   dijiang@asu.edu}},
ResearcherID-Numbers = {{Chowdhary, Ankur/AAJ-6546-2020}},
ORCID-Numbers = {{Chowdhary, Ankur/0000-0001-7131-067X}},
Funding-Acknowledgement = {{NRL {[}N00173-15-G017]; NSFCNational Natural Science Foundation of China
   (NSFC) {[}61628201, 61571375]; NSFNational Science Foundation (NSF)
   {[}1642031, 1528099, 1723440]}},
Funding-Text = {{This research is based upon work supported by the NRL N00173-15-G017,
   NSF Grants 1642031, 1528099, and 1723440, and NSFC Grants 61628201 and
   61571375.}},
Number-of-Cited-References = {{18}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BM5YU}},
Unique-ID = {{WOS:000465774301023}},
DA = {{2021-11-23}},
}

@article{ WOS:000454364800001,
Author = {Shafi, Qaisar and Basit, Abdul and Qaisar, Saad and Koay, Abigail and
   Welch, Ian},
Title = {{Fog-Assisted SDN Controlled Framework for Enduring Anomaly Detection in
   an IoT Network}},
Journal = {{IEEE ACCESS}},
Year = {{2018}},
Volume = {{6}},
Pages = {{73713-73723}},
Abstract = {{Extensive adoption of intelligent devices with ubiquitous connectivity
   has increased Internet of Things (IoT) traffic tremendously. The smart
   devices promise to improve human life through improved safety and
   security through the implementation of intelligent transportation
   systems, optimization of power grids, and applications in human health.
   Devices produce a large amount of data for analytic applications running
   inside a cloud infrastructure. Unlike core networks, the main objective
   of an attack on an IoT network is to disrupt the availability of IoT
   data for the applications by overwhelming devices with information
   requests. Detection of such an attack cannot be done either in the cloud
   where the analytical application runs nor on the IoT device itself due
   to its limited computational resources. Furthermore, the standard
   networking paradigm does not provide an easy way to instrument and
   control networking nodes, for an effective mitigation of identified
   threats. In this paper, we propose a fog-assisted software defined
   networking (SDN) driven intrusion detection/prevention system (IDPS) for
   IoT networks. A collocated fog computational arrangement with IoT
   network equips proposed IDPS for timely identification of various attack
   models in near real time for effective neutralization of threats using
   SDN control. We have found our approach more effective from traditional
   techniques of intrusion detection in the IoT network.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Shafi, Q (Corresponding Author), Natl Univ Sci \& Technol, Sch Elect Engn \& Comp Sci, Islamabad 460002, Pakistan.
   Shafi, Qaisar; Basit, Abdul; Qaisar, Saad, Natl Univ Sci \& Technol, Sch Elect Engn \& Comp Sci, Islamabad 460002, Pakistan.
   Koay, Abigail; Welch, Ian, Victoria Univ Wellington, Sch Engn \& Comp Sci, Wellington 6140, New Zealand.}},
DOI = {{10.1109/ACCESS.2018.2884293}},
ISSN = {{2169-3536}},
Keywords = {{IoT; fog; SDN; machine learning; network security; intrusion detection;
   anomaly}},
Keywords-Plus = {{SOFTWARE-DEFINED NETWORKING; INTRUSION DETECTION; INTERNET; ATTACKS;
   THINGS; MECHANISM; FUTURE; SYSTEM; DOS}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{qaisar.shafi@seecs.edu.pk}},
ResearcherID-Numbers = {{Koay, Abigail/AAO-9282-2020}},
ORCID-Numbers = {{Koay, Abigail/0000-0002-4130-9931}},
Funding-Acknowledgement = {{Higher Education Commission Pakistan Program for Collaborative Research
   (PPCR)}},
Funding-Text = {{This work was supported by the Higher Education Commission Pakistan
   Program for Collaborative Research (PPCR) 2018.}},
Number-of-Cited-References = {{48}},
Times-Cited = {{22}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{IEEE Access}},
Doc-Delivery-Number = {{HF6RA}},
Unique-ID = {{WOS:000454364800001}},
OA = {{gold}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000621584100022,
Author = {Hartl, Alexander and Bachl, Maximilian and Fabini, Joachim and Zseby,
   Tanja},
Book-Group-Author = {{IEEE}},
Title = {{Explainability and Adversarial Robustness for RNNs}},
Booktitle = {{2020 IEEE SIXTH INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING SERVICE
   AND APPLICATIONS (BIGDATASERVICE 2020)}},
Year = {{2020}},
Pages = {{149-157}},
Note = {{6th IEEE International Conference on Big Data Computing Service and
   Applications (IEEE BigDataService), Oxford, ENGLAND, AUG 03-06, 2020}},
Organization = {{IEEE; IEEE Comp Soc}},
Abstract = {{Recurrent Neural Networks (RNNs) yield attractive properties for
   constructing Intrusion Detection Systems (IDSs) for network data. With
   the rise of ubiquitous Machine Learning (ML) systems, malicious actors
   have been catching up quickly to find new ways to exploit ML
   vulnerabilities for profit. Recently developed adversarial ML techniques
   focus on computer vision and their applicability to network traffic is
   not straightforward: Network packets expose fewer features than an
   image, are sequential and impose several constraints on their features.
   We show that despite these completely different characteristics,
   adversarial samples can be generated reliably for RNNs. To understand a
   classifier's potential for misclassification, we extend existing
   explainability techniques and propose new ones, suitable particularly
   for sequential data. Applying them shows that already the first packets
   of a communication flow are of crucial importance and are likely to be
   targeted by attackers. Feature importance methods show that even
   relatively unimportant features can be effectively abused to generate
   adversarial samples. We thus introduce the concept of feature
   sensitivity which quantifies how much potential a feature has to cause
   misclassification.
   Since traditional evaluation metrics such as accuracy are not sufficient
   for quantifying the adversarial threat, we propose the Adversarial
   Robustness Score (ARS) for comparing IDSs and show that an adversarial
   training procedure can significantly and successfully reduce the attack
   surface.}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Hartl, A (Corresponding Author), Tech Univ Wien, Vienna, Austria.
   Hartl, Alexander; Bachl, Maximilian; Fabini, Joachim; Zseby, Tanja, Tech Univ Wien, Vienna, Austria.}},
DOI = {{10.1109/BigDataService49289.2020.00030}},
ISBN = {{978-1-7281-7022-0}},
Keywords-Plus = {{NEURAL-NETWORKS}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory \& Methods}},
Author-Email = {{alexander.hartl@tuwien.ac.at
   maximilian.bachl@tuwien.ac.at
   joachim.fabini@tuwien.ac.at
   tanja.zseby@tuwien.ac.at}},
Number-of-Cited-References = {{24}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BQ8TA}},
Unique-ID = {{WOS:000621584100022}},
OA = {{Green Submitted}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000652194300064,
Author = {Dutta, Indira Kalyan and Ghosh, Bhaskar and Carlson, Albert and Totaro,
   Michael and Bayoumi, Magdy},
Editor = {{Paul, R}},
Title = {{Generative Adversarial Networks in Security: A Survey}},
Booktitle = {{2020 11TH IEEE ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS \& MOBILE
   COMMUNICATION CONFERENCE (UEMCON)}},
Year = {{2020}},
Pages = {{399-405}},
Note = {{11th IEEE Annual Ubiquitous Computing, Electronics and Mobile
   Communication Conference (UEMCON), ELECTR NETWORK, OCT 28-31, 2020}},
Organization = {{IEEE; IEEE New York Sect; IEEE Reg 1; Inst Engn \& Management; SMART;
   IEEE USA; Univ Engn \& Management}},
Abstract = {{In the Information Age, the majority of data stored and transferred is
   digital; however, current security systems are not powerful enough to
   secure this data because they do not anticipate unknown attacks. With a
   growing number of attacks on cybersecurity systems defense mechanisms
   need to stay updated with the evolving threats. Security and their
   related attacks are an iterative pair of objects that learn to enhance
   themselves based upon each others' advances - a cybersecurity ``arms
   race.{''} In this survey, we focus on the various ways in which
   Generative Adversarial Networks (GANs) have been used to provide both
   security advances and attack scenarios in order to bypass detection
   systems. The aim of our survey is to examine works completed in the area
   of GANs, specifically device and network security. This paper also
   discusses new challenges for intrusion detection systems that have been
   generated using GANs. Considering the promising results that have been
   achieved in different GAN applications, it is very likely that GANs can
   shape security advances if applied to cybersecurity.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Dutta, IK (Corresponding Author), Univ Louisiana Lafayette, Lafayette, LA 70504 USA.
   Dutta, Indira Kalyan; Ghosh, Bhaskar; Totaro, Michael; Bayoumi, Magdy, Univ Louisiana Lafayette, Lafayette, LA 70504 USA.}},
Article-Number = {{1570680892}},
ISBN = {{978-1-7281-9656-5}},
Keywords = {{Security; Generative Adversarial Networks; Cybersecurity; Machine
   Learning; Artificial Intelligence}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{indira.dutta1@louisiana.edu
   bhaskar.ghosh1@louisiana.edu
   ltzap1@gmail.com
   michael.totaro@louisiana.edu
   magdy.bayoumi@louisiana.edu}},
Number-of-Cited-References = {{71}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{3}},
Doc-Delivery-Number = {{BR4QF}},
Unique-ID = {{WOS:000652194300064}},
DA = {{2021-11-23}},
}

@article{ WOS:000537437500008,
Author = {Karacay, Leyli and Savas, Erkay and Alptekin, Halit},
Title = {{Intrusion Detection Over Encrypted Network Data}},
Journal = {{COMPUTER JOURNAL}},
Year = {{2020}},
Volume = {{63}},
Number = {{4}},
Pages = {{604-619}},
Month = {{APR}},
Abstract = {{Effective protection against cyber-attacks requires constant monitoring
   and analysis of system data in an IT infrastructure, such as log files
   and network packets, which may contain private and sensitive
   information. Security operation centers (SOC), which are established to
   detect, analyze and respond to cyber-security incidents, often utilize
   detection models either for known types of attacks or for anomaly and
   applies them to the system data for detection. SOC are also motivated to
   keep their models private to capitalize on the models that are their
   propriety expertise, and to protect their detection strategies against
   adversarial machine learning. In this paper, we develop a protocol for
   privately evaluating detection models on the system data, in which
   privacy of both the system data and detection models is protected and
   information leakage is either prevented altogether or quantifiably
   decreased. Our main approach is to provide an end-to-end encryption for
   the system data and detection models utilizing lattice-based
   cryptography that allows homomorphic operations over ciphertext. We
   employ recent data sets in our experiments which demonstrate that the
   proposed privacy-preserving intrusion detection system is feasible in
   terms of execution times and bandwidth requirements and reliable in
   terms of accuracy.}},
Publisher = {{OXFORD UNIV PRESS}},
Address = {{GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Karacay, L (Corresponding Author), Sabanci Univ, Dept Nat Sci \& Engn, Istanbul, Turkey.
   Karacay, Leyli; Savas, Erkay; Alptekin, Halit, Sabanci Univ, Dept Nat Sci \& Engn, Istanbul, Turkey.}},
DOI = {{10.1093/comjnl/bxz111}},
ISSN = {{0010-4620}},
EISSN = {{1460-2067}},
Keywords = {{cyber security; intrusion detection systems; lattice-based homomorphic
   encryption; machine learning; binary decision tree; privacy-preserving
   data classification}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Hardware \& Architecture; Computer Science,
   Information Systems; Computer Science, Software Engineering; Computer
   Science, Theory \& Methods}},
Author-Email = {{leyli@sabanciuniv.edu}},
ResearcherID-Numbers = {{Savas, Erkay/AAY-8766-2020
   }},
ORCID-Numbers = {{Alptekin, Halit/0000-0002-4757-9182}},
Number-of-Cited-References = {{30}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{9}},
Journal-ISO = {{Comput. J.}},
Doc-Delivery-Number = {{LU0EV}},
Unique-ID = {{WOS:000537437500008}},
DA = {{2021-11-23}},
}

@article{ WOS:000626775000009,
Author = {Li, Yundong and Liu, Yi and Dong, Han and Hu, Wei and Lin, Chen},
Title = {{Intrusion detection of railway clearance from infrared images using
   generative adversarial networks}},
Journal = {{JOURNAL OF INTELLIGENT \& FUZZY SYSTEMS}},
Year = {{2021}},
Volume = {{40}},
Number = {{3}},
Pages = {{3931-3943}},
Abstract = {{The intrusion detection of railway clearance is crucial for avoiding
   railway accidents caused by the invasion of abnormal objects, such as
   pedestrians, falling rocks, and animals. However, detecting intrusions
   using deep learning methods from infrared images captured at night
   remains a challenging task because of the lack of sufficient training
   samples. To address this issue, a transfer strategy that migrates
   daytime RGB images to the nighttime style of infrared images is proposed
   in this study. The proposed method consists of two stages. In the first
   stage, a data generation model is trained on the basis of generative
   adversarial networks using RGB images and a small number of infrared
   images, and then, synthetic samples are generated using a well-trained
   model. In the second stage, a single shot multibox detector (SSD) model
   is trained using synthetic data and utilized to detect abnormal objects
   from infrared images at nighttime. To validate the effectiveness of the
   proposed method, two groups of experiments, namely, railway and
   non-railway scenes, are conducted. Experimental results demonstrate the
   effectiveness of the proposed method, and an improvement of 17.8\% is
   achieved for object detection at nighttime.}},
Publisher = {{IOS PRESS}},
Address = {{NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Li, YD (Corresponding Author), North China Univ Technol, Sch Informat Sci \& Technol, Beijing, Peoples R China.
   Li, YD (Corresponding Author), Key Lab Large Struct Hlth Monitoring \& Control, Shijiazhuang, Hebei, Peoples R China.
   Li, Yundong; Liu, Yi; Dong, Han; Hu, Wei; Lin, Chen, North China Univ Technol, Sch Informat Sci \& Technol, Beijing, Peoples R China.
   Li, Yundong, Key Lab Large Struct Hlth Monitoring \& Control, Shijiazhuang, Hebei, Peoples R China.}},
DOI = {{10.3233/JIFS-192141}},
ISSN = {{1064-1246}},
EISSN = {{1875-8967}},
Keywords = {{Railway clearance; infrared image detection; CycleGAN; SSD}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{liyundong@ncut.edu.cn}},
Funding-Acknowledgement = {{National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}62071006]; Beijing Natural Science
   FoundationBeijing Natural Science Foundation {[}4182020]; Key Laboratory
   for Health Monitoring and Control of Large Structures, Shijiazhuang
   {[}KLLSHMC1901]}},
Funding-Text = {{This research is supported by National Natural Science Foundation of
   China (62071006), Beijing Natural Science Foundation (4182020), and Key
   Laboratory for Health Monitoring and Control of Large Structures
   (KLLSHMC1901), Shijiazhuang, 050043.}},
Number-of-Cited-References = {{35}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{8}},
Journal-ISO = {{J. Intell. Fuzzy Syst.}},
Doc-Delivery-Number = {{QT7NB}},
Unique-ID = {{WOS:000626775000009}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000552726400021,
Author = {Kuppa, Aditya and Grzonkowski, Slawomir and Asghar, Muhammad Rizwan and
   Le-Khac, Nhien-An},
Book-Group-Author = {{Assoc Comp Machinery}},
Title = {{Black Box Attacks on Deep Anomaly Detectors}},
Booktitle = {{14TH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY
   (ARES 2019)}},
Year = {{2019}},
Note = {{14th International Conference on Availability, Reliability and Security
   (ARES), Canterbury, ENGLAND, AUG 26-29, 2019}},
Organization = {{SBA Res; Univ Kent}},
Abstract = {{The process of identifying the true anomalies from a given set of data
   instances is known as anomaly detection. It has been applied to address
   a diverse set of problems in multiple application domains including
   cybersecurity. Deep learning has recently demonstrated state-of-the-art
   performance on key anomaly detection applications, such as intrusion
   detection, Denial of Service (DoS) attack detection, security log
   analysis, and malware detection. Despite the great successes achieved by
   neural network architectures, models with very low test error have been
   shown to be consistently vulnerable to small, adversarially chosen
   perturbations of the input. The existence of evasion attacks during the
   test phase of machine learning algorithms represents a significant
   challenge to both their deployment and understanding.
   Recent approaches in the literature have focused on three different
   areas: (a) generating adversarial examples in supervised machine
   learning in multiple domains; (b) countering the attacks with various
   defenses; (c) theoretical guarantees on the robustness of machine
   learning models by understanding their security properties. However,
   they have not covered, from the perspective of the anomaly detection
   task in a black box setting. The exploration of black box attack
   strategies, which reduce the number of queries for finding adversarial
   examples with high probability, is an important problem.
   In this paper, we study the security of black box deep anomaly detectors
   with a realistic threat model. We propose a novel black box attack in
   query constraint settings. First, we run manifold approximation on
   samples collected at attacker end for query reduction and understanding
   various thresholds set by underlying anomaly detector, and use spherical
   adversarial subspaces to generate attack samples. This method is well
   suited for attacking anomaly detectors where decision boundaries of
   nominal and abnormal classes are not very well defined and decision
   process is done with a set of thresholds on anomaly scores. We validate
   our attack on state-of-the-art deep anomaly detectors and show that the
   attacker goal is achieved under constraint settings. Our evaluation of
   the proposed approach shows promising results and demonstrates that our
   strategy can be successfully used against other anomaly detectors.}},
Publisher = {{ASSOC COMPUTING MACHINERY}},
Address = {{1515 BROADWAY, NEW YORK, NY 10036-9998 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Kuppa, A (Corresponding Author), Univ Coll, Dublin, Ireland.
   Kuppa, A (Corresponding Author), Symantec Corp, Tempe, AZ 85281 USA.
   Kuppa, Aditya; Le-Khac, Nhien-An, Univ Coll, Dublin, Ireland.
   Kuppa, Aditya; Grzonkowski, Slawomir, Symantec Corp, Tempe, AZ 85281 USA.
   Asghar, Muhammad Rizwan, Univ Auckland, Auckland, New Zealand.}},
DOI = {{10.1145/3339252.3339266}},
ISBN = {{978-1-4503-7164-3}},
Keywords = {{Black box attacks; Anomaly detection; Neural networks}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Theory \&
   Methods; Engineering, Electrical \& Electronic}},
Author-Email = {{aditya.kuppa@ucdconnect.ie
   slawomir\_grzonkowski@symantec.com
   r.asghar@auckland.ac.nz
   an.lekhac@ucd.ie}},
Number-of-Cited-References = {{59}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BP4JN}},
Unique-ID = {{WOS:000552726400021}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000646231600032,
Author = {Alabugin, Sergei K. and Sokolov, Alexander N.},
Book-Group-Author = {{IEEE}},
Title = {{Applying of Generative Adversarial Networks for Anomaly Detection in
   Industrial Control Systems}},
Booktitle = {{2020 GLOBAL SMART INDUSTRY CONFERENCE (GLOSIC)}},
Year = {{2020}},
Pages = {{199-203}},
Note = {{Global Smart Industry Conference (GloSIC), Chelyabinsk, RUSSIA, NOV
   17-19, 2020}},
Organization = {{S Ural State Univ}},
Abstract = {{Modern industrial control systems (ICS) act as victims of cyber attacks
   more often in last years. These cyber attacks often can not be detected
   by classical information security methods. Moreover, the consequences of
   cyber attack's impact can be catastrophic. Since cyber attacks leads to
   appearance of anomalies in the ICS and technological equipment
   controlled by it, the task of intrusion detection for ICS can be
   reformulated as the task of industrial process anomaly detection. This
   paper considers the applicability of generative adversarial networks
   (GANs) in the field of industrial processes anomaly detection. Existing
   approaches for GANs usage in the field of information security (such as
   anomaly detection in network traffic) were described. It is proposed to
   use the BiGAN architecture in order to detect anomalies in the
   industrial processes. The proposed approach has been tested on Secure
   Water Treatment Dataset (SWaT). The obtained results indicate the
   prospects of using the examined method in practice.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Alabugin, SK (Corresponding Author), South Ural State Univ, Natl Res Univ, FSAEIHE SUSU NRU, Dept Informat Secur,Fed State Autonomous Educ Ins, Chelyabinsk, Russia.
   Alabugin, Sergei K.; Sokolov, Alexander N., South Ural State Univ, Natl Res Univ, FSAEIHE SUSU NRU, Dept Informat Secur,Fed State Autonomous Educ Ins, Chelyabinsk, Russia.}},
ISBN = {{978-1-7281-8075-5}},
Keywords = {{information security; industrial control systems (ICS); deep learning;
   generative adversarial networks (GAN)}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Interdisciplinary Applications; Computer Science,
   Theory \& Methods; Engineering, Industrial; Telecommunications}},
Author-Email = {{asp17ask18@susu.ru
   sokolovan@susu.ru}},
Funding-Acknowledgement = {{Russian Ministry of Science {[}16/2020]}},
Funding-Text = {{The reported study was funded by Russian Ministry of Science
   (information security), project number 16/2020.}},
Number-of-Cited-References = {{22}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BR3GH}},
Unique-ID = {{WOS:000646231600032}},
DA = {{2021-11-23}},
}

@article{ WOS:000617064700009,
Author = {Yang, Yuanda and Xie, Guoqi and Wang, Jilong and Zhou, Jia and Xia, Ze
   and Li, Renfa},
Title = {{Intrusion Detection for In-vehicle Network by Using Single GAN in
   Connected Vehicles}},
Journal = {{JOURNAL OF CIRCUITS SYSTEMS AND COMPUTERS}},
Year = {{2021}},
Volume = {{30}},
Number = {{1}},
Month = {{JAN}},
Abstract = {{Controller area network (CAN) bus-based connected and even self-driving
   vehicles suffer severe cybersecurity challenges because connections from
   outside the vehicle and an existing security vulnerability on CAN expose
   passengers to privacy and security threats. Generative adversarial nets
   (GAN)-based intrusion detection systems (IDSs) for in-vehicle network
   can eliminate the limit of insufficient types of attack data suffered by
   the deep learning-based IDSs. The existing GAN-based IDS is a hybrid
   deep learning model built by DNN and GAN, which is too complex to have a
   short detection time. The evaluation performance of this model can be
   further improved. To mitigate this issue, we propose another GAN-based
   intrusion detection method for in-vehicle network, which is a single
   improved GAN. The proposed model can have better evaluation metrics,
   e.g., the testing accuracy rate is up to 99.8\% and poor detection
   performance is addressed when a single GAN is used in intrusion
   detection for the in-vehicle network. In this paper, we design a new
   loss function for generator in GAN to enhance an ability to produce fake
   abnormal data, and utilize a sparse enhancement training method helping
   discriminator in GAN to correct the arbitration bias for fake attack
   data every 100 steps. In addition, we utilize fewer convolution and
   de-convolution layers for constructing GAN model, which can reduce the
   calculation time theoretically and ultimately shorten the detection time
   to 0.12 +/- 0.03 width={''}.17em{''}ms for a data block built by 64 CAN
   messages. We evaluate this improved GAN-based intrusion detection by
   test set. The results demonstrate that our method has not only a
   capacity of five classifications, but also better evaluation performance
   than the existing method in the area of GAN-based IDSs for the
   in-vehicle network.}},
Publisher = {{WORLD SCIENTIFIC PUBL CO PTE LTD}},
Address = {{5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Li, RF (Corresponding Author), Hunan Univ, Coll Comp Sci \& Elect Engn, Changsha 410082, Hunan, Peoples R China.
   Yang, Yuanda; Xie, Guoqi; Wang, Jilong; Zhou, Jia; Xia, Ze; Li, Renfa, Hunan Univ, Coll Comp Sci \& Elect Engn, Changsha 410082, Hunan, Peoples R China.}},
DOI = {{10.1142/S0218126621500079}},
Article-Number = {{2150007}},
ISSN = {{0218-1266}},
EISSN = {{1793-6454}},
Keywords = {{CAN; GAN; in-vehicle network; IDSs}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Hardware \& Architecture; Engineering, Electrical \&
   Electronic}},
Author-Email = {{yyd@hnu.edu.cn
   xgqman@hnu.edu.cn
   wangjilong@hnu.edu.cn
   zhoujia@hnu.edu.cn
   xiaze@hnu.edu.cn
   lirenfa@hnu.edu.cn}},
Funding-Acknowledgement = {{National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}61672217, 61932010]}},
Funding-Text = {{The research is supported by the National Natural Science Foundation of
   China with Grant Nos. 61672217 and 61932010.}},
Number-of-Cited-References = {{44}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{8}},
Usage-Count-Since-2013 = {{9}},
Journal-ISO = {{J. Circuits Syst. Comput.}},
Doc-Delivery-Number = {{QF7IA}},
Unique-ID = {{WOS:000617064700009}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000664599000010,
Author = {Bouzeraib, Wayoud and Ghenai, Afifa and Zeghib, Nadia},
Book-Group-Author = {{IEEE}},
Title = {{A Blockchain Data Balance Using a Generative Adversarial Network
   Approach: Application to Smart House IDS}},
Booktitle = {{2020 4TH INTERNATIONAL CONFERENCE ON ADVANCED ASPECTS OF SOFTWARE
   ENGINEERING (ICAASE'2020): 4TH INTERNATIONAL CONFERENCE ON ADVANCED
   ASPECTS OF SOFTWARE ENGINEERING}},
Year = {{2020}},
Pages = {{65-70}},
Note = {{4th International Conference on Advanced Aspects of Software Engineering
   (ICAASE), Constantine, ALGERIA, NOV 28-30, 2020}},
Organization = {{IEEE; Univ Constantine 2 Abdelhamid Mehri; Abdelhafid Boussouf Univ Ctr}},
Abstract = {{The rapid development of information and communication technologies
   makes the Internet of Things (IoT) devices much more complex and
   heterogeneous. In this context, the massive end devices (IoTs) and the
   large volume of data raise security and privacy challenges. To tackle
   these issues, the joint use of the Bockchain (BC) and Machine Learning
   (ML) seems attractive to achieve decentralized, secure, intelligent and
   efficient management of networks. On the one hand, the BC can greatly
   facilitate the sharing of training data and ML models, the
   decentralization of intelligence, security, privacy and reliable ML
   decision-making. On the other hand, ML may have significant impacts on
   the development of BC in communications and networking systems,
   including energy and resource efficiency, scalability, security, privacy
   and smart contracting. An important aspect of security intends to detect
   unusual and potentially inappropriate activities according to traffic
   patterns. This paper focuses on the problem of imbalance data where the
   number of abnormal samples is significantly lower than that of the
   normal (secure) ones. In particular, this paper presents a new
   equilibrium model based on an exciting recent innovation in ML namely
   Generator Adverse Networks (GANs) to address the problem of class
   imbalance and data noise to Intrusion Detection System (IDS)
   performance. The proposed approach use is illustrated by a case study: a
   smart house system-based scenario.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Bouzeraib, W (Corresponding Author), Constantine 2 Univ, LIRE Lab, Constantine, Algeria.
   Bouzeraib, Wayoud; Ghenai, Afifa; Zeghib, Nadia, Constantine 2 Univ, LIRE Lab, Constantine, Algeria.}},
DOI = {{10.1109/ICAASE51408.2020.9380110}},
ISBN = {{978-1-6654-2231-4}},
Keywords = {{Blockchain; Generative Adversarial Network (GAN); Internet of Things
   (IoT); Intrusion Detection System IDS; Machine Learning; Security}},
Keywords-Plus = {{INTERNET}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Software Engineering}},
Author-Email = {{wayoud.bouzeraib@univ-constantine2.dz
   afifa.ghenai@univ-constantine2.dz
   nadia.zeghib@univ-constantine2.dz}},
Number-of-Cited-References = {{31}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{3}},
Doc-Delivery-Number = {{BR6XW}},
Unique-ID = {{WOS:000664599000010}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000702210400208,
Author = {Wang, Ning and Chen, Yimin and Hu, Yang and Lou, Wenjing and Hou, Y.
   Thomas},
Book-Group-Author = {{IEEE}},
Title = {{MANDA: On Adversarial Example Detection for Network Intrusion Detection
   System}},
Booktitle = {{IEEE CONFERENCE ON COMPUTER COMMUNICATIONS (IEEE INFOCOM 2021)}},
Series = {{IEEE INFOCOM}},
Year = {{2021}},
Note = {{40th IEEE Conference on Computer Communications (IEEE INFOCOM), ELECTR
   NETWORK, MAY 10-13, 2021}},
Organization = {{IEEE}},
Abstract = {{With the rapid advancement in machine learning (ML), ML-based Intrusion
   Detection Systems (IDSs) are widely deployed to protect networks from
   various attacks. Yet one of the biggest challenges is that ML-based IDSs
   suffer from adversarial example (AE) attacks. By applying small
   perturbations (e.g. slightly increasing packet inter-arrival time) to
   the intrusion traffic, an AE attack can flip the prediction of a
   well-trained IDS. We address this challenge by proposing MANDA, a
   MANifold and Decision boundary-based AE detection system. Through
   analyzing AE attacks, we notice that 1) an AE tends to be close to its
   original manifold (i.e., the cluster of samples in its original class)
   regardless which class it is misclassified into; and 2) AEs tend to be
   close to the decision boundary so as to minimize the perturbation scale.
   Based on the two observations, we design MANDA for accurate AE detection
   by exploiting inconsistency between manifold evaluation and IDS model
   inference and evaluating model uncertainty on small perturbations. We
   evaluate MANDA on NSL-KDD under three state-of-the-art AE attacks. Our
   experimental results show that MANDA achieves as high as 98.41\%
   true-positive rate with 5\% false-positive rate and can be applied to
   other problem spaces such as image recognition.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Wang, N (Corresponding Author), Virginia Polytech Inst \& State Univ, Blacksburg, VA 24061 USA.
   Wang, Ning; Chen, Yimin; Hu, Yang; Lou, Wenjing; Hou, Y. Thomas, Virginia Polytech Inst \& State Univ, Blacksburg, VA 24061 USA.}},
DOI = {{10.1109/INFOCOM42981.2021.9488874}},
ISSN = {{0743-166X}},
ISBN = {{978-0-7381-1281-7}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Hardware \& Architecture; Computer Science,
   Information Systems; Computer Science, Theory \& Methods; Engineering,
   Electrical \& Electronic; Telecommunications}},
Funding-Acknowledgement = {{Office of Naval ResearchOffice of Naval Research {[}N00014-19-1-2621];
   National Science FoundationNational Science Foundation (NSF)
   {[}CNS-1837519]; Virginia Commonwealth Cyber Initiative (CCI)}},
Funding-Text = {{This work was supported in part by the Office of Naval Research under
   grant N00014-19-1-2621, the National Science Foundation under grants
   CNS-1837519, and the Virginia Commonwealth Cyber Initiative (CCI).}},
Number-of-Cited-References = {{47}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BS2JU}},
Unique-ID = {{WOS:000702210400208}},
DA = {{2021-11-23}},
}

@article{ WOS:000692238300014,
Author = {Araujo, Frederico and Ayoade, Gbadebo and Al-Naami, Khaled and Gao, Yang
   and Hamlen, Kevin W. and Khan, Latifur},
Title = {{Crook-sourced intrusion detection as a service}},
Journal = {{JOURNAL OF INFORMATION SECURITY AND APPLICATIONS}},
Year = {{2021}},
Volume = {{61}},
Month = {{SEP}},
Abstract = {{Most conventional cyber defenses strive to reject detected attacks as
   quickly and decisively as possible; however, this instinctive approach
   has the disadvantage of depriving intrusion detection systems (IDSes) of
   learning experiences and threat data that might otherwise be gleaned
   from deeper interactions with adversaries. For IDS technology to
   improve, a next-generation cyber defense is proposed in which cyber
   attacks are unconventionally reimagined as free sources of live IDS
   training data. Rather than aborting attacks against legitimate services,
   adversarial interactions are selectively prolonged to maximize the
   defender's harvest of useful threat intelligence. Enhancing web services
   with deceptive attack-responses in this way is shown to be a powerful
   and practical strategy for improved detection, addressing several
   perennial challenges for machine learning-based IDS in the literature,
   including scarcity of training data, the high labeling burden for (semi
   )supervised learning, encryption opacity, and concept differences
   between honeypot attacks and those against genuine services. By
   reconceptualizing software security patches as feature extraction
   engines, the approach conscripts attackers as free penetration testers,
   and coordinates multiple levels of the software stack to achieve fast,
   automatic, and accurate labeling of live web streams. Prototype
   implementations are showcased for two feature set models to extract
   security-relevant network and system-level features from cloud services
   hosting enterprise-grade web applications. The evaluation demonstrates
   that the extracted data can be fed back into a network-level IDS for
   exceptionally accurate, yet lightweight attack detection.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Araujo, F (Corresponding Author), Thomas J Watson Res Ctr, IBM Res, Yorktown Hts, NY 10598 USA.
   Araujo, Frederico, Thomas J Watson Res Ctr, IBM Res, Yorktown Hts, NY 10598 USA.
   Ayoade, Gbadebo; Al-Naami, Khaled; Gao, Yang; Hamlen, Kevin W.; Khan, Latifur, Univ Texas Dallas, Richardson, TX 75080 USA.}},
DOI = {{10.1016/j.jisa.2021.102880}},
Article-Number = {{102880}},
ISSN = {{2214-2126}},
EISSN = {{2214-2134}},
Keywords = {{Intrusion detection; Datasets; Neural networks; Honeypots;
   Cyberdeception; Cloud computing; Software-as-a-service}},
Keywords-Plus = {{EVOLVING DATA; NETWORK; CLASSIFICATION; SYSTEMS; STREAMS; MODEL}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems}},
Author-Email = {{frederico.araujo@ibm.com}},
ORCID-Numbers = {{Gao, Yang/0000-0001-9328-1611}},
Funding-Acknowledgement = {{ARO, USA award {[}W911NF2110032]; ONR, USA award {[}N00014-17-1-2995];
   NSA, USA award {[}H98230-15-1-0271]; AFOSR, USAUnited States Department
   of DefenseAir Force Office of Scientific Research (AFOSR)
   {[}FA9550-14-1-0173]; National Science Foundation, USA FAIN awards
   {[}DGE-1931800, OAC-1828467, DGE-1723602]; National Science Foundation,
   USANational Science Foundation (NSF) {[}DMS-1737978, MRI-1828467]; IBM,
   USA faculty award; Hewlett-Packard, USA grant; Eugene McDermott family}},
Funding-Text = {{The research reported herein was supported in part by ARO, USA award
   W911NF2110032; ONR, USA award N00014-17-1-2995; NSA, USA award
   H98230-15-1-0271; AFOSR, USA award FA9550-14-1-0173; an endowment from
   the Eugene McDermott family; National Science Foundation, USA FAIN
   awards DGE-1931800, OAC-1828467, and DGE-1723602; National Science
   Foundation, USA awards DMS-1737978 and MRI-1828467; an IBM, USA faculty
   award (Research); and a Hewlett-Packard, USA grant. Any opinions,
   recommendations, or conclusions expressed are those of the authors and
   not necessarily of the aforementioned supporters.}},
Number-of-Cited-References = {{125}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{J. Inf. Secur. Appl.}},
Doc-Delivery-Number = {{UK8TN}},
Unique-ID = {{WOS:000692238300014}},
DA = {{2021-11-23}},
}

@article{ WOS:000600714100002,
Author = {Bai, Tim and Bian, Haibo and Salahuddin, Mohammad A. and Abou Daya,
   Abbas and Limam, Noura and Boutaba, Raouf},
Title = {{RDP-based Lateral Movement detection using Machine Learning}},
Journal = {{COMPUTER COMMUNICATIONS}},
Year = {{2021}},
Volume = {{165}},
Pages = {{9-19}},
Month = {{JAN 1}},
Abstract = {{Detecting cyber threats has been an on-going research endeavor. In this
   era, Advanced Persistent Threats (APTs) can incur significant costs for
   organizations and businesses. The ultimate goal of cybersecurity is to
   thwart attackers from achieving their malicious intent, whether it is
   credential stealing, infrastructure takeover, or program sabotage. Every
   cyber attack goes through several stages before its termination. Lateral
   Movement (LM) is one of those stages that is of particular importance.
   Remote Desktop Protocol (RDP) is a method used in LM to successfully
   authenticate to an unauthorized host that leaves footprints on both host
   and network logs. In this paper, we propose to detect evidence of LM
   using Machine Learning (ML) and Windows RDP event logs. We explore
   different feature sets extracted from these logs and evaluate various
   supervised ML techniques for classifying RDP sessions with high
   precision and recall. We also compare the performance of our proposed
   approach to a state-of-the-art approach and demonstrate that our ML
   model outperforms in classifying RDP sessions in Windows event logs. In
   addition, we show that our model is robust against certain types of
   adversarial attacks.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Limam, N (Corresponding Author), Univ Waterloo, David R Cheriton Sch Comp Sci, Waterloo, ON, Canada.
   Bai, Tim; Bian, Haibo; Salahuddin, Mohammad A.; Abou Daya, Abbas; Limam, Noura; Boutaba, Raouf, Univ Waterloo, David R Cheriton Sch Comp Sci, Waterloo, ON, Canada.}},
DOI = {{10.1016/j.comcom.2020.10.013}},
ISSN = {{0140-3664}},
EISSN = {{1873-703X}},
Keywords = {{Cybersecurity; Advanced Persistent Threats; Lateral Movement;
   Adversarial learning; Machine Learning}},
Keywords-Plus = {{INTRUSION DETECTION}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{tim.bai@uwaterloo.ca
   haibo.bian@uwaterloo.ca
   mohammad.salahuddin@uwaterloo.ca
   aaboudaya@uwaterloo.ca
   noura.limam@uwaterloo.ca
   rboutaba@uwaterloo.ca}},
ORCID-Numbers = {{Bai, Zhenyu/0000-0002-6090-7988}},
Funding-Acknowledgement = {{Royal Bank of Canada; NSERC CRD, CanadaNatural Sciences and Engineering
   Research Council of Canada (NSERC) {[}530335]}},
Funding-Text = {{This work was supported in part by the Royal Bank of Canada and in part
   by the NSERC CRD, Canada Grant No. 530335.}},
Number-of-Cited-References = {{50}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Journal-ISO = {{Comput. Commun.}},
Doc-Delivery-Number = {{PH9HL}},
Unique-ID = {{WOS:000600714100002}},
DA = {{2021-11-23}},
}

@article{ WOS:000579926000007,
Author = {Cui, Lei and Qu, Youyang and Gao, Longxiang and Xie, Gang and Yu, Shui},
Title = {{Detecting false data attacks using machine learning techniques in smart
   grid: A survey}},
Journal = {{JOURNAL OF NETWORK AND COMPUTER APPLICATIONS}},
Year = {{2020}},
Volume = {{170}},
Month = {{NOV 15}},
Abstract = {{The big data sources in smart grid (SG) enable utilities to monitor,
   control, and manage the energy system effectively, which is also
   promising to advance the efficiency, reliability, and sustainability of
   energy usage. However, false data attacks, as a major threat with wide
   targets and severe impacts, have exposed the SG systems to a large
   variety of security issues. To detect this threat effectively, several
   machine learning (ML)-based methods have been developed in the past few
   years. In this paper, we provide a comprehensive survey of these
   advances. The paper starts by providing a brief overview of SG
   architecture and its data sources. Moreover, the categories of false
   data attacks followed by data security requirements are introduced.
   Then, the recent ML-based detection techniques are summarized by
   grouping them into three major detection scenarios: non-technical
   losses, state estimation, and load forecasting. At last, we further
   investigate the potential research directions at the end of the paper,
   considering the deficiencies of current ML-based mechanisms.
   Specifically, we discuss intrusion detection against adversarial
   attacks, collaborative and decentralized detection framework, detection
   with privacy preservation, and some potential advanced ML techniques.}},
Publisher = {{ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD}},
Address = {{24-28 OVAL RD, LONDON NW1 7DX, ENGLAND}},
Type = {{Review}},
Language = {{English}},
Affiliation = {{Yu, S (Corresponding Author), Univ Technol Sydney, Sch Comp Sci, Sydney, NSW, Australia.
   Cui, Lei; Qu, Youyang; Gao, Longxiang, Deakin Univ, Sch Informat Technol, Geelong, Vic, Australia.
   Cui, Lei; Xie, Gang, Taiyuan Univ Sci \& Technol, Key Lab Adv Control \& Intelligent Informat Syst, Taiyuan, Peoples R China.
   Yu, Shui, Univ Technol Sydney, Sch Comp Sci, Sydney, NSW, Australia.}},
DOI = {{10.1016/j.jnca.2020.102808}},
Article-Number = {{102808}},
ISSN = {{1084-8045}},
EISSN = {{1095-8592}},
Keywords = {{Smart grid; Security; False data; Machine learning; Intrusion detection}},
Keywords-Plus = {{ELECTRICITY THEFT DETECTION; STATE ESTIMATION; PRIVACY; SECURITY;
   SYSTEMS; AMI; AGGREGATION; SCHEME}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Hardware \& Architecture; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering}},
Author-Email = {{shui.yu@uts.edu.au}},
ORCID-Numbers = {{Yu, Shui/0000-0003-4485-6743}},
Funding-Acknowledgement = {{China Scholarship Council (CSC)China Scholarship Council
   {[}201808240004]; Shanxi International Cooperation Project, China
   {[}201803D421-039]; Scientific and Technologial Innovation Programs of
   Higher Education Institutions in Shanxi, China {[}2020L0338]; Shanxi
   Province Science Foundation for Youth, China {[}201901D211306]}},
Funding-Text = {{This work was supported by the China Scholarship Council (CSC) under
   Grant No. 201808240004, the Shanxi International Cooperation Project,
   China under Grant No. 201803D421-039, the Scientific and Technologial
   Innovation Programs of Higher Education Institutions in Shanxi, China
   under Grant No. 2020L0338, and the Shanxi Province Science Foundation
   for Youth, China under Grant No. 201901D211306.}},
Number-of-Cited-References = {{108}},
Times-Cited = {{11}},
Usage-Count-Last-180-days = {{8}},
Usage-Count-Since-2013 = {{26}},
Journal-ISO = {{J. Netw. Comput. Appl.}},
Doc-Delivery-Number = {{OD5XG}},
Unique-ID = {{WOS:000579926000007}},
DA = {{2021-11-23}},
}

@article{ WOS:000698955200002,
Author = {Kumar, M. R. Pavan and Jayagopal, Prabhu},
Title = {{Multi-class imbalanced image classification using conditioned GANs}},
Journal = {{INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL}},
Year = {{2021}},
Volume = {{10}},
Number = {{3}},
Pages = {{143-153}},
Month = {{SEP}},
Abstract = {{The problem of data skewness, class imbalance, data scarcity and noise
   limits the application of machine learning and deep learning models in
   applications like anomaly detection, fraud detection, intrusion
   detection, fault diagnosis, machine-to-machine communication, etc.
   Performance of supervised learning leans towards majority class and
   fails to generalize testing data in class imbalance and noisy data
   problems. Using neural-based data augmentation techniques for data
   generation and deep convolutional models for classification would
   enhance the performance of the applications mentioned above. Recently,
   GANs (generative adversarial networks) showed significant improvements
   in generating images. In this paper, a model that uses a conditioned
   deep convolutional GAN and an auxiliary classifier are proposed to
   tackle the aforementioned issues. The conditioned GAN is used for data
   generation of minority classes images and noisy images. Another
   auxiliary deep convolutional model is employed for the classification of
   images on data augmented dataset. Also, a multi-hinge loss is employed
   in both the data augmentation and classification tasks. The
   effectiveness of the proposed model is investigated on the quality of
   generated images and classification metrics using four publicly
   available popular datasets: MNIST, EMNIST, CIFAR10, and SVHN. The
   proposed model has shown significant improvements over the other often
   used models of data augmentation and multi-class imbalance image
   classification in terms of generated samples and classification
   accuracy.}},
Publisher = {{SPRINGER}},
Address = {{ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Jayagopal, P (Corresponding Author), Vellore Inst Technol, Sch Informat Technol \& Engn, Vellore, Tamil Nadu, India.
   Kumar, M. R. Pavan, Vellore Inst Technol, Sch Comp Sci \& Engn, Vellore, Tamil Nadu, India.
   Jayagopal, Prabhu, Vellore Inst Technol, Sch Informat Technol \& Engn, Vellore, Tamil Nadu, India.}},
DOI = {{10.1007/s13735-021-00213-6}},
ISSN = {{2192-6611}},
EISSN = {{2192-662X}},
Keywords = {{Imbalanced data; Convolutional neural network; Data augmentation;
   Generative model; Adversarial network}},
Keywords-Plus = {{ADVERSARIAL; SMOTE}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering}},
Author-Email = {{marabattinasivapavan@gmail.com
   jprabhuit@gmail.com}},
ORCID-Numbers = {{JAYAGOPAL, PRABHU/0000-0003-3335-6911
   , Pavan Kumar M R/0000-0002-6754-7372}},
Number-of-Cited-References = {{38}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{10}},
Usage-Count-Since-2013 = {{10}},
Journal-ISO = {{Int. J. Multimed. Inf. Retr.}},
Doc-Delivery-Number = {{UU7DE}},
Unique-ID = {{WOS:000698955200002}},
DA = {{2021-11-23}},
}

@article{ WOS:000302787900003,
Author = {Gargiulo, Francesco and Mazzariello, Claudio and Sansone, Carlo},
Title = {{Automatically building datasets of labeled IP traffic traces: A
   self-training approach}},
Journal = {{APPLIED SOFT COMPUTING}},
Year = {{2012}},
Volume = {{12}},
Number = {{6}},
Pages = {{1640-1649}},
Month = {{JUN}},
Abstract = {{Many approaches have been proposed so far to tackle computer network
   security. Among them, several systems exploit Machine Learning and
   Pattern Recognition techniques, by regarding malicious behavior
   detection as a classification problem. Supervised and unsupervised
   algorithms have been used in this context, each one with its own
   benefits and shortcomings. When using supervised techniques, a
   representative training set is required, which reliably indicates what a
   human expert wants the system to learn and recognize, by means of
   suitably labeled samples. In real environments there is a significant
   difficulty in collecting a representative dataset of correctly labeled
   traffic traces. In adversarial environments such a task is made even
   harder by malicious attackers, trying to make their actions' evidences
   stealthy.
   In order to overcome this problem, a self-training system is presented
   in this paper, building a dataset of labeled network traffic based on
   raw tcpdump traces and no prior knowledge on data. Results on both
   emulated and real traffic traces have shown that intrusion detection
   systems trained on such a dataset perform as well as the same systems
   trained on correctly hand-labeled data. (C) 2012 Elsevier B. V. All
   rights reserved.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Sansone, C (Corresponding Author), Univ Naples Federico II, Comp \& Syst Engn Dept, Via Claudio 21, I-80125 Naples, Italy.
   Gargiulo, Francesco; Mazzariello, Claudio; Sansone, Carlo, Univ Naples Federico II, Comp \& Syst Engn Dept, I-80125 Naples, Italy.}},
DOI = {{10.1016/j.asoc.2012.02.012}},
ISSN = {{1568-4946}},
EISSN = {{1872-9681}},
Keywords = {{Soft label; Network security; IDS}},
Keywords-Plus = {{INTRUSION DETECTION; MULTIPLE CLASSIFIERS; FUSION; CLASSIFICATION}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications}},
Author-Email = {{francesco.grg@unina.it
   claudio.mazzariello@unina.it
   carlo.sansone@gmail.com}},
ResearcherID-Numbers = {{Gargiulo, Francesco/Q-5204-2018
   }},
ORCID-Numbers = {{Gargiulo, Francesco/0000-0003-0400-3332
   Sansone, Carlo/0000-0002-8176-6950}},
Number-of-Cited-References = {{29}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{17}},
Journal-ISO = {{Appl. Soft. Comput.}},
Doc-Delivery-Number = {{925UT}},
Unique-ID = {{WOS:000302787900003}},
DA = {{2021-11-23}},
}

@article{ WOS:000640857400005,
Author = {Dlamini, Gcinizwe and Fahim, Muhammad},
Title = {{DGM: a data generative model to improve minority class presence in
   anomaly detection domain}},
Journal = {{NEURAL COMPUTING \& APPLICATIONS}},
Year = {{2021}},
Volume = {{33}},
Number = {{20}},
Pages = {{13635-13646}},
Month = {{OCT}},
Abstract = {{Anomaly detection is a process to identify abnormal behavior that does
   not confirm the normal behavior. The abnormal behavior clues are few
   because it appears rarely. To detect each abnormal behavior, the problem
   is transformed into a multi-class classification task where it lies into
   data imbalance representation. In data imbalance setting, minority
   classes are over-sampled to improve the performance of the classifier.
   Existing methods are unable to learn the distribution of the minority
   class and effects the performance of classifier. In this research, we
   introduced a data generative model (DGM) to improve the minority class
   presence in the anomaly detection domain. Our approach is based on a
   conditional generative adversarial network to generate synthetic samples
   for minority classes. It includes the KL-divergence to guide the model
   towards the true learning of minority class distribution. In this way,
   model learns the complex underlying data distribution and generates new
   samples. We performed experiments over the two benchmark datasets
   NSL-KDD and UNSW-NB15 that are publicly available to demonstrate the
   effectiveness of our approach. Furthermore, the comparative analysis
   with the existing approaches confirms the stability and superiority of
   our presented model.}},
Publisher = {{SPRINGER LONDON LTD}},
Address = {{236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Fahim, M (Corresponding Author), Innopolis Univ, Innopolis, Russia.
   Dlamini, Gcinizwe; Fahim, Muhammad, Innopolis Univ, Innopolis, Russia.}},
DOI = {{10.1007/s00521-021-05993-w}},
Early Access Date = {{APR 2021}},
ISSN = {{0941-0643}},
EISSN = {{1433-3058}},
Keywords = {{Intrusion detection system; Data balancing; Generative adversarial
   network; Cybersecurity}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{g.dlamini@innopolis.university
   m.fahim@innnopolis.ru}},
Number-of-Cited-References = {{33}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{6}},
Usage-Count-Since-2013 = {{6}},
Journal-ISO = {{Neural Comput. Appl.}},
Doc-Delivery-Number = {{WL7HG}},
Unique-ID = {{WOS:000640857400005}},
DA = {{2021-11-23}},
}

@article{ WOS:000628914700071,
Author = {Bian, Haibo and Bai, Tim and Salahuddin, Mohammad A. and Limam, Noura
   and Daya, Abbas Abou and Boutaba, Raouf},
Title = {{Uncovering Lateral Movement Using Authentication Logs}},
Journal = {{IEEE TRANSACTIONS ON NETWORK AND SERVICE MANAGEMENT}},
Year = {{2021}},
Volume = {{18}},
Number = {{1}},
Pages = {{1049-1063}},
Month = {{MAR}},
Abstract = {{Network infiltrations due to advanced persistent threats (APTs) have
   significantly grown in recent years. Their primary objective is to gain
   unauthorized access to network assets, compromise system and data. APTs
   are stealthy and remain dormant for an extended period of time, which
   makes their detection challenging. In this article, we leverage machine
   learning (ML) to detect hosts in a network that are a target of an APT
   attack. We evaluate a number of ML classifiers to detect susceptible
   hosts in the Los Alamos National Lab dataset. We (i) scrutinize
   graph-based features extracted from host authentication logs, (ii) use
   feature engineering to reduce dimensionality, (iii) explore balancing
   the training dataset using over- and under-sampling techniques, (iv)
   evaluate numerous supervised ML techniques and their ensemble, (v)
   compare our classification model to the state-of-the-art approaches that
   leverage the same dataset, and show that our model outperforms them with
   respect to prediction performance and overhead, and (vi) perturb the
   attack patterns to study the influence of change in attack frequency and
   scale on classification performance, and propose a solution for such
   adversarial behavior.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Limam, N (Corresponding Author), Univ Waterloo, DC Sch Comp Sci, Waterloo, ON N2L 3G1, Canada.
   Bian, Haibo; Bai, Tim; Boutaba, Raouf, Univ Waterloo, Dept Comp Sci, Waterloo, ON N2L 3G1, Canada.
   Salahuddin, Mohammad A., Univ Waterloo, David R Cheriton Sch Comp Sci, Waterloo, ON N2L 3G1, Canada.
   Limam, Noura; Daya, Abbas Abou, Univ Waterloo, DC Sch Comp Sci, Waterloo, ON N2L 3G1, Canada.}},
DOI = {{10.1109/TNSM.2021.3054356}},
ISSN = {{1932-4537}},
Keywords = {{Feature extraction; Authentication; Training; Anomaly detection;
   Tagging; Protocols; Principal component analysis; Machine learning;
   advanced persistent threat; intrusion detection; adversarial learning}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems}},
Author-Email = {{haibo.bian@uwaterloo.ca
   tim.bai@uwaterloo.ca
   mohammad.salahuddin@uwaterloo.ca
   n2limam@uwaterloo.ca
   aaboudaya@uwaterloo.ca
   rboutaba@uwaterloo.ca}},
ResearcherID-Numbers = {{Boutaba, Raouf/G-8483-2017
   }},
ORCID-Numbers = {{Boutaba, Raouf/0000-0001-7936-6862
   Bai, Zhenyu/0000-0002-6090-7988
   Limam, Noura/0000-0002-7759-3751}},
Funding-Acknowledgement = {{Royal Bank of Canada; Natural Sciences and Engineering Research Council
   of Canada Collaborative Research and Development GrantNatural Sciences
   and Engineering Research Council of Canada (NSERC) {[}530335]}},
Funding-Text = {{This work was supported in part by the Royal Bank of Canada and in part
   by the Natural Sciences and Engineering Research Council of Canada
   Collaborative Research and Development Grant 530335. The associate
   editor coordinating the review of this article and approving it for
   publication was G. Casale.}},
Number-of-Cited-References = {{42}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{IEEE Trans. Netw. Serv. Manag.}},
Doc-Delivery-Number = {{QW8QZ}},
Unique-ID = {{WOS:000628914700071}},
DA = {{2021-11-23}},
}

@article{ WOS:000699628200001,
Author = {Bourou, Stavroula and El Saer, Andreas and Velivassaki,
   Terpsichori-Helen and Voulkidis, Artemis and Zahariadis, Theodore},
Title = {{A Review of Tabular Data Synthesis Using GANs on an IDS Dataset}},
Journal = {{INFORMATION}},
Year = {{2021}},
Volume = {{12}},
Number = {{9}},
Month = {{SEP}},
Abstract = {{Recent technological innovations along with the vast amount of available
   data worldwide have led to the rise of cyberattacks against network
   systems. Intrusion Detection Systems (IDS) play a crucial role as a
   defense mechanism in networks against adversarial attackers. Machine
   Learning methods provide various cybersecurity tools. However, these
   methods require plenty of data to be trained efficiently, which may be
   hard to collect or to use due to privacy reasons. One of the most
   notable Machine Learning tools is the Generative Adversarial Network
   (GAN), and it has great potential for tabular data synthesis. In this
   work, we start by briefly presenting the most popular GAN architectures,
   VanillaGAN, WGAN, and WGAN-GP. Focusing on tabular data generation,
   CTGAN, CopulaGAN, and TableGAN models are used for the creation of
   synthetic IDS data. Specifically, the models are trained and evaluated
   on an NSL-KDD dataset, considering the limitations and requirements that
   this procedure needs. Finally, based on certain quantitative and
   qualitative methods, we argue and evaluate the most prominent GANs for
   tabular network data synthesis.}},
Publisher = {{MDPI}},
Address = {{ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND}},
Type = {{Review}},
Language = {{English}},
Affiliation = {{Bourou, S (Corresponding Author), Synelixis Solut SA, Chalkida 34100, Greece.
   Bourou, Stavroula; El Saer, Andreas; Velivassaki, Terpsichori-Helen; Voulkidis, Artemis; Zahariadis, Theodore, Synelixis Solut SA, Chalkida 34100, Greece.}},
DOI = {{10.3390/info12090375}},
Article-Number = {{375}},
EISSN = {{2078-2489}},
Keywords = {{GAN; tabular data generation; synthetic dataset; NSL-KDD dataset; IDS}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems}},
Author-Email = {{bourou@synelixis.com
   elsaer@synelixis.com
   terpsi@synelixis.com
   voulkidis@synelixis.com
   zahariad@synelixis.com}},
ORCID-Numbers = {{Velivassaki, Terpsichori-Eleni/0000-0002-0362-4607}},
Funding-Acknowledgement = {{H2020 IoT-NGIN project within the H2020 Framework Program of the
   European Commission {[}957246]}},
Funding-Text = {{This work was partially funded by the H2020 IoT-NGIN project, contract
   no. 957246, within the H2020 Framework Program of the European
   Commission.}},
Number-of-Cited-References = {{48}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{Information}},
Doc-Delivery-Number = {{UV7BF}},
Unique-ID = {{WOS:000699628200001}},
OA = {{gold, Green Published}},
DA = {{2021-11-23}},
}

@article{ WOS:000711308800001,
Author = {Ahsan, Rahbar and Shi, Wei and Ma, Xiangyu and Croft, William Lee},
Title = {{A comparative analysis of CGAN-based oversampling for anomaly detection}},
Journal = {{IET CYBER-PHYSICAL SYSTEMS: THEORY \& APPLICATIONS}},
Abstract = {{In this work, the problem of anomaly detection in imbalanced datasets,
   framed in the context of network intrusion detection is studied. A novel
   anomaly detection solution that takes both data-level and
   algorithm-level approaches into account to cope with the class-imbalance
   problem is proposed. This solution integrates the auto-learning ability
   of Reinforcement Learning with the oversampling ability of a Conditional
   Generative Adversarial Network (CGAN). To further investigate the
   potential of a CGAN, in imbalanced classification tasks, the effect of
   CGAN-based oversampling on the following classifiers is examined: Naive
   Bayes, Multilayer Perceptron, Random Forest and Logistic Regression.
   Through the experimental results, the authors demonstrate improved
   performance from the proposed approach, and from CGAN-based oversampling
   in general, over other oversampling techniques such as Synthetic
   Minority Oversampling Technique and Adaptive Synthetic.}},
Publisher = {{WILEY}},
Address = {{111 RIVER ST, HOBOKEN 07030-5774, NJ USA}},
Type = {{Article; Early Access}},
Language = {{English}},
Affiliation = {{Ma, XY (Corresponding Author), Carleton Univ, Sch Informat Technol, 1125 Colonel By Dr, Ottawa, ON, Canada.
   Ahsan, Rahbar; Croft, William Lee, Carleton Univ, Sch Comp Sci, Ottawa, ON, Canada.
   Shi, Wei; Ma, Xiangyu, Carleton Univ, Sch Informat Technol, 1125 Colonel By Dr, Ottawa, ON, Canada.}},
DOI = {{10.1049/cps2.12019}},
Early Access Date = {{OCT 2021}},
EISSN = {{2398-3396}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical \& Electronic}},
Author-Email = {{johnnyma@cmail.carleton.ca}},
Funding-Acknowledgement = {{Natural Sciences and Engineering Research Council of CanadaNatural
   Sciences and Engineering Research Council of Canada (NSERC)CGIAR
   {[}RGPIN-202006482]}},
Funding-Text = {{Natural Sciences and Engineering Research Council of Canada, Grant/Award
   Number: RGPIN-202006482}},
Number-of-Cited-References = {{39}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{IET Cyber Phys. Syst. Theory Appl.}},
Doc-Delivery-Number = {{WM8DD}},
Unique-ID = {{WOS:000711308800001}},
OA = {{gold}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000671822600025,
Author = {Leslie, Nandi},
Book-Group-Author = {{IEEE}},
Title = {{An Unsupervised Learning Approach for In-Vehicle Network Intrusion
   Detection}},
Booktitle = {{2021 55TH ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS (CISS)}},
Year = {{2021}},
Note = {{55th Annual Conference on Information Sciences and Systems (CISS),
   ELECTR NETWORK, MAR 24-26, 2021}},
Abstract = {{In-vehicle networks remain largely unprotected from a myriad of
   vulnerabilities to failures caused by adversarial activities. Remote
   attacks on the SAE J1939 protocol based on controller access network
   (CAN) bus for heavy-duty ground vehicles can lead to detectable changes
   in the physical characteristics of the vehicle. In this paper, I develop
   an unsupervised learning approach to monitor the normal behavior within
   the CAN bus data and detect malicious traffic. The J1939 data packets
   have some text-based features that I convert to numerical values. In
   addition, I propose an algorithm based on hierarchical agglomerative
   clustering that considers multiple approaches for linkages and pairwise
   distances between observations. I present prediction performance results
   to show the effectiveness of this ensemble algorithm. In addition to
   in-vehicle network security, this algorithm is also transferrable to
   other cybersecurity datasets, including botnet attacks in traditional
   enterprise IP networks.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Leslie, N (Corresponding Author), Raytheon Technol, Arlington, VA 22209 USA.
   Leslie, Nandi, Raytheon Technol, Arlington, VA 22209 USA.}},
DOI = {{10.1109/CISS50987.2021.9400233}},
ISBN = {{978-1-6654-1268-1}},
Keywords = {{Unsupervised learning; hierarchical clustering; in-vehicle networks;
   cybersecurity}},
Research-Areas = {{Computer Science; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Telecommunications}},
Author-Email = {{nandi.o.leslie@raytheon.com}},
Number-of-Cited-References = {{15}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BR8FQ}},
Unique-ID = {{WOS:000671822600025}},
DA = {{2021-11-23}},
}

@article{ WOS:000668574400001,
Author = {Podder, Prajoy and Bharati, Subrato and Mondal, M. Rubaiyat Hossain and
   Paul, Pinto Kumar and Kose, Utku},
Title = {{Artificial Neural Network for Cybersecurity: A Comprehensive Review}},
Journal = {{JOURNAL OF INFORMATION ASSURANCE AND SECURITY}},
Year = {{2021}},
Volume = {{16}},
Number = {{1}},
Pages = {{10-23}},
Abstract = {{Cybersecurity is a very emerging field that protects systems, networks,
   and data from digital attacks. With the increase in the scale of the
   Internet and the evolution of cyber attacks, developing novel
   cybersecurity tools has become important, particularly for Internet of
   things (IoT) networks. This paper provides a systematic review of the
   application of deep learning (DL) approaches for cybersecurity. This
   paper provides a short description of DL methods which is used in
   cybersecurity, including deep belief networks, generative adversarial
   networks, recurrent neural networks, and others. Next, we illustrate the
   differences between shallow learning and DL. Moreover, a discussion is
   provided on the currently prevailing cyber-attacks in IoT and other
   networks, and the effectiveness of DL methods to manage these attacks.
   Besides, this paper describes studies that highlight the DL technique,
   cybersecurity applications, and the source of datasets. Next, a
   discussion is provided on the feasibility of DL systems for malware
   detection and classification, intrusion detection, and other frequent
   cyber-attacks, including identifying file type, spam, and network
   traffic. Our review indicates that high classification accuracy of
   99.72\% is obtained by restricted Boltzmann machine (RBM) when applied
   to a custom dataset, while long short-term memory (LSTM) achieves an
   accuracy of 99.80\% for KDD Cup 99 dataset. Finally, this article
   discusses the importance of cybersecurity for reliable and practicable
   IoT-driven healthcare systems.}},
Publisher = {{DYNAMIC PUBLISHERS, INC}},
Address = {{PO BOX 48654, ATLANTA, GA 30362-0654 USA}},
Type = {{Review}},
Language = {{English}},
Affiliation = {{Podder, P (Corresponding Author), Bangladesh Univ Engn \& Technol, Inst Informat \& Commun Technol, Dhaka 1205, Bangladesh.
   Podder, Prajoy; Bharati, Subrato; Mondal, M. Rubaiyat Hossain, Bangladesh Univ Engn \& Technol, Inst Informat \& Commun Technol, Dhaka 1205, Bangladesh.
   Paul, Pinto Kumar, Ranada Prasad Shaha Univ, Dept CSE, Narayanganj 1400, Bangladesh.
   Kose, Utku, Suleyman Demirel Univ, Isparta, Turkey.}},
ISSN = {{1554-1010}},
EISSN = {{1554-1029}},
Keywords = {{Deep learning; cyber analytics; autoencoders; convolutional neural
   networks (CNN); deep belief networks (DBN)}},
Keywords-Plus = {{DISTRIBUTED ATTACK DETECTION; DEEP LEARNING APPROACH; INTRUSION
   DETECTION; CYBER SECURITY; ANOMALY DETECTION; CLASSIFICATION; INTERNET;
   SYSTEM}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems}},
Author-Email = {{prajoypodder@gmail.com
   subratobharati1@gmail.com
   rubaiyat97@iict.buetac.bd
   pinto.kumar07@gmail.com
   utkukose@sdu.edu.tr}},
ResearcherID-Numbers = {{Bharati, Subrato/U-2601-2019
   Kose, Utku/C-8683-2009}},
ORCID-Numbers = {{Bharati, Subrato/0000-0001-8849-4313
   Kose, Utku/0000-0002-9652-6415}},
Number-of-Cited-References = {{120}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{12}},
Usage-Count-Since-2013 = {{12}},
Journal-ISO = {{J. Inf. Assur. Secur.}},
Doc-Delivery-Number = {{TC3XI}},
Unique-ID = {{WOS:000668574400001}},
DA = {{2021-11-23}},
}

@article{ WOS:000391049000005,
Author = {Sharma, Rupam Kumar and Kalita, Hemanta Kr. and Issac, Biju},
Title = {{Plant based Biologically Inspired Intrusion Response Mechanism : An
   insight into the proposed model PIRIDS}},
Journal = {{JOURNAL OF INFORMATION ASSURANCE AND SECURITY}},
Year = {{2016}},
Volume = {{11}},
Number = {{6}},
Pages = {{340-347}},
Abstract = {{Intrusion Detection Systems (IDS) are one of the primary components in
   keeping a network secure. They are classified into different forms based
   on the nature of their functionality such as Host based IDS, Network
   based IDS and Anomaly based IDS. However, Literature survey portrays
   different evasion techniques of IDS. Thus it is always important to
   study the responsive behavior of IDS after such failures. The state of
   the art shows that much work have been done on IDS on contrary to little
   on Intrusion Response System (IRS). In this paper we propose a model of
   IRS based on the inspiration derived from the functioning of defense and
   response mechanism in plants. The proposed model is the first attempt of
   its kind with the objective to develop an efficient response mechanism
   in a network subsequent to the failure of IDS, adopting plants as a
   source of inspiration.}},
Publisher = {{DYNAMIC PUBLISHERS, INC}},
Address = {{PO BOX 48654, ATLANTA, GA 30362-0654 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Sharma, RK (Corresponding Author), North Eastern Hills Univ, Sch Technl, Shillong, Meghalayn, India.
   Sharma, Rupam Kumar, North Eastern Hills Univ, Sch Technl, Shillong, Meghalayn, India.
   Kalita, Hemanta Kr., North Eastern Hills Univ, Sch Technol, Shillong, Meghalayn, India.
   Issac, Biju, Univ Teesside, Sch Comp, Middlesbrough, Cleveland, England.}},
ISSN = {{1554-1010}},
EISSN = {{1554-1029}},
Keywords = {{Intrusion Detection System; Intrusion Response System; Bio-inspired;
   nature; biologically inspired; Learning; KDD99; Anomaly Detection; Host
   Intrusion System; Network Security; bot nets; bot; SAR; plants defense}},
Keywords-Plus = {{INNATE IMMUNITY; EVOLUTION; DEFENSE}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems}},
Author-Email = {{sun1\_rupam1@yahoo.com
   kalita.hemanta@gmail.com
   bijuissac@gmail.com}},
ResearcherID-Numbers = {{Kalita, Hemanta Kumar/AAS-3829-2021
   Issac, Biju/AAA-3802-2019
   Issac, Biju/E-2465-2011}},
ORCID-Numbers = {{Issac, Biju/0000-0002-1109-8715}},
Number-of-Cited-References = {{28}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{J. Inf. Assur. Secur.}},
Doc-Delivery-Number = {{EG4YD}},
Unique-ID = {{WOS:000391049000005}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000529790700114,
Author = {Cheng, Adriel},
Editor = {{Chakrabarti, S and Saha, HN}},
Title = {{PAC-GAN: Packet Generation of Network Traffic using Generative
   Adversarial Networks}},
Booktitle = {{2019 IEEE 10TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE
   COMMUNICATION CONFERENCE (IEMCON)}},
Year = {{2019}},
Pages = {{728-734}},
Note = {{IEEE 10th Annual Information Technology, Electronics and Mobile
   Communication Conference (IEMCON), Univ British Columbia, CANADA, OCT
   17-19, 2019}},
Organization = {{IEEE; IEEE Vancouver Sect; Inst Engn \& Management; Univ Engn \&
   Management}},
Abstract = {{Generative adversarial networks (GANs) have proven extremely successful
   in creating artificial yet highly realistic media data such as images,
   text, audio and videos. In this paper, we adapt and describe a GAN
   method for creating network traffic data at the IP packet layer.
   Generating realistic network traffic is essential for development and
   testing of techniques in Cyber and network security related tasks such
   as anomaly or intrusion detection. The effectiveness of such network
   monitoring techniques depends directly on the traffic data. Despite
   this, traffic generation is often considered low priority because it is
   difficult. Using GANs, we prototype and prove feasibility in the
   generation of real traffic flows such as ICMP Pings, DNS queries, and
   HTTP web requests. Using Convolutional Neural Network (CNN) GANs, we
   propose an alternative encoding of network traffic data into the CNN
   model. Experiments show our generated traffic can be successfully
   transmitted through the Internet eliciting desired responses from the
   network. The work described in this paper is the first step in
   demonstrating successful creation and transmission of network traffic;
   it forms the basis for future GAN based traffic generators at scale.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Cheng, A (Corresponding Author), Def Sci \& Technol, Dept Def, Cyber \& Elect Warfare Div, Canberra, ACT, Australia.
   Cheng, Adriel, Def Sci \& Technol, Dept Def, Cyber \& Elect Warfare Div, Canberra, ACT, Australia.}},
ISBN = {{978-1-7281-2530-5}},
Keywords = {{Deep-Learning; Generative Adversarial Networks; Convolutional Neural
   Networks; Test Generation; Traffic Generation; Packet Encoding; Network
   Security; Cyber Security}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{Adriel.Cheng@dst.defence.gov.au}},
Number-of-Cited-References = {{13}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BO8XK}},
Unique-ID = {{WOS:000529790700114}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000682965600043,
Author = {Wu, Jiachen and Li, Jipeng and Wang, Yan and Zhang, Yanru and Zhou,
   Yingjie},
Book-Group-Author = {{IEEE Comp Soc}},
Title = {{Optimal Defense Strategy against Evasion Attacks}},
Booktitle = {{2020 16TH INTERNATIONAL CONFERENCE ON MOBILITY, SENSING AND NETWORKING
   (MSN 2020)}},
Year = {{2020}},
Pages = {{323-329}},
Note = {{16th IEEE International Conference on Mobility, Sensing and Networking
   (MSN), ELECTR NETWORK, DEC 17-19, 2020}},
Organization = {{IEEE; IEEE Comp Soc; MDPI, Sensors Journal}},
Abstract = {{Recent detection method based on machine learning demonstrates
   significant advantages against varieties of network attacks, and has
   been widely deployed in cloud applications. However, novel attacks such
   as Advanced Persistent Threats (APTs) could evade detection of the
   intrusion detection system, which may lead to serious data leakage in
   cloud. Existing methods studied the countermeasures to defend against
   evasion attacks. However, a cloud service provider (CSP) also have to
   balance between its expect revenue and the security risk of system with
   limited resources. In this paper, we present the CSP's optimal strategy
   for effective and safety operation, in which the CSP decides the size of
   users that the cloud service will provide and whether enhanced
   countermeasures will be conducted for discovering the possible evasion
   attacks. While the CSP tries to optimize its profit by carefully making
   a two-step decision of the defense plan and service scale, the attacker
   considers its expected revenue to launch evasion attacks or not. To
   obtain insights of such a highly coupled system, we consider a system
   with one CSP and one attacker with two attack choices of whether to
   launch an evasion attack. We propose a two-stage Stackelberg game, in
   which the CSP acts as the leader who decides the defense plan and
   service scale in Stage I, and the attacker acts as the follower that
   determines whether to make evasion attacks in Stage II. We derive the
   Nash Equilibrium by analyzing the attacker's choices under different
   scenarios that the CSP selects. Then, we provide the CSP's optimal
   strategies to maximize its revenue. The simulation results help to
   better understand the CSP's optimal solutions under different
   situations.}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Zhou, YJ (Corresponding Author), Sichuan Univ, Coll Comp Sci, Chengdu, Sichuan, Peoples R China.
   Zhou, YJ (Corresponding Author), Sichuan Univ, Inst Networks \& Intelligent Syst, Chengdu, Sichuan, Peoples R China.
   Wu, Jiachen; Zhou, Yingjie, Sichuan Univ, Coll Comp Sci, Chengdu, Sichuan, Peoples R China.
   Li, Jipeng; Wang, Yan; Zhang, Yanru, Univ Elect Sci \& Technol China, Sch Comp Sci \& Engn, IntelliGame Lab, Chengdu, Sichuan, Peoples R China.
   Zhou, Yingjie, Sichuan Univ, Inst Networks \& Intelligent Syst, Chengdu, Sichuan, Peoples R China.}},
DOI = {{10.1109/MSN50589.2020.00060}},
ISBN = {{978-1-7281-9916-0}},
Keywords = {{evasion attacks; cloud service; game theory; Stackelberg game; Nash
   Equilibrium}},
Keywords-Plus = {{GAME}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Theory \&
   Methods; Engineering, Electrical \& Electronic; Telecommunications}},
Author-Email = {{cheneywooo@gmail.com
   jeeperly@std.uestc.edu.cn
   yanbo1990@uestc.edu.cn
   yanruzhang@uestc.edu.cn
   yjzhou09@gmail.com}},
Funding-Acknowledgement = {{National Natural Science Foundation of China (NSFC)National Natural
   Science Foundation of China (NSFC) {[}61801315, 62001085]; UESTC Funds
   for Outstanding Talents {[}A1098531023601183]}},
Funding-Text = {{This work was partly supported by National Natural Science Foundation of
   China (NSFC) with grant number 61801315 and 62001085, and UESTC Funds
   for Outstanding Talents A1098531023601183.}},
Number-of-Cited-References = {{14}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BS0IY}},
Unique-ID = {{WOS:000682965600043}},
DA = {{2021-11-23}},
}

@article{ WOS:000316788900006,
Author = {Ghosh, Abhrajit and Gottlieb, Yitzchak M. and Naidu, Aditya and Vashist,
   Akshay and Poylisher, Alexander and Kubota, Ayumu and Sawaya, Yukiko and
   Yamada, Akira},
Title = {{Managing High Volume Data for Network Attack Detection Using Real-Time
   Flow Filtering}},
Journal = {{CHINA COMMUNICATIONS}},
Year = {{2013}},
Volume = {{10}},
Number = {{3}},
Pages = {{56-66}},
Month = {{MAR}},
Abstract = {{In this paper, we present Real-Time Flow Filter (RTFF) -a system that
   adopts a middle ground between coarse-grained volume anomaly detection
   and deep packet inspection. RTFF was designed with the goal of scaling
   to high volume data feeds that are common in large Tier-1 ISP networks
   and providing rich, timely information on observed attacks. It is a
   software solution that is designed to run on off-the-shelf hardware
   platforms and incorporates a scalable data processing architecture along
   with lightweight analysis algorithms that make it suitable for
   deployment in large networks. RTFF also makes use of state of the art
   machine learning algorithms to construct attack models that can be used
   to detect as well as predict attacks.}},
Publisher = {{CHINA INST COMMUNICATIONS}},
Address = {{NO 13 WEST CHANG AN AVENUE, BEIJING, 00000, PEOPLES R CHINA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Ghosh, A (Corresponding Author), Appl Commun Sci, 150 Mt Airy Rd, Basking Ridge, NJ 07920 USA.
   Ghosh, Abhrajit; Gottlieb, Yitzchak M.; Naidu, Aditya; Vashist, Akshay; Poylisher, Alexander, Appl Commun Sci, Basking Ridge, NJ 07920 USA.
   Kubota, Ayumu; Sawaya, Yukiko; Yamada, Akira, KDDI R\&D Labs, Saitama 3568502, Japan.}},
DOI = {{10.1109/CC.2013.6488830}},
ISSN = {{1673-5447}},
Keywords = {{network security; intrusion detection; scaling}},
Research-Areas = {{Telecommunications}},
Web-of-Science-Categories  = {{Telecommunications}},
Number-of-Cited-References = {{11}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{15}},
Journal-ISO = {{China Commun.}},
Doc-Delivery-Number = {{115CB}},
Unique-ID = {{WOS:000316788900006}},
DA = {{2021-11-23}},
}

@article{ WOS:000315861800001,
Author = {Goernitz, Nico and Kloft, Marius and Rieck, Konrad and Brefeld, Ulf},
Title = {{Toward Supervised Anomaly Detection}},
Journal = {{JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH}},
Year = {{2013}},
Volume = {{46}},
Pages = {{235-262}},
Abstract = {{Anomaly detection is being regarded as an unsupervised learning task as
   anomalies stem from adversarial or unlikely events with unknown
   distributions. However, the predictive performance of purely
   unsupervised anomaly detection often fails to match the required
   detection rates in many tasks and there exists a need for labeled data
   to guide the model generation. Our first contribution shows that
   classical semi-supervised approaches, originating from a supervised
   classifier, are inappropriate and hardly detect new and unknown
   anomalies. We argue that semi-supervised anomaly detection needs to
   ground on the unsupervised learning paradigm and devise a novel
   algorithm that meets this requirement. Although being intrinsically
   non-convex, we further show that the optimization problem has a convex
   equivalent under relatively mild assumptions. Additionally, we propose
   an active learning strategy to automatically filter candidates for
   labeling. In an empirical study on network intrusion detection data, we
   observe that the proposed learning methodology requires much less
   labeled data than the state-of-the-art, while achieving higher detection
   accuracies.}},
Publisher = {{AI ACCESS FOUNDATION}},
Address = {{USC INFORMATION SCIENCES INST, 4676 ADMIRALITY WAY, MARINA DEL REY, CA
   90292-6695 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Gornitz, N (Corresponding Author), Tech Univ Berlin, Machine Learning Lab, Franklinstr 28-29, Berlin, Germany.
   Goernitz, Nico; Kloft, Marius, Tech Univ Berlin, Machine Learning Lab, Berlin, Germany.
   Goernitz, Nico; Kloft, Marius, Mem Sloan Kettering Canc Ctr, Computat Biol Ctr, New York, NY 10021 USA.
   Rieck, Konrad, Univ Gottingen, Dep Comp Sci, D-37077 Gottingen, Germany.
   Brefeld, Ulf, Tech Univ Darmstadt, D-64289 Darmstadt, Germany.
   Brefeld, Ulf, German Inst Int Educ Res, D-60486 Frankfurt, Germany.}},
DOI = {{10.1613/jair.3623}},
ISSN = {{1076-9757}},
EISSN = {{1943-5037}},
Keywords-Plus = {{NOVELTY DETECTION; SUPPORT; CLASSIFICATION; ATTACKS; SYSTEM; SVMS}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{NICO.GOERNITZ@TU-BERLIN.DE
   KLOFT@TU-BERLIN.DE
   KONRAD.RIECK@UNI-GOETTINGEN.DE
   BREFELD@KMA.INFORMATIK.TU-DARMSTADT.DE}},
ORCID-Numbers = {{Rieck, Konrad/0000-0002-5054-8758}},
Funding-Acknowledgement = {{German Bundesministerium fur Bildung und Forschung (BMBF) under the
   project PROSECFederal Ministry of Education \& Research (BMBF) {[}FKZ
   01BY1145]; FP7-ICT Programme of the European Community, under the
   PASCAL2 Network of Excellence; German National Science Foundation
   (DFG)German Research Foundation (DFG) {[}GA 1615/1-1, MU 987/6-1, MU
   987/11-1, RA 1894/11]; German Academic Exchange Service (DAAD)Deutscher
   Akademischer Austausch Dienst (DAAD); German Research Foundation
   (DFG)German Research Foundation (DFG); Ministry of Education, Science,
   and Technology, through the National Research Foundation of Korea
   {[}R31-10008]}},
Funding-Text = {{The authors are very grateful to Klaus-Robert Muller for comments that
   helped improving the manuscript. This work was supported in part by the
   German Bundesministerium fur Bildung und Forschung (BMBF) under the
   project PROSEC (FKZ 01BY1145), by the FP7-ICT Programme of the European
   Community, under the PASCAL2 Network of Excellence, and by the German
   National Science Foundation (DFG) under GA 1615/1-1, MU 987/6-1, MU
   987/11-1 and RA 1894/11. Furthermore, Marius Kloft acknowledges a PhD
   scholarship by the German Academic Exchange Service (DAAD) and a
   postdoctoral fellowship by the German Research Foundation (DFG) as well
   as funding by the Ministry of Education, Science, and Technology,
   through the National Research Foundation of Korea under Grant R31-10008.
   A part of the work was done while Marius Kloft was with Computer Science
   Division and Department of Statistics, University of California,
   Berkeley, CA 94720-1758, USA.}},
Number-of-Cited-References = {{62}},
Times-Cited = {{94}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{9}},
Journal-ISO = {{J. Artif. Intell. Res.}},
Doc-Delivery-Number = {{102RN}},
Unique-ID = {{WOS:000315861800001}},
OA = {{Green Submitted, gold}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000509775000017,
Author = {Tong, Liang and Li, Bo and Hajaj, Chen and Xiao, Chaowei and Zhang, Ning
   and Vorobeychik, Yevgeniy},
Book-Group-Author = {{USENIX Assoc}},
Title = {{Improving Robustness of ML Classifiers against Realizable Evasion
   Attacks Using Conserved Features}},
Booktitle = {{PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM}},
Year = {{2019}},
Pages = {{285-302}},
Note = {{28th USENIX Security Symposium, Santa Clara, CA, AUG 14-16, 2019}},
Organization = {{USENIX Assoc; Facebook; Microsoft; Intel; Avast; Baidu; Cisco; Google;
   King Abdullah Univ Sci \& Technol; Paloalto Networks; Dropbox; IBM Res;
   Kaspersky; USC Viterbi, Sch Engn, Informat Sci Inst; Bloomberg; NetApp}},
Abstract = {{Machine learning (ML) techniques are increasingly common in security
   applications, such as malware and intrusion detection. However, ML
   models are often susceptible to evasion attacks, in which an adversary
   makes changes to the input (such as malware) in order to avoid being
   detected. A conventional approach to evaluate ML robustness to such
   attacks, as well as to design robust ML, is by considering simplified
   feature-space models of attacks, where the attacker changes ML features
   directly to effect evasion, while minimizing or constraining the
   magnitude of this change. We investigate the effectiveness of this
   approach to designing robust ML in the face of attacks that can be
   realized in actual malware (realizable attacks). We demonstrate that in
   the context of structure-based PDF malware detection, such techniques
   appear to have limited effectiveness, but they are effective with
   content-based detectors. In either case, we show that augmenting the
   feature space models with conserved features (those that cannot be
   unilaterally modified without compromising malicious functionality)
   significantly improves performance. Finally, we show that feature space
   models enable generalized robustness when faced with a variety of
   realizable attacks, as compared to classifiers which are tuned to be
   robust to a specific realizable attack.}},
Publisher = {{USENIX ASSOC}},
Address = {{SUITE 215, 2560 NINTH ST, BERKELEY, CA 94710 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Tong, L (Corresponding Author), Washington Univ, St Louis, MO 14263 USA.
   Tong, Liang; Zhang, Ning; Vorobeychik, Yevgeniy, Washington Univ, St Louis, MO 14263 USA.
   Li, Bo, UIUC, Champaign, IL USA.
   Hajaj, Chen, Ariel Univ, Ariel, Israel.
   Xiao, Chaowei, Univ Michigan, Ann Arbor, MI 48109 USA.}},
ISBN = {{978-1-939133-06-9}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems}},
ResearcherID-Numbers = {{Xiao, Chaowei/AAT-8772-2021
   Hajaj, Chen/L-1843-2019}},
ORCID-Numbers = {{Xiao, Chaowei/0000-0002-7043-4926
   Hajaj, Chen/0000-0001-9940-5654}},
Funding-Acknowledgement = {{Army Research Office {[}W911NF1610069]; NSF CAREER awardNational Science
   Foundation (NSF)NSF - Office of the Director (OD) {[}IIS-1649972]}},
Funding-Text = {{This work was partially supported by the Army Research Office
   (W911NF1610069) and NSF CAREER award (IIS-1649972).}},
Number-of-Cited-References = {{46}},
Times-Cited = {{8}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BO3AB}},
Unique-ID = {{WOS:000509775000017}},
DA = {{2021-11-23}},
}

@article{ WOS:000672542400015,
Author = {Okutan, Ahmet and Yang, Shanchieh Jay},
Title = {{ASSERT: attack synthesis and separation with entropy redistribution
   towards predictive cyber defense}},
Journal = {{CYBERSECURITY}},
Year = {{2019}},
Volume = {{2}},
Number = {{1}},
Abstract = {{The sophistication of cyberattacks penetrating into enterprise networks
   has called for predictive defense beyond intrusion detection, where
   different attack strategies can be analyzed and used to anticipate next
   malicious actions, especially the unusual ones. Unfortunately,
   traditional predictive analytics or machine learning techniques that
   require training data of known attack strategies are not practical,
   given the scarcity of representative data and the evolving nature of
   cyberattacks. This paper describes the design and evaluation of a novel
   automated system, ASSERT, which continuously synthesizes and separates
   cyberattack behavior models to enable better prediction of future
   actions. It takes streaming malicious event evidences as inputs,
   abstracts them to edge-based behavior aggregates, and associates the
   edges to attack models, where each represents a unique and collective
   attack behavior. It follows a dynamic Bayesian-based model generation
   approach to determine when a new attack behavior is present, and creates
   new attack models by maximizing a cluster validity index. ASSERT
   generates empirical attack models by separating evidences and use the
   generated models to predict unseen future incidents. It continuously
   evaluates the quality of the model separation and triggers a
   re-clustering process when needed. Through the use of 2017 National
   Collegiate Penetration Testing Competition data, this work demonstrates
   the effectiveness of ASSERT in terms of the quality of the generated
   empirical models and the predictability of future actions using the
   models.}},
Publisher = {{SPRINGERNATURE}},
Address = {{CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Okutan, A (Corresponding Author), Rochester Inst Technol, Comp Engn, Rochester, NY 14623 USA.
   Okutan, Ahmet; Yang, Shanchieh Jay, Rochester Inst Technol, Comp Engn, Rochester, NY 14623 USA.}},
DOI = {{10.1186/s42400-019-0032-0}},
Article-Number = {{15}},
EISSN = {{2523-3246}},
Keywords = {{Cyber security; Dynamic bayesian classifier; Clustering KL divergence}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering}},
Author-Email = {{axoeec@rit.edu}},
ORCID-Numbers = {{, Ahmet/0000-0001-8990-6869}},
Funding-Acknowledgement = {{NSFNational Science Foundation (NSF) {[}1526383]}},
Funding-Text = {{This research is supported by NSF Award \#1526383.}},
Number-of-Cited-References = {{45}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{Cybersecurity}},
Doc-Delivery-Number = {{VK2XP}},
Unique-ID = {{WOS:000672542400015}},
OA = {{gold}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000671077600217,
Author = {Xu, Jinghui and Wen, Yu and Yang, Chun and Meng, Dan},
Editor = {{Wang, GJ and Ko, R and Bhuiyan, MZA and Pan, Y}},
Title = {{An Approach for Poisoning Attacks against RNN-Based Cyber Anomaly
   Detection}},
Booktitle = {{2020 IEEE 19TH INTERNATIONAL CONFERENCE ON TRUST, SECURITY AND PRIVACY
   IN COMPUTING AND COMMUNICATIONS (TRUSTCOM 2020)}},
Series = {{IEEE International Conference on Trust Security and Privacy in Computing
   and Communications}},
Year = {{2020}},
Pages = {{1680-1687}},
Note = {{19th IEEE International Conference on Trust, Security and Privacy in
   Computing and Communications (IEEE TrustCom), Guangzhou, PEOPLES R
   CHINA, DEC 29-JAN 01, 2020-2021}},
Organization = {{IEEE; IEEE Comp Soc}},
Abstract = {{In the face of the increasingly complex Internet environment, the
   traditional intrusion detection system is difficult to cope with the
   unknown variety of attacks. People hope to find reliable anomaly
   detection technology to help improve the security of cyberspace. The
   rapid development of artificial intelligence technology provides new
   development opportunities for anomaly detection technology, and the
   anomaly detection system based on deep learning performs well in some
   studies. However, neural networks are highly dependent on data quality,
   and a small number of poisoned samples injected into the data set will
   have a huge impact on the results. The online abnormal threat detection
   system based on deep learning is likely to be attacked by poisoning due
   to the need for continuous data collection and training. We propose a
   poisoning attack method using adversarial samples to resist the anomaly
   detection system based on an unsupervised deep neural network, which can
   destroy the neural network with as few samples as possible. We verified
   the effectiveness of poisoning attacks on the network security data set
   of los alamos national laboratory and further demonstrated its
   generality on other abnormal detection data set.}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Wen, Y (Corresponding Author), Chinese Acad Sci, Inst Informat Engn, Beijing, Peoples R China.
   Xu, Jinghui; Wen, Yu; Yang, Chun; Meng, Dan, Chinese Acad Sci, Inst Informat Engn, Beijing, Peoples R China.
   Xu, Jinghui; Yang, Chun, Univ Chinese Acad Sci, Sch Cyber Secur, Beijing, Peoples R China.}},
DOI = {{10.1109/TrustCom50675.2020.00231}},
ISSN = {{2324-898X}},
ISBN = {{978-1-6654-0392-4}},
Keywords = {{anomaly detection; unsupervised recurrent neural network; adversarial
   sample; poisoning attack}},
Keywords-Plus = {{MODEL}},
Research-Areas = {{Computer Science; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Hardware \& Architecture; Computer Science,
   Information Systems; Computer Science, Theory \& Methods;
   Telecommunications}},
Author-Email = {{wenyu@iie.ac.cn}},
Funding-Acknowledgement = {{Strategic Priority Research Program of CAS}},
Funding-Text = {{This work was supported by the Strategic Priority Research Program of
   CAS, Grant No.XDC02010300. Thanks to Aaron Tuor et al. open source the
   Safekti - an anomaly detection system based on the RNN language model.
   Thanks also to Los Alamos National Laboratory's published anomaly
   detection data set.}},
Number-of-Cited-References = {{37}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BR8DU}},
Unique-ID = {{WOS:000671077600217}},
DA = {{2021-11-23}},
}

@article{ WOS:000401542700010,
Author = {Mishra, Preeti and Pilli, Emmanuel S. and Varadharajan, Vijay and
   Tupakula, Udaya},
Title = {{VAED: VMI-assisted evasion detection approach for infrastructure as a
   service cloud}},
Journal = {{CONCURRENCY AND COMPUTATION-PRACTICE \& EXPERIENCE}},
Year = {{2017}},
Volume = {{29}},
Number = {{12}},
Month = {{JUN 25}},
Abstract = {{Cloud computing provides on demand provisioning of resources mostly
   offered as Infrastructure as a Service. The flexibility in services has
   opened doors for attackers. Research has been performed to detect
   various malware in the last few years. However, modern malware are
   advanced enough to detect the presence of virtualization environment,
   security analyzer, or even the hypervisor by observing the
   virtualization-specific information such as virtual processor features,
   timing features, etc. The malware exhibit evasive nature and can fool
   existing security solutions by performing modern antidetection tactics.
   In this paper, we propose an approach named as VMI-assisted evasion
   detection (VAED), deployed at virtual machine monitor, to detect the
   evasion-based malware attacks. The VAED is based on learning the program
   semantic of evasive malware. It uses system call dependency graph
   approach generated using Markov Chain principle and keeps track of
   system call ordering with transition probability distribution between
   each pair system calls. It uses software break point injection technique
   to extract the system call traces of evasive malware samples, which is
   free from any modification in hardware-specific values. Hence, it is
   secure from evasion attempts. The VAED is validated over evasive samples
   collected from the University of California on request, and results seem
   to be promising.}},
Publisher = {{WILEY}},
Address = {{111 RIVER ST, HOBOKEN 07030-5774, NJ USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Pilli, ES (Corresponding Author), Malaviya Natl Inst Technol, Dept Comp Sci \& Engn, JLN Marg, Jaipur 302017, Rajasthan, India.
   Mishra, Preeti; Pilli, Emmanuel S., Malaviya Natl Inst Technol, Dept Comp Sci \& Engn, JLN Marg, Jaipur 302017, Rajasthan, India.
   Varadharajan, Vijay; Tupakula, Udaya, Macquarie Univ, Dept Comp, Fac Sci \& Engn, Sydney, NSW, Australia.}},
DOI = {{10.1002/cpe.4133}},
Article-Number = {{e4133}},
ISSN = {{1532-0626}},
EISSN = {{1532-0634}},
Keywords = {{cloud security; intrusion detection; system call analysis; virtual
   machine introspection}},
Keywords-Plus = {{MALWARE DETECTION; SYSTEM}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Software Engineering; Computer Science, Theory \&
   Methods}},
Author-Email = {{espilli.cse@mnit.ac.in}},
ResearcherID-Numbers = {{Pilli, Emmanuel/H-7984-2017
   Mishra, Preeti/R-7933-2017
   }},
ORCID-Numbers = {{Pilli, Emmanuel/0000-0002-6056-1147
   Varadharajan, Vijay/0000-0002-3621-9114
   Mishra, Preeti/0000-0002-3809-0887
   TUPAKULA, Udaya/0000-0001-5048-9797}},
Number-of-Cited-References = {{63}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{11}},
Journal-ISO = {{Concurr. Comput.-Pract. Exp.}},
Doc-Delivery-Number = {{EV1WZ}},
Unique-ID = {{WOS:000401542700010}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000519271301015,
Author = {Liu, Yunyu and Xia, Zhiyang and Yi, Ping and Yao, Yao and Xie, Tiantian
   and Wang, Wei and Zhu, Ting},
Book-Group-Author = {{IEEE}},
Title = {{GENPass: A General Deep Learning Model for Password Guessing with PCFG
   Rules and Adversarial Generation}},
Booktitle = {{2018 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS (ICC)}},
Series = {{IEEE International Conference on Communications}},
Year = {{2018}},
Note = {{IEEE International Conference on Communications (ICC) / Workshop on
   Integrating UAVs into 5G, Kansas City, MO, MAY 20-24, 2018}},
Organization = {{IEEE; Sprint; Qualcomm; Cisco; Huawei; Natl Instruments; Nokia; Comput
   Res Assoc Women; GARMIN; Juniper Networks; NSF}},
Abstract = {{Password has become today's dominant method of authentication in social
   network. While the brute-force attack methods, such as HashCat and John
   the Ripper, are unpractical, the research then switches to the password
   guess. The stateof-the-art approaches, such as Markov Model and
   probabilistic context-free grammars(PCFG), are all based on statistical
   probability. These approaches have a low matching rate. The methods on
   neural network have been proved more accurate and practical for password
   guessing than traditional methods. However, a raw neural network model
   is not qualified for cross-sites attack since each data set has its own
   features.
   This paper proposes a general deep learning model for password guessing,
   called GENPass. GENPass can learn features from several data sets and
   ensure the output wordlist high accuracy in different data sets by using
   adversarial generation. The password generator of GENPass is
   PCFG+LSTM(PL), where LSTM is a kind of Recurrent Neural Network. We
   combine neural network with PCFG because we found people were used to
   set their passwords with meaningful strings. Compared with LSTM, PL
   increased the matching rate by 16\%-30\% in the cross-sites tests when
   learning from a single dataset. GENPass uses several PL models to learn
   datasets and generate passwords. The result shows that the matching rate
   of GENPass is 20\% higher than that of simply mixing those datasets in
   the cross-sites test.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Liu, YY (Corresponding Author), Shanghai Jiao Tong Univ, Sch Cyber Secur, Shanghai Key Lab Integrated Adm Technol Informat, Shanghai 200240, Peoples R China.
   Liu, Yunyu; Xia, Zhiyang; Yi, Ping, Shanghai Jiao Tong Univ, Sch Cyber Secur, Shanghai Key Lab Integrated Adm Technol Informat, Shanghai 200240, Peoples R China.
   Yao, Yao; Xie, Tiantian; Wang, Wei; Zhu, Ting, Univ Maryland Baltimore Cty, Dept Comp Sci \& Elect Engn, Baltimore, MD 21250 USA.}},
ISSN = {{1550-3607}},
ISBN = {{978-1-5386-3180-5}},
Keywords-Plus = {{INTRUSION DETECTION; NETWORKS}},
Research-Areas = {{Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic; Telecommunications}},
Funding-Acknowledgement = {{National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}61571290,61431008]; NSFNational Science
   Foundation (NSF) {[}1652669, 1539047]}},
Funding-Text = {{National Natural Science Foundation of China (61571290,61431008), NSF
   grants 1652669 and 1539047.}},
Number-of-Cited-References = {{29}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BO5ZI}},
Unique-ID = {{WOS:000519271301015}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000674762400030,
Author = {Dutta, Preetam K. and Ryan, Gabriel and Zieba, Aleksander and Stolfo,
   Salvatore J.},
Book-Group-Author = {{IEEE Comp Soc}},
Title = {{Simulated User Bots: Real Time Testing of Insider Threat Detection
   Systems}},
Booktitle = {{2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018)}},
Year = {{2018}},
Pages = {{228-236}},
Note = {{IEEE Symposium on Security and Privacy Workshops (SPW), San Francisco,
   CA, MAY 24, 2018}},
Organization = {{IEEE; IEEE Comp Soc}},
Abstract = {{The insider threat is one of the most serious security problems faced by
   modern organizations. High profile cases demonstrate the serious
   consequences of successful attacks. The problem has been studied for
   many years, leading to a number of technologies and products that have
   been deployed widely in government and commercial enterprises. A
   fundamental question is: how well do these systems work? How may they be
   tested? How expensive are widely deployed monitoring infrastructures in
   terms of computational cost?
   Measurement of real systems, which are dynamic in nature, encounter
   unknown configuration bugs and have sensitivities to the vagaries of
   human nature and adversarial behavior, requires a formal means to
   continuously test and evaluate deployed detection systems. We present a
   framework to deploy in situ simulated user bots (SUBs) that can emulate
   the actions of real users. By creating a user account and by running a
   host in the enterprise network, a SUB can be introduced into an
   enterprise system that runs at a realistic pace and does not interfere
   with normal operations. Infusing malicious behavior into the SUB should
   be detected by the insider threat monitoring infrastructure. The SUB
   framework can be controlled to explore the limits of deployed systems
   and to test the effectiveness of insider evasion tactics, especially low
   and slow behaviors.
   We demonstrate our framework in a synthetic ecosystem as well as in a
   live enterprise deployment. We created a synthetic environment of users
   based on data collected in a West Point cadet study. Various machine
   learning based intrusion detection algorithms are used to validate the
   ability of the SUB framework to generate both normal and malicious
   users. In a live University network, we launched a number of attacks on
   its intrusion detection system and showcased the ability to devise
   malicious users. In addition, we further deployed low and slow attacks
   that perform malicious actions over an extended period of time and
   demonstrate how even a large enterprise is ill equipped to combat such
   attacks.}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Dutta, PK (Corresponding Author), Columbia Univ, Dept Comp Sci, New York, NY 10027 USA.
   Dutta, Preetam K.; Ryan, Gabriel; Zieba, Aleksander; Stolfo, Salvatore J., Columbia Univ, Dept Comp Sci, New York, NY 10027 USA.}},
DOI = {{10.1109/SPW.2018.00038}},
ISBN = {{978-0-7695-6349-7}},
Keywords-Plus = {{SUPPORT}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Theory \&
   Methods}},
Author-Email = {{pkd2108@columbia.edu
   gr2547@columbia.edu
   arz2116@columbia.edu
   sjs11@columbia.edu}},
Funding-Acknowledgement = {{IARPA SCITE Program, Scientific advances to Continuous Insider Threat
   Evaluation}},
Funding-Text = {{We would like to thank Professor Ross for supporting us with
   computational resources to develop and test our neural networks. Also,
   we would like to thank Professor Geambasu and her PhD student Mathias
   Lecuyer for their insights into the LSTM architecture. This work was
   supported as part of the IARPA SCITE Program, Scientific advances to
   Continuous Insider Threat Evaluation. Professor Stolfo is the founder of
   Allure Security Technology, Inc.}},
Number-of-Cited-References = {{26}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BR8ZO}},
Unique-ID = {{WOS:000674762400030}},
OA = {{Bronze, Green Submitted}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000593830400092,
Author = {Luo, Zhengping and Hou, Tao and Nguyen, Tung Thanh and Zeng, Hui and Lu,
   Zhuo},
Book-Group-Author = {{IEEE}},
Title = {{Log Analytics in HPC: A Data-driven Reinforcement Learning Framework}},
Booktitle = {{IEEE INFOCOM 2020 - IEEE CONFERENCE ON COMPUTER COMMUNICATIONS WORKSHOPS
   (INFOCOM WKSHPS)}},
Series = {{IEEE Conference on Computer Communications Workshops}},
Year = {{2020}},
Pages = {{550-555}},
Note = {{IEEE Conference on Computer Communications (IEEE INFOCOM), ELECTR
   NETWORK, JUL 06-09, 2020}},
Organization = {{IEEE}},
Abstract = {{High Performance Computing (HPC) has been employed in many fields such
   as aerospace, weather forecast, numerical simulation, scientific
   research etc. Security of HPC, especially anomaly/intrusion detection,
   has attracted many attentions in recent years. Given the heavily
   instrumented property of HPC systems, logs become an effective and
   direct data source that can be utilized to evaluate the system status,
   further, to detect anomalies or malicious users. In this paper, we offer
   a novel perspective, treating the anomaly detection in HPC as a
   sequential decision process, and further applying reinforcement learning
   techniques to learn the state transition process, based on which we
   build a framework named as ReLog to detect anomalies or malicious users.
   Besides, a common challenge of employing machine learning techniques is
   lacking sufficient data, we provide a generative adversarial network
   (GAN)-based solution to generate sufficient training data in HPC. The
   experimental validations are conducted based on real-world collected MPI
   logs, and our results demonstrate a 93\% of detection accuracy on the
   collected dataset.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Luo, ZP (Corresponding Author), Univ S Florida, Tampa, FL 33620 USA.
   Luo, Zhengping; Hou, Tao; Lu, Zhuo, Univ S Florida, Tampa, FL 33620 USA.
   Nguyen, Tung Thanh; Zeng, Hui, Intelligent Automat Inc, Rockville, MD USA.}},
ISSN = {{2159-4228}},
ISBN = {{978-1-7281-8695-5}},
Keywords = {{High performance computing; security; reinforcement learning; defenses
   and attacks; log analytics}},
Research-Areas = {{Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic; Telecommunications}},
Author-Email = {{zhengpingluo@mail.usf.edu
   taohou@mail.usf.edu
   tnguyen@i-a-i.com
   hzeng@i-a-i.com
   zhuolu@usf.edu}},
Funding-Acknowledgement = {{U.S. Department of Energy, Office of ScienceUnited States Department of
   Energy (DOE) {[}DE-SC0017180]}},
Funding-Text = {{This material is based upon work supported by the U.S. Department of
   Energy, Office of Science under Award Number DE-SC0017180.}},
Number-of-Cited-References = {{26}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BQ4QE}},
Unique-ID = {{WOS:000593830400092}},
DA = {{2021-11-23}},
}

@article{ WOS:000436148400007,
Author = {Xuan Dau Hoang and Quynh Chi Nguyen},
Title = {{Botnet Detection Based On Machine Learning Techniques Using DNS Query
   Data}},
Journal = {{FUTURE INTERNET}},
Year = {{2018}},
Volume = {{10}},
Number = {{5}},
Month = {{MAY}},
Abstract = {{In recent years, botnets have become one of the major threats to
   information security because they have been constantly evolving in both
   size and sophistication. A number of botnet detection measures, such as
   honeynet-based and Intrusion Detection System (IDS)-based, have been
   proposed. However, IDS-based solutions that use signatures seem to be
   ineffective because recent botnets are equipped with sophisticated code
   update and evasion techniques. A number of studies have shown that
   abnormal botnet detection methods are more effective than
   signature-based methods because anomaly-based botnet detection methods
   do not require pre-built botnet signatures and hence they have the
   capability to detect new or unknown botnets. In this direction, this
   paper proposes a botnet detection model based on machine learning using
   Domain Name Service query data and evaluates its effectiveness using
   popular machine learning techniques. Experimental results show that
   machine learning algorithms can be used effectively in botnet detection
   and the random forest algorithm produces the best overall detection
   accuracy of over 90\%.}},
Publisher = {{MDPI}},
Address = {{ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Hoang, XD (Corresponding Author), Posts \& Telecommun Inst Technol, Hanoi 100000, Vietnam.
   Xuan Dau Hoang, Posts \& Telecommun Inst Technol, Hanoi 100000, Vietnam.
   Quynh Chi Nguyen, Samsung SVMC, Hanoi 100000, Vietnam.}},
DOI = {{10.3390/fi10050043}},
Article-Number = {{43}},
ISSN = {{1999-5903}},
Keywords = {{botnet detection; botnet detection model; machine learning-based botnet
   detection; domain generation algorithm botnet detection; fast flux
   botnet detection}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems}},
Author-Email = {{dauhx@ptit.edu.vn
   nguyenquynhchi2204@gmail.com}},
ORCID-Numbers = {{Hoang, Dau/0000-0002-2566-7704}},
Funding-Acknowledgement = {{Ministry of Science and Technology, Vietnam {[}KC.01.05/16-20]}},
Funding-Text = {{This research was funded by the Ministry of Science and Technology,
   Vietnam grant number KC.01.05/16-20.}},
Number-of-Cited-References = {{16}},
Times-Cited = {{16}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{8}},
Journal-ISO = {{Future Internet}},
Doc-Delivery-Number = {{GK4QQ}},
Unique-ID = {{WOS:000436148400007}},
OA = {{gold, Green Submitted}},
DA = {{2021-11-23}},
}

@article{ WOS:000495739500001,
Author = {Lee, JooHwa and Park, KeeHyun},
Title = {{GAN-based imbalanced data intrusion detection system}},
Journal = {{PERSONAL AND UBIQUITOUS COMPUTING}},
Year = {{2021}},
Volume = {{25}},
Number = {{1, SI}},
Pages = {{121-128}},
Month = {{FEB}},
Abstract = {{According to the development of deep learning technologies, a wide
   variety of research is being performed to detect intrusion data by using
   vast amounts of data. Although deep learning performs more accurately
   than machine learning algorithms when learning large amounts of data,
   the performance declines significantly in the case of learning from
   imbalanced data. And, while there are many studies on imbalanced data,
   most have weaknesses that can result in data loss or overfitting. The
   purpose of this study is to solve data imbalance by using the Generative
   Adversarial Networks (GAN) model, which is an unsupervised learning
   method of deep learning which generates new virtual data similar to the
   existing data. It also proposed a model that would be classified as
   Random Forest to identify detection performance after addressing data
   imbalances based on a GAN. The results of the experiment showed that the
   performance of the model proposed in this paper was better than the
   model classified without addressing the imbalance of data. In addition,
   it was found that the performance of the model proposed in this paper
   was excellent when compared with other models that were previously used
   widely for the data imbalance problem.}},
Publisher = {{SPRINGER LONDON LTD}},
Address = {{236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Park, K (Corresponding Author), Keimyung Univ, Dept Comp Engn, 1095 Dalgubeol Daero, Daegu, South Korea.
   Lee, JooHwa; Park, KeeHyun, Keimyung Univ, Dept Comp Engn, 1095 Dalgubeol Daero, Daegu, South Korea.}},
DOI = {{10.1007/s00779-019-01332-y}},
Early Access Date = {{NOV 2019}},
ISSN = {{1617-4909}},
EISSN = {{1617-4917}},
Keywords = {{GAN; IDS; Imbalanced data; Deep learning; Resampling}},
Research-Areas = {{Computer Science; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Telecommunications}},
Author-Email = {{yezi1004@gmail.com
   khp@kmu.ac.kr}},
Funding-Acknowledgement = {{Basic Science Research Programs through the National Research Foundation
   of Korea (NRF) - Ministry of Education, Science and Technology
   {[}NRF-2018R1D1A1B07043982]}},
Funding-Text = {{This research was supported by the Basic Science Research Programs
   through the National Research Foundation of Korea (NRF), funded by the
   Ministry of Education, Science and Technology (No.
   NRF-2018R1D1A1B07043982)}},
Number-of-Cited-References = {{21}},
Times-Cited = {{9}},
Usage-Count-Last-180-days = {{10}},
Usage-Count-Since-2013 = {{42}},
Journal-ISO = {{Pers. Ubiquitous Comput.}},
Doc-Delivery-Number = {{RC7BR}},
Unique-ID = {{WOS:000495739500001}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000524690200223,
Author = {Choi, Changhee and Shin, Sunguk and Lee, Inseop},
Book-Group-Author = {{IEEE}},
Title = {{Opcode Sequence Amplifier using Sequence Generative Adversarial Networks}},
Booktitle = {{2019 10TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION
   TECHNOLOGY CONVERGENCE (ICTC): ICT CONVERGENCE LEADING THE AUTONOMOUS
   FUTURE}},
Series = {{International Conference on Information and Communication Technology
   Convergence}},
Year = {{2019}},
Pages = {{968-970}},
Note = {{10th International Conference on Information and Communication
   Technology Convergence (ICTC) - ICT Convergence Leading the Autonomous
   Future, Jeju, SOUTH KOREA, OCT 16-18, 2019}},
Organization = {{Korean Inst Commun \& Informat Sci; IEEE Commun Soc; IEICE Commun Soc;
   Minist Sci \& ICT; Elect \& Telecommunicat Res Inst; Korean Federat Sci
   \& Technol Soc; Samsung Elect; SK Telecom; LG Elect; LGU+; KT; LG
   ERICSSON; Huawei; Qualcomm; SOLID; Korea Elect Technol Inst;
   Telecommunicat Technol Assoc; ICT Convergence Korea Forum; Multi Screen
   Serv Forum Soc Safety Syst Forum; Jeju Convent \& Visitors Bur; Jeju
   Special Self Governing Prov}},
Abstract = {{Weapon systems and military networks are threatened by increased cyber
   attacks. In case of usual cyber attack, commercial grade defence systems
   are available. Because of speciality of military system, cyber attacks
   for them are also special and the number is extremely small. For machine
   learning based defence system, the shortage of malware samples is
   critical problem. To solve this problem, we proposed the new method for
   amplifying opcode sequence which is part of the malware and used for
   malware detection. We first extract opcode sequences from malwares and
   benign portable files. To make them meaningful and easy to learn, whole
   opcode sequence is split into several blocks, called OPSEN(OPcode
   SENtence), using special delimiters. Considering that opcode sequence is
   not a numerical data but a sequence of instruction, we used SeqGAN with
   stochastic policy in reinforcement learning and policy gradient. The
   experimental results shows that the proposed amplified opcode sequence
   help to improve the detection rate.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Choi, C (Corresponding Author), Agcy Def Dev, Daejeon, South Korea.
   Choi, Changhee; Shin, Sunguk; Lee, Inseop, Agcy Def Dev, Daejeon, South Korea.}},
ISSN = {{2162-1233}},
ISBN = {{978-1-7281-0893-3}},
Keywords = {{Opcode; malware; GAN; SeqGAN; malware family}},
Keywords-Plus = {{INTRUSION DETECTION}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{changhee84@add.re.kr
   ssw1419@add.re.kr
   dlstjq0711@add.re.kr}},
Number-of-Cited-References = {{19}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BO7KM}},
Unique-ID = {{WOS:000524690200223}},
DA = {{2021-11-23}},
}

@article{ WOS:000524748500061,
Author = {Li, Gangqiang and Wu, Sissi Xiaoxiao and Zhang, Shengli and Li, Qiang},
Title = {{Neural Networks-Aided Insider Attack Detection for the Average Consensus
   Algorithm}},
Journal = {{IEEE ACCESS}},
Year = {{2020}},
Volume = {{8}},
Pages = {{51871-51883}},
Abstract = {{To support the big-data processing needs of large-scale deployments of
   smart devices, there is significant interest in moving from
   cloud-computing to multi-agent (fog-computing) models, given these
   algorithms scalability and self-healing properties with respect to nodes
   and link failures. However, these algorithms are often based on the
   average consensus primitive, which is, unfortunately, vulnerable to data
   injection attacks. Recognizing this challenge, this work proposes three
   novel methods for detecting and localizing adversarial nodes using
   neural network (NN) models. The methods proposed are based on fully
   distributed algorithms, wherein each node locally updates its local
   states by exchanging information with its neighbors without supervision.
   Compared to the state-of-the-art, the proposed approach leverages the
   automatic learning characteristics of NN to reduce the dependence on
   pre-designed models and human expertise in complex internal attack
   scenarios. Simulation results show that the NN-based methods can
   significantly improve the attacker detection and localization
   performance.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Wu, SX (Corresponding Author), Shenzhen Univ, Coll Elect \& Informat Engn, Shenzhen 518060, Peoples R China.
   Wu, SX (Corresponding Author), Peng Cheng Lab, Shenzhen 518055, Peoples R China.
   Li, Gangqiang; Wu, Sissi Xiaoxiao; Zhang, Shengli, Shenzhen Univ, Coll Elect \& Informat Engn, Shenzhen 518060, Peoples R China.
   Wu, Sissi Xiaoxiao; Li, Qiang, Peng Cheng Lab, Shenzhen 518055, Peoples R China.
   Li, Qiang, UESTC, Sch Informat \& Commun Engn, Chengdu 611731, Peoples R China.}},
DOI = {{10.1109/ACCESS.2020.2978458}},
ISSN = {{2169-3536}},
Keywords = {{Artificial neural networks; Peer-to-peer computing; Protocols; Cloud
   computing; Intrusion detection; Simulation; Gossip algorithm; average
   consensus; neural network (NN); insider attack; detection and
   localization}},
Keywords-Plus = {{DISTRIBUTED RESOURCE-ALLOCATION; INTRUSION DETECTION; INTERNET}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{xxwu.eesissi@szu.edu.cn}},
ORCID-Numbers = {{Li, Gangqiang/0000-0002-7363-1060
   Zhang, Shengli/0000-0002-7937-5870}},
Funding-Acknowledgement = {{National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}61701315]; Shenzhen Technology Research
   and Development Fund {[}JCYJ20170817101149906]; Shenzhen University
   Launch Fund {[}2018018]}},
Funding-Text = {{This work was supported in part by the National Natural Science
   Foundation of China under Grant 61701315, in part by the Shenzhen
   Technology Research and Development Fund under Grant
   JCYJ20170817101149906, and in part by the Shenzhen University Launch
   Fund under Grant 2018018.}},
Number-of-Cited-References = {{42}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{6}},
Journal-ISO = {{IEEE Access}},
Doc-Delivery-Number = {{LB6MS}},
Unique-ID = {{WOS:000524748500061}},
OA = {{gold}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000662964400051,
Author = {Tian, Yunzhe and Wang, Yingdi and Tong, Endong and Niu, Wenjia and
   Chang, Liang and Chen, Qi Alfred and Li, Gang and Liu, Jiqiang},
Book-Group-Author = {{IEEE COMP SOC}},
Title = {{Exploring Data Correlation between Feature Pairs for Generating
   Constraint-based Adversarial Examples}},
Booktitle = {{2020 IEEE 26TH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED
   SYSTEMS (ICPADS)}},
Series = {{International Conference on Parallel and Distributed Systems -
   Proceedings}},
Year = {{2020}},
Pages = {{430-437}},
Note = {{26th IEEE International Conference on Parallel and Distributed Systems
   (IEEE ICPADS), ELECTR NETWORK, DEC 02-04, 2020}},
Organization = {{IEEE; IEEE Comp Soc}},
Abstract = {{Adversarial example (AE), an input that is modified slightly to cause a
   machine learning system to produce erroneous outputs, has seen
   significant studies recently. Unfortunately, the fine data perturbation
   of AE ignores to keep potential data correlations between feature pairs.
   Thus, such AE will be easily filtered by configuring data correlations
   as basic filtering rules. In this paper, avoiding not to be filtered as
   well as causing false classification, an advanced robust AE generation
   attack is proposed. We first define four basic data correlations called
   strict linear constraint, approximate linear constraint, addition
   boundary constraint and zero multiplication constraint. Then, based on
   embedding multiple data correlations into one constraint matrix from the
   Pearson analysis, our approach can enable a Hadamard product of the
   constraint matrix and the sign of gradient matrix to craft
   perturbations, keeping consistent data correlations. Experimental
   results on intrusion detection system (IDS) indicate: 1) Nearly all AEs
   from original IFGSM are invalid by filtering according to basic data
   correlations; 2) In our method, AEs against a targeted DNN-based
   classifier can achieve an attack success rate of 99\%, with transfer
   attack ability of 94\% average success rate to attack other different
   mainstream classifiers.}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Tong, ED; Niu, WJ (Corresponding Author), Beijing Jiaotong Univ, Beijing Key Lab Secur \& Privacy Intelligent Trans, Beijing, Peoples R China.
   Tian, Yunzhe; Wang, Yingdi; Tong, Endong; Niu, Wenjia; Liu, Jiqiang, Beijing Jiaotong Univ, Beijing Key Lab Secur \& Privacy Intelligent Trans, Beijing, Peoples R China.
   Chang, Liang, Guilin Univ Elect Technol, Guangxi Key Lab Trusted Software, Guilin, Peoples R China.
   Chen, Qi Alfred, Univ Calif Irvine, Irvine, CA USA.
   Li, Gang, Deakin Univ, Australia Ctr Cyber Secur Res \& Innovat, Geelong, Vic, Australia.}},
DOI = {{10.1109/ICPADS51040.2020.00064}},
ISSN = {{1521-9097}},
ISBN = {{978-1-7281-9074-7}},
Keywords = {{deep neural network; adversarial examples generation; pearson
   correlation coefficient; feature constraints}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Hardware \& Architecture; Computer Science, Theory \&
   Methods; Engineering, Electrical \& Electronic}},
Author-Email = {{tianyunzhe@bjtu.edu.cn
   wangyingdi@bjtu.edu.cn
   edtong@bjtu.edu.cn
   niuwj@bitu.edu.cn
   changl@guet.edu.cn
   alfchen@umich.edu
   gang.li@deakin.edu.au
   jqliu@bjtu.edu.cn}},
ORCID-Numbers = {{tong, endong/0000-0003-0348-2108}},
Funding-Acknowledgement = {{National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}61972025, 61802389, 61672092, U1811264,
   61966009]; Fundamental Research Funds for the Central Universities of
   ChinaFundamental Research Funds for the Central Universities
   {[}2018JBZ103, 2019RC008]; Science and Technology on Information
   Assurance Laboratory {[}614200103011711]; Guangxi Key Laboratory of
   Trusted Software {[}KX201902]}},
Funding-Text = {{This research is supported by the National Natural Science Foundation of
   China (61972025, 61802389, 61672092, U1811264, 61966009), the
   Fundamental Research Funds for the Central Universities of China
   (2018JBZ103, No.2019RC008), Science and Technology on Information
   Assurance Laboratory (614200103011711), Guangxi Key Laboratory of
   Trusted Software (KX201902).}},
Number-of-Cited-References = {{25}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BR6QS}},
Unique-ID = {{WOS:000662964400051}},
DA = {{2021-11-23}},
}

@article{ WOS:000314529000008,
Author = {Kloft, Marius and Laskov, Pavel},
Title = {{Security Analysis of Online Centroid Anomaly Detection}},
Journal = {{JOURNAL OF MACHINE LEARNING RESEARCH}},
Year = {{2012}},
Volume = {{13}},
Pages = {{3681-3724}},
Month = {{DEC}},
Abstract = {{Security issues are crucial in a number of machine learning
   applications, especially in scenarios dealing with human activity rather
   than natural phenomena (e. g., information ranking, spam detection,
   malware detection, etc.). In such cases, learning algorithms may have to
   cope with manipulated data aimed at hampering decision making. Although
   some previous work addressed the issue of handling malicious data in the
   context of supervised learning, very little is known about the behavior
   of anomaly detection methods in such scenarios. In this contribution,(1)
   we analyze the performance of a particular method-online centroid
   anomaly detection-in the presence of adversarial noise. Our analysis
   addresses the following security-related issues: formalization of
   learning and attack processes, derivation of an optimal attack, and
   analysis of attack efficiency and limitations. We derive bounds on the
   effectiveness of a poisoning attack against centroid anomaly detection
   under different conditions: attacker's full or limited control over the
   traffic and bounded false positive rate. Our bounds show that whereas a
   poisoning attack can be effectively staged in the unconstrained case, it
   can be made arbitrarily difficult (a strict upper bound on the
   attacker's gain) if external constraints are properly used. Our
   experimental evaluation, carried out on real traces of HTTP and exploit
   traffic, confirms the tightness of our theoretical bounds and the
   practicality of our protection mechanisms.}},
Publisher = {{MICROTOME PUBL}},
Address = {{31 GIBBS ST, BROOKLINE, MA 02446 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Kloft, M (Corresponding Author), Tech Univ Berlin, Machine Learing Grp, Franklinstr 28-29, D-10587 Berlin, Germany.
   Kloft, Marius, Tech Univ Berlin, Machine Learing Grp, D-10587 Berlin, Germany.
   Laskov, Pavel, Univ Tubingen, Wilhelm Schickard Inst Comp Sci, D-72076 Tubingen, Germany.
   Kloft, Marius, Korea Univ, Dept Brain \& Cognit Engn, Seoul 136713, South Korea.}},
ISSN = {{1532-4435}},
Keywords = {{anomaly detection; adversarial; security analysis; support vector data
   description; computer security; network intrusion detection}},
Keywords-Plus = {{NOVELTY DETECTION; CLASSIFICATION; SUPPORT; ATTACKS; SELF}},
Research-Areas = {{Automation \& Control Systems; Computer Science}},
Web-of-Science-Categories  = {{Automation \& Control Systems; Computer Science, Artificial Intelligence}},
Author-Email = {{KLOFT@TU-BERLIN.DE
   PAVEL.LASKOV@UNI-TUEBINGEN.DE}},
Funding-Acknowledgement = {{German Bundesministerium fur Bildung und Forschung (BMBF)Federal
   Ministry of Education \& Research (BMBF) {[}FKZ 01-IS07007A]; European
   Community, under the PASCAL2 Network of ExcellenceEuropean Commission
   {[}ICT-216886]; National Research Foundation of Germany (DFG); German
   Science Foundation under DFGGerman Research Foundation (DFG) {[}MU
   987/6-1, RA 1894/1-1]; World Class University Program through the
   National Research Foundation of Korea; Korean Ministry of Education,
   Science, and TechnologyMinistry of Education, Science and Technology,
   Republic of Korea {[}R31-10008]}},
Funding-Text = {{The authors greatly thank Peter Bartlett, Ulf Brefeld, Vojtech Franc,
   and Klaus-Robert Muller, Konrad Rieck for fruitful discussions and
   helpful comments. Furthermore we thank Konrad Rieck for providing the
   network traffic and an anonymous reviewer for many helpful comments.
   Most of the work was done when MK and PL were supported by the German
   Bundesministerium fur Bildung und Forschung (BMBF) under the project
   REMIND (FKZ 01-IS07007A), and by the FP7-ICT Programme of the European
   Community, under the PASCAL2 Network of Excellence, ICT-216886. MK
   achknowledges a postdoctorial fellowship and PL a Heisenberg fellowship,
   both by the National Research Foundation of Germany (DFG). MK is also
   supported by the German Science Foundation under DFG MU 987/6-1, RA
   1894/1-1, and by the World Class University Program through the National
   Research Foundation of Korea funded by the Korean Ministry of Education,
   Science, and Technology, under Grant R31-10008.}},
Number-of-Cited-References = {{70}},
Times-Cited = {{31}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{8}},
Journal-ISO = {{J. Mach. Learn. Res.}},
Doc-Delivery-Number = {{084HI}},
Unique-ID = {{WOS:000314529000008}},
DA = {{2021-11-23}},
}

@article{ WOS:000614686200001,
Author = {Becue, Adrien and Praca, Isabel and Gama, Joao},
Title = {{Artificial intelligence, cyber-threats and Industry 4.0: challenges and
   opportunities}},
Journal = {{ARTIFICIAL INTELLIGENCE REVIEW}},
Year = {{2021}},
Volume = {{54}},
Number = {{5}},
Pages = {{3849-3886}},
Month = {{JUN}},
Abstract = {{This survey paper discusses opportunities and threats of using
   artificial intelligence (AI) technology in the manufacturing sector with
   consideration for offensive and defensive uses of such technology. It
   starts with an introduction of Industry 4.0 concept and an understanding
   of AI use in this context. Then provides elements of security principles
   and detection techniques applied to operational technology (OT) which
   forms the main attack surface of manufacturing systems. As some
   intrusion detection systems (IDS) already involve some AI-based
   techniques, we focus on existing machine-learning and data-mining based
   techniques in use for intrusion detection. This article presents the
   major strengths and weaknesses of the main techniques in use. We also
   discuss an assessment of their relevance for application to OT, from the
   manufacturer point of view. Another part of the paper introduces the
   essential drivers and principles of Industry 4.0, providing insights on
   the advent of AI in manufacturing systems as well as an understanding of
   the new set of challenges it implies. AI-based techniques for production
   monitoring, optimisation and control are proposed with insights on
   several application cases. The related technical, operational and
   security challenges are discussed and an understanding of the impact of
   such transition on current security practices is then provided in more
   details. The final part of the report further develops a vision of
   security challenges for Industry 4.0. It addresses aspects of
   orchestration of distributed detection techniques, introduces an
   approach to adversarial/robust AI development and concludes with
   human-machine behaviour monitoring requirements.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Becue, A (Corresponding Author), Airbus Cybersecur, Elancourt, France.
   Becue, Adrien, Airbus Cybersecur, Elancourt, France.
   Praca, Isabel, ISEP GECAD, Porto, Portugal.
   Gama, Joao, INESC TEC, Porto, Portugal.}},
DOI = {{10.1007/s10462-020-09942-2}},
Early Access Date = {{FEB 2021}},
ISSN = {{0269-2821}},
EISSN = {{1573-7462}},
Keywords = {{Intrusion detection systems; Security; Industry 4; 0; Artificial
   intelligence}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{adrien.becue@airbus.com
   icp@iscp.ipp.pt
   jgama@fep.up.pt}},
ResearcherID-Numbers = {{Gama, Joao/A-2070-2008
   Praca, Isabel/K-8430-2014
   }},
ORCID-Numbers = {{Gama, Joao/0000-0003-3357-1195
   Praca, Isabel/0000-0002-2519-9859
   BECUE, Adrien/0000-0002-9328-9581}},
Number-of-Cited-References = {{177}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{15}},
Usage-Count-Since-2013 = {{36}},
Journal-ISO = {{Artif. Intell. Rev.}},
Doc-Delivery-Number = {{SH1BR}},
Unique-ID = {{WOS:000614686200001}},
DA = {{2021-11-23}},
}

@article{ WOS:000628912100008,
Author = {Wahab, Omar Abdel and Bentahar, Jamal and Otrok, Hadi and Mourad, Azzam},
Title = {{Resource-Aware Detection and Defense System against Multi-Type Attacks
   in the Cloud: Repeated Bayesian Stackelberg Game}},
Journal = {{IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING}},
Year = {{2021}},
Volume = {{18}},
Number = {{2}},
Pages = {{605-622}},
Month = {{MAR-APR}},
Abstract = {{Cloud-based systems are subject to various attack types launched by
   Virtual Machines (VMs) manipulated by attackers having different goals
   and skills. The existing detection and defense mechanisms might be
   suitable for simple attack environments but become ineffective when the
   system faces advanced attack scenarios wherein simultaneous attacks of
   different types are involved. This is because these mechanisms overlook
   the attackers' strategies in the detection system's design, ignore the
   system's resource constraints, and lack sufficient knowledge about the
   attackers' types and abilities. To address these shortcomings, we
   propose a repeated Bayesian Stackelberg game consisting of the following
   phases: risk assessment framework that identifies the VMs' risk levels,
   live-migration-based defense mechanism that protects services from being
   successful targets for attackers, machine-learning-based technique that
   collects malicious data from VMs using honeypots and employs one-class
   Support Vector Machine to learn the attackers' types distributions, and
   resource-aware Bayesian Stackelberg game that provides the hypervisor
   with the detection load's optimal distribution over VMs that maximizes
   the detection of multi-type attacks. Experiments conducted using
   Amazon's datacenter and Amazon Web Services honeypot data reveal that
   our solution maximizes the detection, minimizes the number of attacked
   services, and runs efficiently compared to the state-of-the-art
   detection and defense strategies, namely Collabra, probabilistic
   migration, Stackelberg, maxmin, and fair allocation.}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Wahab, OA (Corresponding Author), Univ Quebec Outaouais, Dept Comp Sci \& Engn, Gatineau, PQ J8X 3X7, Canada.
   Wahab, Omar Abdel, Univ Quebec Outaouais, Dept Comp Sci \& Engn, Gatineau, PQ J8X 3X7, Canada.
   Bentahar, Jamal, Concordia Univ, Concordia Inst Informat Syst Engn, Montreal, PQ H3G 1M8, Canada.
   Otrok, Hadi, Khalifa Univ Sci Technol \& Res, Dept ECE, Abu Dhabi, U Arab Emirates.
   Mourad, Azzam, Lebanese Amer Univ, Dept Math \& Comp Sci, Beirut, Lebanon.}},
DOI = {{10.1109/TDSC.2019.2907946}},
ISSN = {{1545-5971}},
EISSN = {{1941-0018}},
Keywords = {{Cloud computing; Monitoring; Bayes methods; Games; Virtual machine
   monitors; Intrusion detection; Adversarial artificial intelligence;
   intrusion detection; game theory; machine learning; data-driven
   optimization; Moving Target Defense (MTD); honeypots; security risk
   assessment}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Hardware \& Architecture; Computer Science,
   Information Systems; Computer Science, Software Engineering}},
Author-Email = {{omar.abdulwahab@uqo.ca
   bentahar@ciise.concordia.ca
   Hadi.Otrok@kustar.ac.ae
   azzam.mourad@lau.edu.lb}},
ResearcherID-Numbers = {{Mourad, Azzam/A-7204-2008
   }},
ORCID-Numbers = {{Mourad, Azzam/0000-0001-9434-5322
   Otrok, Hadi/0000-0002-9574-5384
   Bentahar, Jamal/0000-0002-3136-4849
   Abdel Wahab, Omar/0000-0002-3991-4673}},
Funding-Acknowledgement = {{Fonds de Recherche du Quebec-Nature et Technologie (FRQNT); Natural
   Sciences and Engineering Research Council of Canada (NSERC)Natural
   Sciences and Engineering Research Council of Canada (NSERC); Khalifa
   University of Science, Technology \& Research (KUSTAR); Associated
   Research Unit of the National Council for Scientific Research
   (CNRS-Lebanon); Lebanese American University}},
Funding-Text = {{This work has been supported by the Fonds de Recherche du Quebec-Nature
   et Technologie (FRQNT), Natural Sciences and Engineering Research
   Council of Canada (NSERC), Khalifa University of Science, Technology \&
   Research (KUSTAR), Associated Research Unit of the National Council for
   Scientific Research (CNRS-Lebanon), and Lebanese American University.}},
Number-of-Cited-References = {{30}},
Times-Cited = {{14}},
Usage-Count-Last-180-days = {{13}},
Usage-Count-Since-2013 = {{16}},
Journal-ISO = {{IEEE Trans. Dependable Secur. Comput.}},
Doc-Delivery-Number = {{QW8QE}},
Unique-ID = {{WOS:000628912100008}},
ESI-Highly-Cited-Paper = {{Y}},
ESI-Hot-Paper = {{N}},
DA = {{2021-11-23}},
}

@article{ WOS:000621951100001,
Author = {Yang, Jin and Liang, Gang and Li, Beibei and Wen, Guozhu and Gao, Tianyu},
Title = {{A deep-learning- and reinforcement-learning-based system for encrypted
   network malicious traffic detection}},
Journal = {{ELECTRONICS LETTERS}},
Year = {{2021}},
Volume = {{57}},
Number = {{9}},
Pages = {{363-365}},
Month = {{APR}},
Abstract = {{Traditional network intrusion detection methods lack the ability of
   automatic feature extraction for encrypted network malicious traffic,
   and thus, the detection rates are low. Moreover, the means of this
   malicious traffic are concealed, and the key malicious features are
   usually hidden in many normal data packets, so fewer encrypted malicious
   traffic samples can be captured. This easily leads to insufficient
   system training, low detection rate, and high false alarm rate. This
   letter proposes an encrypted network malicious traffic detection model
   based on deep learning, in which automatic feature extraction is
   performed against encrypted network malicious traffic. The proposed
   model has self-learning and self-adaption abilities. Furthermore, a
   sample generation method of encrypted traffic based on deep Q-networks
   and deep convolution generative adversarial networks is proposed, in
   which new samples are learned from the training samples of encrypted
   traffic and solves problems, such as insufficient original training
   samples and unbalanced samples. In a validation experiment, the proposed
   model could distinguish between normal and abnormal encrypted network
   traffic, and the accuracy rate reached 99.94\%. Experimental results
   show that the proposed model in this letter can provide a new and better
   solution for an encrypted network malicious traffic detection system.}},
Publisher = {{WILEY}},
Address = {{111 RIVER ST, HOBOKEN 07030-5774, NJ USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Liang, G (Corresponding Author), Sichuan Univ, Sch Cyber Sci \& Engn, Chengdu, Peoples R China.
   Yang, Jin; Liang, Gang; Li, Beibei; Wen, Guozhu; Gao, Tianyu, Sichuan Univ, Sch Cyber Sci \& Engn, Chengdu, Peoples R China.}},
DOI = {{10.1049/ell2.12125}},
Early Access Date = {{FEB 2021}},
ISSN = {{0013-5194}},
EISSN = {{1350-911X}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{253960818@qq.com}},
Funding-Acknowledgement = {{National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}61872254]; Key Laboratory of Information
   Network Security of Ministry of Public Security {[}C20606]; Sichuan
   Science and Technology Program {[}21CXRC0103]; Sichuan University Zigong
   Joint Project {[}2020CDZG-18]}},
Funding-Text = {{This work was supported in part by the National Natural Science
   Foundation of China under Grant 61872254, in part by the Key Laboratory
   of Information Network Security of Ministry of Public Security under
   Grant C20606, in part by the Sichuan Science and Technology Program
   under Grant 21CXRC0103, and in part by the Sichuan University Zigong
   Joint Project under Grant 2020CDZG-18.}},
Number-of-Cited-References = {{10}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{12}},
Usage-Count-Since-2013 = {{18}},
Journal-ISO = {{Electron. Lett.}},
Doc-Delivery-Number = {{RT3KK}},
Unique-ID = {{WOS:000621951100001}},
OA = {{gold}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000465799100224,
Author = {Avelino, Joy Nathalie and Mora, Carmi Anne Loren and Balaquit, Jessica
   Patricia},
Book-Group-Author = {{IEEE}},
Title = {{Ahead of the Curve: A Deeper Understanding of Network Threats Through
   Machine Learning}},
Booktitle = {{PROCEEDINGS OF TENCON 2018 - 2018 IEEE REGION 10 CONFERENCE}},
Series = {{TENCON IEEE Region 10 Conference Proceedings}},
Year = {{2018}},
Pages = {{1172-1176}},
Note = {{IEEE-Region-10 Conference (IEEE TENCON), IEEE Reg 10, SOUTH KOREA, OCT
   28-31, 2018}},
Organization = {{IEEE Korea Council; IEIE; KICS; KIEE; KIEES; KIPS}},
Abstract = {{The role of big data and machine intelligence in the field of
   information security is gaining importance as malicious attackers use
   evasion techniques (polymorphism, encryption, obfuscation) to bypass
   signature-based detection. As most threats propagate through the
   network, it is important to have proactive techniques to discover an
   infection before it damages a computer.
   This paper will examine how header-based information as well as other
   characteristics in the HTTP network traffic can be used to train a
   machine learning model to capture malicious behavior.
   Network streams tagged as malicious are preprocessed and clustered. It
   has been found that features in the raw byte stream augmented with
   handcrafted features are useful in learning the characteristics of
   network threats.
   In specific clusters formed, it is possible to identify certain threats
   targeting a specific server, or if there are characteristics that can be
   observed in the injected code for exploit detection.
   Clustering malicious network traffic leads to a better understanding of
   protection against these types of threats, identification of connected
   malware campaigns, and insight on future trends.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Avelino, JN (Corresponding Author), Trend Micro Inc, Core Technol, Pasig, Philippines.
   Avelino, Joy Nathalie; Mora, Carmi Anne Loren; Balaquit, Jessica Patricia, Trend Micro Inc, Core Technol, Pasig, Philippines.}},
ISSN = {{2159-3442}},
ISBN = {{978-1-5386-5457-6}},
Keywords = {{Computational Intelligence; Machine Learning; Big Data Applications;
   Information Security; Network Security; Intrusion Detection}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{Joy\_Avelino@trendmicro.com
   Carmi\_Mora@trendmicro.com
   Jessica\_Balaquit@trendmicro.com}},
Funding-Acknowledgement = {{Trend Micro Incorporated}},
Funding-Text = {{We would like to acknowledge the following people who gave their support
   in this project from Trend Micro Incorporated: Threat Research Director
   Mary Ong; Head of Machine Learning Group Brian Cayanan; Jameson Ong;
   machine learning consultants Jon Oliver, Abraham Camba, Jayson Pryde,
   Robert Tacbad, and Joa Suico; the Quality Assurance Team that pioneered
   this project; and the Deep Discovery Inspector Group that provided their
   threat expertise in network analysis.}},
Number-of-Cited-References = {{30}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BM5ZA}},
Unique-ID = {{WOS:000465799100224}},
DA = {{2021-11-23}},
}

@article{ WOS:000428582200001,
Author = {Liu, Qiang and Li, Pan and Zhao, Wentao and Cai, Wei and Yu, Shui and
   Leung, Victor C. M.},
Title = {{A Survey on Security Threats and Defensive Techniques of Machine
   Learning: A Data Driven View}},
Journal = {{IEEE ACCESS}},
Year = {{2018}},
Volume = {{6}},
Pages = {{12103-12117}},
Abstract = {{Machine learning is one of the most prevailing techniques in computer
   science, and it has been widely applied in image processing, natural
   language processing, pattern recognition, cybersecurity, and other
   fields. Regardless of successful applications of machine learning
   algorithms in many scenarios, e.g., facial recognition, malware
   detection, automatic driving, and intrusion detection, these algorithms
   and corresponding training data are vulnerable to a variety of security
   threats, inducing a significant performance decrease. Hence, it is vital
   to call for further attention regarding security threats and
   corresponding defensive techniques of machine learning, which motivates
   a comprehensive survey in this paper. Until now, researchers from
   academia and industry have found out many security threats against a
   variety of learning algorithms, including naive Bayes, logistic
   regression, decision tree, support vector machine (SVM), principle
   component analysis, clustering, and prevailing deep neural networks.
   Thus, we revisit existing security threats and give a systematic survey
   on them from two aspects, the training phase and the testing/inferring
   phase. After that, we categorize current defensive techniques of machine
   learning into four groups: security assessment mechanisms,
   countermeasures in the training phase, those in the testing or inferring
   phase, data security, and privacy. Finally, we provide five notable
   trends in the research on security threats and defensive techniques of
   machine learning, which are worth doing in-depth studies in future.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Liu, Q (Corresponding Author), Natl Univ Def Technol, Coll Comp, Changsha 410073, Hunan, Peoples R China.
   Liu, Qiang; Li, Pan; Zhao, Wentao, Natl Univ Def Technol, Coll Comp, Changsha 410073, Hunan, Peoples R China.
   Cai, Wei; Leung, Victor C. M., Univ British Columbia, Dept Elect \& Comp Engn, Vancouver, BC V6T 1Z4, Canada.
   Yu, Shui, Deakin Univ Melbourne, Sch Informat Technol, Burwood Campus, Burwood, Vic 3125, Australia.}},
DOI = {{10.1109/ACCESS.2018.2805680}},
ISSN = {{2169-3536}},
Keywords = {{Machine learning; adversarial samples; security threats; defensive
   techniques}},
Keywords-Plus = {{ATTACKS}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{qiangliu06@nudt.edu.cn}},
ResearcherID-Numbers = {{Leung, Victor C.M./X-6823-2019
   }},
ORCID-Numbers = {{Leung, Victor C.M./0000-0003-3529-2640
   Yu, Shui/0000-0003-4485-6743}},
Funding-Acknowledgement = {{National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) {[}61702539, 61728201]}},
Funding-Text = {{This work was supported by the National Natural Science Foundation of
   China under Grant 61702539 and Grant 61728201.}},
Number-of-Cited-References = {{111}},
Times-Cited = {{116}},
Usage-Count-Last-180-days = {{8}},
Usage-Count-Since-2013 = {{55}},
Journal-ISO = {{IEEE Access}},
Doc-Delivery-Number = {{GA8IC}},
Unique-ID = {{WOS:000428582200001}},
OA = {{gold}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000707024100151,
Author = {Chkirbene, Zina and Ben Abdallah, Habib and Hassine, Kawther and Hamila,
   Ridha and Erbad, Aiman},
Book-Group-Author = {{IEEE}},
Title = {{Data Augmentation for Intrusion Detection and Classification in Cloud
   Networks}},
Booktitle = {{IWCMC 2021: 2021 17TH INTERNATIONAL WIRELESS COMMUNICATIONS \& MOBILE
   COMPUTING CONFERENCE (IWCMC)}},
Series = {{International Wireless Communications and Mobile Computing Conference}},
Year = {{2021}},
Pages = {{831-836}},
Note = {{17th IEEE International Wireless Communications and Mobile Computing
   Conference (IEEE IWCMC), ELECTR NETWORK, JUN 28-JUL 02, 2021}},
Organization = {{IEEE; IEEE Harbin Sect; IEEE Commun Soc Harbin Chapter; Huawei}},
Abstract = {{Cloud computing is a paradigm that provides multiple services over the
   internet with high flexibility in a cost-effective way. However, the
   growth of cloud-based services comes with major security issues.
   Recently, machine learning techniques are gaining much interest in
   security applications as they exhibit fast processing capabilities with
   real-time predictions. One major challenge in the implementation of
   these techniques is the available training data for each new potential
   attack category. In this paper, we propose a new model for secure
   network based on machine learning algorithms. The proposed model ensures
   better learning of minority classes using Generative Adversarial Network
   (GAN) architecture. In particular, the new model optimizes the GAN
   parameter including the number of inner learning steps for the
   discriminator to balance the training datasets. Then, the optimized GAN
   generates highly informative ``like real{''} instances to be appended to
   the original data which improve the detection of the classes with
   relatively small training data. Our experimental results show that the
   proposed approach enhances the overall classification performance and
   detection accuracy even for the rarely detectable classes for both UNSW
   and NSL-KDD datasets. The simulation results show also that the proposed
   model could detect better the network attacks compared to the
   state-of-art techniques.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Chkirbene, Z (Corresponding Author), Qatar Univ, Coll Engn, Doha, Qatar.
   Chkirbene, Zina; Hassine, Kawther; Hamila, Ridha, Qatar Univ, Coll Engn, Doha, Qatar.
   Ben Abdallah, Habib, Univ Winnipeg, Appl Comp Sci Dept, Winnipeg, MB, Canada.
   Erbad, Aiman, Hamad Bin Khalifa Univ, Coll Sci \& Engn, Doha, Qatar.}},
DOI = {{10.1109/IWCMC51323.2021.9498633}},
ISSN = {{2376-6492}},
ISBN = {{978-1-7281-8616-0}},
Keywords = {{security; class imbalance; human interaction; machine learning
   technique; accuracy}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Hardware \& Architecture; Computer Science,
   Information Systems; Engineering, Electrical \& Electronic;
   Telecommunications}},
Funding-Acknowledgement = {{Qatar University Internal Grant {[}IRCC-2020-001]}},
Funding-Text = {{This work was supported by Qatar University Internal Grant
   IRCC-2020-001. The statements made herein are solely the responsibility
   of the author{[}s].}},
Number-of-Cited-References = {{17}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BS2VJ}},
Unique-ID = {{WOS:000707024100151}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000446384603010,
Author = {Bedi, Amrit Singh and Sarma, Paban and Rajawat, Ketan},
Book-Group-Author = {{IEEE}},
Title = {{ADVERSARIAL MULTI-AGENT TARGET TRACKING WITH INEXACT ONLINE GRADIENT
   DESCENT}},
Booktitle = {{2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING (ICASSP)}},
Year = {{2018}},
Pages = {{2881-2885}},
Note = {{IEEE International Conference on Acoustics, Speech and Signal Processing
   (ICASSP), Calgary, CANADA, APR 15-20, 2018}},
Organization = {{Inst Elect \& Elect Engineers; Inst Elect \& Elect Engineers Signal Proc
   Soc}},
Abstract = {{Multi-agent systems are being increasingly deployed in challenging
   environments for performing complex tasks such as multi-target tracking,
   search-and-rescue, and intrusion detection. This paper formulates the
   generic target tracking problem as a time-varying optimization problem
   and puts forth an inexact online gradient descent method for solving it
   sequentially. The performance of the proposed algorithm is studied by
   characterizing its dynamic regret, a notion common to the online
   learning literature. Building upon the existing results, we provide
   improved regret rates that not only allow non-strongly convex costs but
   also explicating the role of the cumulative gradient error. The
   objective function is convex but the variable belongs to a compact
   domain. The efficacy of the proposed inexact gradient framework is
   established on a multi-agent multi-target tracking problem.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Bedi, AS (Corresponding Author), IIT Kanpur, Dept Elect Engn, Kanpur, UP, India.
   Bedi, Amrit Singh; Sarma, Paban; Rajawat, Ketan, IIT Kanpur, Dept Elect Engn, Kanpur, UP, India.}},
ISBN = {{978-1-5386-4658-8}},
Keywords = {{Time varying optimization; stochastic optimization; target tracking;
   gradient descent methods}},
Keywords-Plus = {{CONVERGENCE}},
Research-Areas = {{Acoustics; Engineering}},
Web-of-Science-Categories  = {{Acoustics; Engineering, Electrical \& Electronic}},
Author-Email = {{amritbd@iitk.ac.in
   sarma.paban@gmail.com
   ketan@iitk.ac.in}},
Number-of-Cited-References = {{30}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BL0QY}},
Unique-ID = {{WOS:000446384603010}},
DA = {{2021-11-23}},
}

@article{ WOS:000687445100017,
Author = {Seyfollahi, Ali and Ghaffari, Ali},
Title = {{A Review of Intrusion Detection Systems in RPL Routing Protocol Based on
   Machine Learning for Internet of Things Applications}},
Journal = {{WIRELESS COMMUNICATIONS \& MOBILE COMPUTING}},
Year = {{2021}},
Volume = {{2021}},
Month = {{AUG 10}},
Abstract = {{IPv6 routing protocol for low-power and lossy networks (RPL) has been
   developed as a routing agent in low-power and lossy networks (LLN),
   where nodes' resource constraint nature is challenging. This protocol
   operates at the network layer and can create routing and optimally
   distribute routing information between nodes. RPL is a low-power,
   high-throughput IPv6 routing protocol that uses distance vectors. Each
   sensor-to-wire network router has a collection of fixed parents and a
   preferred parent on the path to the Destination-oriented directed
   acyclic graph (DODAG) graph's root in steady-state. Each router part of
   the graph sends DODAG information object (DIO) control messages and
   specifies its rank within the graph, indicating its position within the
   network relative to the root. When a node receives a DIO message, it
   determines its network rank, which must be higher than all its parents'
   rank, and then continues sending DIO messages using the trickle timer.
   As a result, DODAG begins at the root and eventually extends to
   encompass the whole network. This paper is the first review to study
   intrusion detection systems in the RPL protocol based on machine
   learning (ML) techniques to the best of our knowledge. The complexity of
   the new attack models identified for RPL and the efficiency of ML in
   intelligent and collaborative threats detection, and the issues of
   deploying ML in challenging LLN environments underscore the importance
   of research in this area. The analysis is done using research sources of
   ``Google Scholar,{''} ``Crossref,{''} ``Scopus,{''} and ``Web of
   Science{''} resources. The evaluations are assessed for studies from
   2016 to 2021. The results are illustrated with tables and figures.}},
Publisher = {{WILEY-HINDAWI}},
Address = {{ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND}},
Type = {{Review}},
Language = {{English}},
Affiliation = {{Ghaffari, A (Corresponding Author), Islamic Azad Univ, Dept Comp Engn, Tabriz Branch, Tabriz, Iran.
   Seyfollahi, Ali; Ghaffari, Ali, Islamic Azad Univ, Dept Comp Engn, Tabriz Branch, Tabriz, Iran.}},
DOI = {{10.1155/2021/8414503}},
Article-Number = {{8414503}},
ISSN = {{1530-8669}},
EISSN = {{1530-8677}},
Keywords-Plus = {{WIRELESS SENSOR NETWORKS; LOW-POWER; LOSSY NETWORKS; SECURITY; ATTACKS;
   CLASSIFICATION; HYBRID; AWARE; COMMUNICATION; ENHANCEMENTS}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{a.ghaffari@iaut.ac.ir}},
ResearcherID-Numbers = {{Seyfollahi, Ali/AAR-4907-2020
   Ghaffari, Ali/AAV-3651-2020}},
ORCID-Numbers = {{Seyfollahi, Ali/0000-0002-4254-0297
   Ghaffari, Ali/0000-0001-5407-8629}},
Number-of-Cited-References = {{184}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{6}},
Usage-Count-Since-2013 = {{6}},
Journal-ISO = {{Wirel. Commun. Mob. Comput.}},
Doc-Delivery-Number = {{UD8HX}},
Unique-ID = {{WOS:000687445100017}},
OA = {{gold}},
DA = {{2021-11-23}},
}

@article{ WOS:000537110500280,
Author = {Maestre Vidal, Jorge and Sotelo Monge, Marco Antonio},
Title = {{Obfuscation of Malicious Behaviors for Thwarting Masquerade Detection
   Systems Based on Locality Features}},
Journal = {{SENSORS}},
Year = {{2020}},
Volume = {{20}},
Number = {{7}},
Month = {{APR}},
Abstract = {{In recent years, dynamic user verification has become one of the basic
   pillars for insider threat detection. From these threats, the research
   presented in this paper focuses on masquerader attacks, a category of
   insiders characterized by being intentionally conducted by persons
   outside the organization that somehow were able to impersonate
   legitimate users. Consequently, it is assumed that masqueraders are
   unaware of the protected environment within the targeted organization,
   so it is expected that they move in a more erratic manner than
   legitimate users along the compromised systems. This feature makes them
   susceptible to being discovered by dynamic user verification methods
   based on user profiling and anomaly-based intrusion detection. However,
   these approaches are susceptible to evasion through the imitation of the
   normal legitimate usage of the protected system (mimicry), which is
   being widely exploited by intruders. In order to contribute to their
   understanding, as well as anticipating their evolution, the conducted
   research focuses on the study of mimicry from the standpoint of an
   uncharted terrain: the masquerade detection based on analyzing locality
   traits. With this purpose, the problem is widely stated, and a pair of
   novel obfuscation methods are introduced: locality-based mimicry by
   action pruning and locality-based mimicry by noise generation. Their
   modus operandi, effectiveness, and impact are evaluated by a collection
   of well-known classifiers typically implemented for masquerade
   detection. The simplicity and effectiveness demonstrated suggest that
   they entail attack vectors that should be taken into consideration for
   the proper hardening of real organizations.}},
Publisher = {{MDPI}},
Address = {{ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Vidal, JM (Corresponding Author), Indra, Digital Labs, Ave Bruselas,35,Alcobendas, Madrid 28108, Spain.
   Monge, MAS (Corresponding Author), Univ Lima, Fac Engn \& Architecture, Ave Javier Prado Este, Lima 4600, Peru.
   Maestre Vidal, Jorge, Indra, Digital Labs, Ave Bruselas,35,Alcobendas, Madrid 28108, Spain.
   Sotelo Monge, Marco Antonio, Univ Lima, Fac Engn \& Architecture, Ave Javier Prado Este, Lima 4600, Peru.}},
DOI = {{10.3390/s20072084}},
Article-Number = {{2084}},
EISSN = {{1424-8220}},
Keywords = {{insider threats; masquerade attacks; adversarial machine learning;
   mimicry; dynamic user verification}},
Keywords-Plus = {{INTRUSION; CLASSIFIER; FRAMEWORK; USERS}},
Research-Areas = {{Chemistry; Engineering; Instruments \& Instrumentation}},
Web-of-Science-Categories  = {{Chemistry, Analytical; Engineering, Electrical \& Electronic;
   Instruments \& Instrumentation}},
Author-Email = {{jmaestre@indra.es
   msotelo@ulima.edu.pe}},
ResearcherID-Numbers = {{Maestre Vidal, Jorge/K-3721-2017}},
ORCID-Numbers = {{Sotelo Monge, Marco Antonio/0000-0001-6392-0216
   Maestre Vidal, Jorge/0000-0002-4131-5100}},
Funding-Acknowledgement = {{European CommissionEuropean CommissionEuropean Commission Joint Research
   Centre {[}830892, H2020-SU-ICT-03-2018/830892]}},
Funding-Text = {{This work is funded by the European Commission Horizon 2020 Programme
   under grant agreement number 830892, as part of the project
   H2020-SU-ICT-03-2018/830892 SPARTA: Special projects for advanced
   research and technology in Europe.}},
Number-of-Cited-References = {{51}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Journal-ISO = {{Sensors}},
Doc-Delivery-Number = {{LT5KW}},
Unique-ID = {{WOS:000537110500280}},
OA = {{Green Published, gold}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000653149400008,
Author = {Shahid, Mustafizur R. and Blanc, Gregory and Jmila, Houda and Zhang,
   Zonghua and Debar, Herve},
Editor = {{Ceballos, C}},
Title = {{Generative Deep Learning for Internet of Things Network Traffic
   Generation}},
Booktitle = {{2020 IEEE 25TH PACIFIC RIM INTERNATIONAL SYMPOSIUM ON DEPENDABLE
   COMPUTING (PRDC 2020)}},
Series = {{IEEE Pacific Rim International Symposium on Dependable Computing}},
Year = {{2020}},
Pages = {{70-79}},
Note = {{25th IEEE Pacific Rim International Symposium on Dependable Computing
   (IEEE PRDC), Perth, AUSTRALIA, DEC 01-04, 2020}},
Organization = {{IEEE; IEEE Comp Soc; IEEE Comp Soc Tech Comm Dependable Comp \& Fault
   Tolerance}},
Abstract = {{The rapid development of the Internet of Things (IoT) has prompted a
   recent interest into realistic IoT network traffic generation. Security
   practitioners need IoT network traffic data to develop and assess
   network-based intrusion detection systems (NIDS). Emulating realistic
   network traffic will avoid the costly physical deployment of thousands
   of smart devices. From an attacker's perspective, generating network
   traffic that mimics the legitimate behavior of a device can be useful to
   evade NIDS. As network traffic data consist of sequences of packets, the
   problem is similar to the generation of sequences of categorical data,
   like word by word text generation. Many solutions in the field of
   natural language processing have been proposed to adapt a Generative
   Adversarial Network (GAN) to generate sequences of categorical data. In
   this paper, we propose to combine an autoencoder with a GAN to generate
   sequences of packet sizes that correspond to bidirectional flows. First,
   the autoencoder is trained to learn a latent representation of the real
   sequences of packet sizes. A GAN is then trained on the latent space, to
   learn to generate latent vectors that can be decoded into realistic
   sequences. For experimental purposes, bidirectional flows produced by a
   Google Home Mini are used, and the autoencoder is combined with a
   Wassertein GAN. Comparison of different network characteristics shows
   that our proposed approach is able to generate sequences of packet sizes
   that behave closely to real bidirectional flows. We also show that the
   synthetic bidirectional flows are close enough to the real ones that
   they can fool anomaly detectors into labeling them as legitimate.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Shahid, MR (Corresponding Author), Telecom SudParis, Inst Polytech Paris, Paris, France.
   Shahid, Mustafizur R.; Blanc, Gregory; Jmila, Houda; Debar, Herve, Telecom SudParis, Inst Polytech Paris, Paris, France.
   Zhang, Zonghua, IMT Lille Douai, Inst Mines Telecom, Lille, France.}},
DOI = {{10.1109/PRDC50213.2020.00018}},
ISSN = {{1555-094X}},
ISBN = {{978-1-7281-8003-8}},
Keywords = {{Deep Learning; Generative Adversarial Network; Autoencoder; Network
   Security; Internet of Things}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods; Engineering, Electrical \&
   Electronic}},
Author-Email = {{mustafizur.shahid@telecom-sudparis.eu
   gregory.blanc@telecom-sudparis.eu
   houda.jmila@telecom-sudparis.eu
   zonghua.zhang@imt-lille-douai.fr
   herve.debar@telecom-sudparis.eu}},
Funding-Acknowledgement = {{TENtec {[}28263632]; Connecting Europe Facility of the European Union;
   SPARTA project - European Union's Horizon 2020 research and innovation
   programme {[}830892]; VARIoT project}},
Funding-Text = {{The authors are partially funded under the VARIoT project with TENtec n.
   28263632, co-financed by the Connecting Europe Facility of the European
   Union, and under the SPARTA project, which has received funding from the
   European Union's Horizon 2020 research and innovation programme under
   grant agreement No. 830892. The dataset used in this project has been
   generated by a platform built for VARIoT.}},
Number-of-Cited-References = {{31}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BR4SY}},
Unique-ID = {{WOS:000653149400008}},
OA = {{Green Submitted}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000681331400092,
Author = {Yang, Hao and Zhou, Yun},
Book-Group-Author = {{IEEE COMP SOC}},
Title = {{IDA-GAN: A Novel Imbalanced Data Augmentation GAN}},
Booktitle = {{2020 25TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION (ICPR)}},
Series = {{International Conference on Pattern Recognition}},
Year = {{2021}},
Pages = {{8299-8305}},
Note = {{25th International Conference on Pattern Recognition (ICPR), ELECTR
   NETWORK, JAN 10-15, 2021}},
Organization = {{Int Assoc Pattern Recognit; IEEE Comp Soc; Italian Assoc Comp Vis
   Pattern Recognit \& Machine Learning}},
Abstract = {{Class imbalance is a widely existed and challenging problem in
   real-world applications such as disease diagnosis, fraud detection,
   network intrusion detection and so on. Due to the scarce of data, it
   could significantly deteriorate the accuracy of classification. To
   address this challenge, we propose a novel Imbalanced Data Augmentation
   Generative Adversarial Networks (GAN) named IDA-GAN as an augmentation
   tool to deal with the imbalanced dataset. This is a great challenge
   because it is hard to train a GAN model under this situation. We address
   this issue by coupling variational autoencoder along with GAN training.
   In this paper, specifically, we introduce the variational autoencoder to
   learn the majority and minority class distributions in the latent space,
   and use the generative model to utilize each class distribution for the
   subsequent GAN training. The generative model learns useful features to
   generate target minority-class samples. Compared with the
   state-of-the-art GAN model, the experimental results demonstrate that
   our proposed IDA-GAN could generate more diverse minority samples with
   better qualities, and it could benefits the imbalanced classification
   task in terms of several widely-used evaluation metrics on five
   benchmark datasets: MNIST, Fashion-MNIST, SVHN, CIFAR-10 and GTSRB.}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Zhou, Y (Corresponding Author), Natl Univ Def Technol, Sci \& Technol Informat Syst Engn Lab, Changsha, Hunan, Peoples R China.
   Yang, Hao; Zhou, Yun, Natl Univ Def Technol, Sci \& Technol Informat Syst Engn Lab, Changsha, Hunan, Peoples R China.}},
DOI = {{10.1109/ICPR48806.2021.9411996}},
ISSN = {{1051-4651}},
ISBN = {{978-1-7281-8808-9}},
Keywords = {{Imbalanced learning; Data augmentation; Variational autoencoder; GAN}},
Keywords-Plus = {{CLASSIFICATION}},
Research-Areas = {{Computer Science; Engineering; Imaging Science \& Photographic
   Technology}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic; Imaging Science \& Photographic Technology}},
Author-Email = {{zhouyun@nudt.edu.cn}},
Number-of-Cited-References = {{29}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{5}},
Usage-Count-Since-2013 = {{5}},
Doc-Delivery-Number = {{BS0DY}},
Unique-ID = {{WOS:000681331400092}},
DA = {{2021-11-23}},
}

@article{ WOS:000389163700003,
Author = {Narang, Pratik and Hota, Chittaranjan and Sencar, Husrev Taha},
Title = {{Noise-resistant mechanisms for the detection of stealthy peer-to-peer
   botnets}},
Journal = {{COMPUTER COMMUNICATIONS}},
Year = {{2016}},
Volume = {{96}},
Pages = {{29-42}},
Month = {{DEC 15}},
Abstract = {{The problem of detection of malicious network traffic is adversarial in
   nature. Accurate detection of stealthy Peer-to-Peer botnets is an
   ongoing research problem. Past research on detection of P2P botnets has
   frequently used machine learning algorithms to build detection models.
   However, most prior work lacks the evaluation of such detection models
   in the presence of deliberate injection of noise by an adversary.
   Furthermore, detection of P2P botnets in the presence of benign P2P
   traffic has received little attention from the research community. This
   work proposes a novel approach for the detection of stealthy P2P botnets
   (in presence of benign P2P traffic) using conversation-based mechanisms
   and new features based on Fourier transforms and information entropy. We
   use real-world botnet data to compare the performance of our features
   with traditional `flow-based' features employed by past research, and
   demonstrate that our approach is more resilient towards the injection of
   noise in the communication patterns by an adversary. We build detection
   models with multiple supervised machine learning algorithms. With our
   approach, we could detect P2P botnet traffic in the presence of injected
   noise with True Positive rate as high as 90\%. (C) 2016 Elsevier B.V.
   All rights reserved.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Narang, P (Corresponding Author), Natl Univ Singapore, Dept Elect \& Comp Engn, Singapore, Singapore.
   Narang, Pratik, Natl Univ Singapore, Dept Elect \& Comp Engn, Singapore, Singapore.
   Hota, Chittaranjan, BITS Pilani, Deptartment Comp Sci \& Informat Syst, Hyderabad Campus, Hyderabad, Telangana, India.
   Sencar, Husrev Taha, TOBB Univ, Dept Comp Engn, Ankara, Turkey.
   Sencar, Husrev Taha, NYU, CRISSP AD, Abu Dhabi, U Arab Emirates.}},
DOI = {{10.1016/j.comcom.2016.05.017}},
ISSN = {{0140-3664}},
EISSN = {{1873-703X}},
Keywords = {{Botnet; Machine learning; Peer-to-peer; Intrusion detection; Security}},
Keywords-Plus = {{P2P BOTNETS}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{pratik@nus.edu.sg
   hota@hyderabad.bits-pilani.ac.in
   htsencar@etu.edu.tr}},
ResearcherID-Numbers = {{Narang, Pratik/Q-5960-2019
   Hota, Chittaranjan/AAV-2180-2020
   }},
ORCID-Numbers = {{Narang, Pratik/0000-0003-1865-3512
   Hota, Chittaranjan/0000-0002-6031-6408
   Bennett University, Computer Science/0000-0002-9193-5850}},
Funding-Acknowledgement = {{Department of Information Technology, Govt. of India, New Delhi, India
   {[}12(13)/2012-ESD]}},
Funding-Text = {{This work was supported by Grant number 12(13)/2012-ESD for scientific
   research under Cyber Security area from the Department of Information
   Technology, Govt. of India, New Delhi, India.}},
Number-of-Cited-References = {{56}},
Times-Cited = {{6}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{19}},
Journal-ISO = {{Comput. Commun.}},
Doc-Delivery-Number = {{ED9AY}},
Unique-ID = {{WOS:000389163700003}},
DA = {{2021-11-23}},
}

@article{ WOS:000674531600001,
Author = {Kalnoor, Gauri and Gowrishankar, S.},
Title = {{IoT-based smart environment using intelligent intrusion detection system}},
Journal = {{SOFT COMPUTING}},
Year = {{2021}},
Volume = {{25}},
Number = {{17}},
Pages = {{11573-11588}},
Month = {{SEP}},
Abstract = {{One of the most basic characteristic features of every smart device in a
   network based on the Internet of Things (IoT) is to gather a larger set
   of data that has been created and then transfer the gathered data to the
   destination/receiver server through the internet. Thus, IoT-based
   networks are most vulnerable to simple or complex attacks that need to
   be identified in the early stage of data transmission for saving the
   network from these malicious attacks. The chief goal of the proposed
   work is to design and form the intelligent intrusion detection system
   (I-IDS) using the machine learning models such that the attacks can be
   identified in the IoT network. The model is built considering the normal
   and malicious attacks on the data that are generated in IoT smart
   environment. To simulate such a model, a testbed is built where a
   wireless router, a DHT11 sensor, and a node MCU are being used during
   the design phase. An attacker or adversarial system is built to perform
   poisoning and sniffing attacks using a laptop system. The node captures
   the sensor values and transmits the data to the ThinkSpeak platform,
   during the normal phase via the wireless gateway, and in the attack
   phase, the malicious attacker interprets the data, modifies it while
   transmitting from node to the ThinkSpeak server. Thus, the attack called
   Man-In-The-Middle (MITM) is performed and classified as abnormal data.
   Various machine learning algorithms are performed on the data, and
   finally, the results obtained using a probabilistic model called as
   Markov model have a high performance evaluated based on the I-IDS IoT
   network. The results obtained during the experimental analysis show that
   the Markov model has obtained a 100\% detection rate and 19\% of false
   alarm rate (FAR) with high precision and low error rate. The algorithms
   such as naive Bayes classifier, support vector machine (SVM), decision
   tree, and Adaboost are considered in comparison with the Markov model.
   The optimal solution is obtained concerning other evaluation metrics
   like sensitivity, F1, and true-positive rate (TPR). Therefore, the
   integrated network of IoT-WSN with its performance metrics is tabulated
   to show the potentials of securing a network system. Additionally, the
   proposed work gives a high level of security for IoT smart environment
   as compared with the other machine learning algorithms using the novel
   technique of intelligent IDS.}},
Publisher = {{SPRINGER}},
Address = {{ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Kalnoor, G (Corresponding Author), BMS Coll Engn, Bangalore, Karnataka, India.
   Kalnoor, Gauri; Gowrishankar, S., BMS Coll Engn, Bangalore, Karnataka, India.}},
DOI = {{10.1007/s00500-021-06028-1}},
Early Access Date = {{JUL 2021}},
ISSN = {{1432-7643}},
EISSN = {{1433-7479}},
Keywords = {{Internet of Things (IoT); Fog computing; Wireless sensor network (WSN);
   Security; Cloud computing; Intrusion detection; Computing}},
Keywords-Plus = {{INTERNET; SECURITY; PROTOCOLS; TAXONOMY; SCHEME}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications}},
Author-Email = {{kalnoor.gauri@gmail.com}},
Number-of-Cited-References = {{34}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{2}},
Journal-ISO = {{Soft Comput.}},
Doc-Delivery-Number = {{TX9TV}},
Unique-ID = {{WOS:000674531600001}},
DA = {{2021-11-23}},
}

@article{ WOS:000643675900009,
Author = {Liu, Ao and Wang, Yunpeng and Li, Tao},
Title = {{SFE-GACN: A novel unknown attack detection under insufficient data via
   intra categories generation in embedding space}},
Journal = {{COMPUTERS \& SECURITY}},
Year = {{2021}},
Volume = {{105}},
Month = {{JUN}},
Abstract = {{In the network traffic intrusion detection, deep learning based schemes
   have attracted lots of achievements. However, in real-world scenarios,
   data is often insufficient (few-shot), which leads to various deviations
   between the models prediction and the ground truth. Consequently,
   downstream tasks such as unknown attack detection based on few-shot will
   be limited by insufficient data. In this paper, we propose a novel
   unknown attack detection method based on Intra Categories Generation in
   Embedding Space, namely SFE-GACN, which might be the solution of
   few-shot problem. Concretely, we first propose Session Feature Embedding
   (SFE) to summarize the context of basic granularity of network traffic:
   sessions, bring the insufficient data to the pre-trained embedding
   space. In this way, we achieve the goal of preliminary information
   extension in the few-shot case. Second, we further propose the
   Generative Adversarial Cooperative Network (GACN), which improves the
   conventional Generative Adversarial Network by supervising the generated
   sample to avoid falling into similar categories, and thus enables
   samples to generate intra categories. Our proposed SFE-GACN achieved
   that it can accurately generate session samples in the case of few-shot,
   and ensure the difference between categories during data augmentation.
   The detection results show that compared to the state-of-the-art method,
   the average TPR is 8.38\% higher, and the average FPR is 12.77\% lower.
   In addition, we evaluated the graphics generation capabilities of GACN
   on the graphics dataset, the result shows our proposed GACN can be
   popularized for generating easy-confused multi-categories graphics.
   (c) 2021 Elsevier Ltd. All rights reserved.}},
Publisher = {{ELSEVIER ADVANCED TECHNOLOGY}},
Address = {{OXFORD FULFILLMENT CENTRE THE BOULEVARD, LANGFORD LANE, KIDLINGTON,
   OXFORD OX5 1GB, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Wang, YP (Corresponding Author), Sichuan Univ, Coll Cybersecur, Chengdu 610065, Peoples R China.
   Liu, Ao; Wang, Yunpeng; Li, Tao, Sichuan Univ, Coll Cybersecur, Chengdu 610065, Peoples R China.}},
DOI = {{10.1016/j.cose.2021.102262}},
Article-Number = {{102262}},
ISSN = {{0167-4048}},
EISSN = {{1872-6208}},
Keywords = {{Session feature embedding; Few-shot; Unknown attack detection; Intra
   categories generation; Generative adversarial cooperative network (GACN)}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems}},
Author-Email = {{liuao@stu.scu.edu.cn
   wyp@scu.edu.cn
   litao@scu.edu.cn}},
Funding-Acknowledgement = {{National Key R\&D Program of China {[}2020YFB1805400]; National Natural
   Science Foundation of ChinaNational Natural Science Foundation of China
   (NSFC) {[}U19A2068, U1736212, 62032002]}},
Funding-Text = {{This work is partially sponsored by the National Key R\&D Program of
   China 2020YFB1805400) and the National Natural Science Foundation of
   China (U19A2068, U1736212, 62032002).}},
Number-of-Cited-References = {{21}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{8}},
Usage-Count-Since-2013 = {{8}},
Journal-ISO = {{Comput. Secur.}},
Doc-Delivery-Number = {{RS3JK}},
Unique-ID = {{WOS:000643675900009}},
OA = {{Green Submitted}},
DA = {{2021-11-23}},
}

@article{ WOS:000401340500012,
Author = {Garnaev, Andrey and Trappe, Wade},
Title = {{Bandwidth Scanning When Facing Interference Attacks Aimed at Reducing
   Spectrum Opportunities}},
Journal = {{IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY}},
Year = {{2017}},
Volume = {{12}},
Number = {{8}},
Pages = {{1916-1930}},
Month = {{AUG}},
Abstract = {{Unutilized spectra, i.e., spectrum holes, are opportunities that may be
   used for communication or adapting other services that use radio
   frequency (RF). Such opportunities can also represent an adversarial
   target, if his objective is to block the RF system from using such
   opportunities opened by spectrum holes. In this paper, we explore the
   challenge of finding spectrum holes in an adversarial environment.
   First, by means of a simple model, we show that an adversary's attack
   designed to close spectrum holes can be more harmful for the spectrum
   holes than just random jamming. This calls for designing a scanning
   strategy to detect such an attack. Second, by applying a
   game-theoretical model, we design the optimal scanning strategy to
   detect such attacks. In particular, we show the efficiency of such a
   scanning strategy compared with uninformed random scanning. This
   efficiency is achieved by focusing scanning efforts on the bands that
   will be more likely under attack, and neglecting less promising bands.
   Beyond the benefits, though, such a strategy has also drawbacks since,
   if the adversary has a different objective, such as sneaking usage of
   the spectrum, he can sneak usage undetected by using the bands neglected
   by such specially tuned scanning. To deal with this problem, third, we
   suggest to combine this strategy with a strategy that maximizes
   detection probability in a learning algorithm that updates the beliefs
   about the adversary's objective. The convergence of the combined
   algorithm is proven.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Garnaev, A (Corresponding Author), Rutgers State Univ, Wireless Informat Network Lab, North Brunswick, NJ 08901 USA.
   Garnaev, Andrey; Trappe, Wade, Rutgers State Univ, Wireless Informat Network Lab, North Brunswick, NJ 08901 USA.}},
DOI = {{10.1109/TIFS.2017.2694766}},
ISSN = {{1556-6013}},
EISSN = {{1556-6021}},
Keywords = {{Intrusion detection; wireless networks; Bayes methods}},
Keywords-Plus = {{GAMES; NETWORKS; STRATEGY}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods; Engineering, Electrical \&
   Electronic}},
Author-Email = {{garnaev@yahoo.com
   trappe@winlab.rutgers.edu}},
Funding-Acknowledgement = {{National Science FoundationNational Science Foundation (NSF)
   {[}ECCS-1247864]; Division Of Computer and Network SystemsNational
   Science Foundation (NSF)NSF - Directorate for Computer \& Information
   Science \& Engineering (CISE) {[}1443434] Funding Source: National
   Science Foundation}},
Funding-Text = {{This work was supported by the National Science Foundation under Grant
   ECCS-1247864. The associate editor coordinating the review of this
   manuscript and approving it for publication was Prof. Athanasios V.
   Vasilakos. (Corresponding author: Andrey Garnaev.)}},
Number-of-Cited-References = {{38}},
Times-Cited = {{5}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{IEEE Trans. Inf. Forensic Secur.}},
Doc-Delivery-Number = {{EU9EJ}},
Unique-ID = {{WOS:000401340500012}},
OA = {{hybrid}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000316952800047,
Author = {Streisand, David and Dove, Rick},
Editor = {{Pritchard, DA}},
Title = {{Basic Genetic-Algorithm-Neural-Network (GANN) Pattern with a
   Self-Organizing Security Example}},
Booktitle = {{46TH ANNUAL 2012 IEEE INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY
   TECHNOLOGY}},
Series = {{International Carnahan Conference on Security Technology Proceedings}},
Year = {{2012}},
Pages = {{312-318}},
Note = {{46th Annual IEEE International Carnahan Conference on Security
   Technology (ICCST), Boston, MA, OCT 15-18, 2012}},
Organization = {{IEEE; Chung Shan Inst Sci; IEEE Aerosp \& Elect Syst Soc (AESS); Natl
   Cent Univ; Sandia Natl Labs; Volpe Ctr; FLIR; US Amer, Dept Transformat}},
Abstract = {{The anti-system adversarial community is characterized as a
   self-organizing system-of-systems, noted collectively for its leadership
   in rapid evolution and innovative advancement widening the gap between
   security cost and security losses. It appears that system security
   strategy cannot hope to even achieve parity without a comparable
   self-organizing strategy. Toward that end a project is underway to
   catalog re-usable patterns of self-organizing security of many kinds,
   principally found in natural systems, but also seen in recent
   computational approaches. One class of pattern of special interest
   involves discovery of previously unseen threats and attacks. In general
   this class of pattern has aspects of learning, innovation, and evolution
   as capability objectives. The genetic algorithm is one such pattern.
   Another such pattern is seen in artificial neural networks. Combining
   the two into a Genetic Algorithm augmented Neural Network, often called
   GANN, has considerable recent history in the literature. Not many of
   these are directly related to security applications. Some
   security-application work shows GANNs employed for feature selection
   provide enhanced learning performance and accuracy, and avoidance of
   local minimum traps. This paper adds the GANN pattern to the
   self-organizing security pattern catalog, and applies the pattern to a
   self-organizing security application under development}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Streisand, D (Corresponding Author), Stevens Inst Technol, Hoboken, NJ 07030 USA.
   Streisand, David; Dove, Rick, Stevens Inst Technol, Hoboken, NJ 07030 USA.}},
ISSN = {{1071-6572}},
ISBN = {{978-1-4673-2451-9}},
Keywords = {{GANN; intrusion detection; SARE PH}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods; Engineering, Electrical \&
   Electronic}},
Number-of-Cited-References = {{15}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BEJ66}},
Unique-ID = {{WOS:000316952800047}},
DA = {{2021-11-23}},
}

@article{ WOS:000497250800006,
Author = {Arivudainambi, D. and Kumar, Varun K. A. and Chakkaravarthy, Sibi S. and
   Visu, P.},
Title = {{Malware traffic classification using principal component analysis and
   artificial neural network for extreme surveillance}},
Journal = {{COMPUTER COMMUNICATIONS}},
Year = {{2019}},
Volume = {{147}},
Pages = {{50-57}},
Month = {{NOV}},
Abstract = {{Code-driven systems have extent to more than half of the world's
   populations in ambient data and connectivity, offering formerly
   unimagined opportunities and unexpected threats. Evolutions in
   Artificial Intelligence (AI) are seen increasing day by day especially
   in industrial builds. The unconventional technique of AI in
   cyber-attacks seems to be quite daunting. The idea of a machine growing
   its own knowledge through self-learning becomes sophisticated to attack
   things is a fretful problem to the cyber world. Most of the time, these
   AI enabled cyber-attacks are performed using advanced malwares which
   incorporates advanced evasion techniques to evade security perimeters.
   Traditional cyber security methods fail to cope with these attacks. In
   order to address these issues, robust traffic classification system
   using Principal Component Analysis (PCA) and Artificial Neural Network
   (ANN) is proposed for providing extreme surveillance. Further, these
   proposed method aims to expose various AI based cyber-attacks with their
   present-day impact, and their fortune in the future. Simulation is
   carried out using a self-developed autonomous agent which learns by
   itself. Experimental results confirm that the proposed schemes are
   efficient to classify the attack traffic with 99\% of accuracy when
   compared to the state of the art methods.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Kumar, KAV (Corresponding Author), Anna Univ, Dept Math, Madras, Tamil Nadu, India.
   Arivudainambi, D.; Kumar, Varun K. A., Anna Univ, Dept Math, Madras, Tamil Nadu, India.
   Chakkaravarthy, Sibi S., VIT AP, Dept Comp Sci \& Engn, Amaravati, Andhra Pradesh, India.
   Visu, P., Velammal Engn Coll, Dept Comp Sci \& Engn, Chennai, Tamil Nadu, India.}},
DOI = {{10.1016/j.comcom.2019.08.003}},
ISSN = {{0140-3664}},
EISSN = {{1873-703X}},
Keywords = {{AI driven cyber-attacks; Malwares; Principle component analysis;
   Surveillance; Artificial neural network}},
Keywords-Plus = {{INTRUSION DETECTION}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{arivu@annauniv.edu
   kavaruncse@gmail.com
   sb.sibi@mitindia.edu
   pandu.visu@gmail.com}},
ResearcherID-Numbers = {{Chakkaravarthy, Sibi S/D-3735-2019
   D, Arivudainambi/D-1205-2015
   S, Sibi Chakkaravarthy/W-7245-2019
   }},
ORCID-Numbers = {{D, Arivudainambi/0000-0003-0917-6814
   S, Sibi Chakkaravarthy/0000-0001-7778-0453
   D, Arivudainambi/0000-0001-5128-8970
   Kumar, Varun/0000-0001-9281-2273}},
Number-of-Cited-References = {{23}},
Times-Cited = {{8}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{16}},
Journal-ISO = {{Comput. Commun.}},
Doc-Delivery-Number = {{JO0AT}},
Unique-ID = {{WOS:000497250800006}},
DA = {{2021-11-23}},
}

@article{ WOS:000441191400006,
Author = {Islamic, Toqeer Ali and Jan, Salman and Faizullah, Safiullah and Musa,
   Shahrulniza},
Title = {{A Comparison of Svm With Deep Learning Models for Large-Scale Intents
   Analysis}},
Journal = {{INTERNATIONAL JOURNAL OF COMPUTER SCIENCE AND NETWORK SECURITY}},
Year = {{2018}},
Volume = {{18}},
Number = {{7}},
Pages = {{38-46}},
Month = {{JUL 30}},
Abstract = {{Android has been effectively adopted as an open source operating system
   over the smart devices since it offers customers a wide range of
   applications. The statistics regarding number of active applications in
   Google Play Store show overwhelming increase. Until December 2017, the
   number of available applications in the Google Play Store was 3.5
   million while 50.6 million number of active applications are predicted
   by 2020. However, there are reports of intruded applications which
   violates user's privacy. It is essential to devise effective techniques
   to analyze and detect threats. to ensure integrity of data and
   applications, security experts presented various approaches including
   use sequences of permissions required by applications similarly system
   calls generated by applications are measured. This study proposes to
   consider intents initiated by applications as a parameter to verify
   malignant behavior of applications. To meet the purpose, a dataset
   containing 60,000 applications is generated which includes 20,000
   malicious while 40,000 benign applications. The dataset is utilized to
   train proposed deep machine learning models including SVM and Generative
   Adversarial Networks (GANs). The results show reasonable malicious
   detection rate using intents on GANs. We believe that the proposed model
   is appropriate solution for ensuring security of Android applications.}},
Publisher = {{INT JOURNAL COMPUTER SCIENCE \& NETWORK SECURITY-IJCSNS}},
Address = {{DAE-SANG OFFICE 301, SANGDO 5 DONG 509-1, SEOUL, 00000, SOUTH KOREA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Islamic, TA (Corresponding Author), Univ Madinah Madinah, Medina, Saudi Arabia.
   Islamic, Toqeer Ali, Univ Madinah Madinah, Medina, Saudi Arabia.
   Jan, Salman; Musa, Shahrulniza, Univ Kuala Lumpur, Kuala Lumpur, Malaysia.
   Faizullah, Safiullah, Islamic Univ Madinah, Madinah, Saudi Arabia.}},
ISSN = {{1738-7906}},
Keywords = {{Smartphone Security; Android intents based analysis; intrusion
   detection; dynamic behavior analysis}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems}},
ResearcherID-Numbers = {{jan, salman/AAT-6209-2021
   Musa, Shahrulniza/J-3430-2016}},
ORCID-Numbers = {{Musa, Shahrulniza/0000-0003-4867-5085}},
Number-of-Cited-References = {{43}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{3}},
Journal-ISO = {{Int. J. Comput. Sci. Netw. Secur.}},
Doc-Delivery-Number = {{GP8UV}},
Unique-ID = {{WOS:000441191400006}},
DA = {{2021-11-23}},
}

@article{ WOS:000661130600004,
Author = {Sabir, Bushra and Ullah, Faheem and Babar, M. Ali and Gaire, Raj},
Title = {{Machine Learning for Detecting Data Exfiltration: A Review}},
Journal = {{ACM COMPUTING SURVEYS}},
Year = {{2021}},
Volume = {{54}},
Number = {{3}},
Month = {{JUN}},
Abstract = {{Research at the intersection of cybersecurity, Machine Learning (ML),
   and Software Engineering (SE) has recently taken significant steps in
   proposing countermeasures for detecting sophisticated data exfiltration
   attacks. It is important to systematically reviewand synthesize the
   ML-based data exfiltration countermeasures for building a body of
   knowledge on this important topic. Objective: This article aims at
   systematically reviewing ML-based data exfiltration countermeasures to
   identify and classify ML approaches, feature engineering techniques,
   evaluation datasets, and performance metrics used for these
   countermeasures. This review also aims at identifying gaps in research
   on ML-based data exfiltration countermeasures. Method: We used
   Systematic Literature Review (SLR) method to select and review 92
   papers. Results: The review has enabled us to: (a) classify the ML
   approaches used in the countermeasures into data-driven, and
   behaviordriven approaches; (b) categorize features into six types:
   behavioral, content-based, statistical, syntactical, spatial, and
   temporal; (c) classify the evaluation datasets into simulated,
   synthesized, and real datasets; and (d) identify 11 performance measures
   used by these studies. Conclusion: We conclude that: (i) The integration
   of data-driven and behavior-driven approaches should be explored; (ii)
   There is a need of developing high quality and large size evaluation
   datasets; (iii) Incremental ML model training should be incorporated in
   countermeasures; (iv) Resilience to adversarial learning should be
   considered and explored during the development of countermeasures to
   avoid poisoning attacks; and (v) The use of automated feature
   engineering should be encouraged for efficiently detecting data
   exfiltration attacks.}},
Publisher = {{ASSOC COMPUTING MACHINERY}},
Address = {{2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA}},
Type = {{Review}},
Language = {{English}},
Affiliation = {{Sabir, B (Corresponding Author), Univ Adelaide, CREST Ctr Res Engn Software Technol, Adelaide, SA, Australia.
   Sabir, B (Corresponding Author), CSIRO, Data61, Sydney, NSW, Australia.
   Sabir, B (Corresponding Author), Univ Adelaide, Frome Rd, Adelaide, SA 5005, Australia.
   Sabir, Bushra; Ullah, Faheem; Babar, M. Ali, Univ Adelaide, CREST Ctr Res Engn Software Technol, Adelaide, SA, Australia.
   Sabir, Bushra; Gaire, Raj, CSIRO, Data61, Sydney, NSW, Australia.
   Babar, M. Ali, CSCRC Cyber Secur Cooperat Res Ctr, Sydney, NSW, Australia.
   Sabir, Bushra, Univ Adelaide, Frome Rd, Adelaide, SA 5005, Australia.
   Gaire, Raj, GPO Box 1700, Canberra, ACT 2601, Australia.}},
DOI = {{10.1145/3442181}},
Article-Number = {{50}},
ISSN = {{0360-0300}},
EISSN = {{1557-7341}},
Keywords = {{Data exfiltration; data leakage; data breach; advanced persistent
   threat; machine learning}},
Keywords-Plus = {{INTRUSION DETECTION SYSTEMS; BIG DATA ANALYTICS; FEATURE-SELECTION;
   CHALLENGES; SECURITY; ATTACKS; TRENDS}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods}},
Author-Email = {{bushra.sabir@adelaide.edu.au
   faheem.ullah@adelaide.edu.au
   ali.babar@adelaide.edu.au
   raj.gaire@data61.csiro.au}},
ResearcherID-Numbers = {{Gaire, Raj/S-6923-2019}},
ORCID-Numbers = {{Gaire, Raj/0000-0003-2499-2553}},
Funding-Acknowledgement = {{CSIRO's Data61, AustraliaCommonwealth Scientific \& Industrial Research
   Organisation (CSIRO); Cyber Security Research Centre Limited -
   Australian Government's Cooperative Research Centres Programme}},
Funding-Text = {{Thiswork is partially supported by CSIRO's Data61, Australia and Cyber
   Security Research Centre Limited whose activities are partly funded by
   the Australian Government's Cooperative Research Centres Programme.}},
Number-of-Cited-References = {{186}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{8}},
Usage-Count-Since-2013 = {{8}},
Journal-ISO = {{ACM Comput. Surv.}},
Doc-Delivery-Number = {{SR6CQ}},
Unique-ID = {{WOS:000661130600004}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000505774700008,
Author = {Khanapuri, Eshaan and Kartik, Tarun and Sharma, Rajnikant and Gerdes,
   Ryan M.},
Book-Group-Author = {{Assoc Comp Machinery}},
Title = {{Learning-based Adversarial Agent Detection and Identification in Cyber
   Physical Systems applied to Autonomous Vehicular Platoon}},
Booktitle = {{2019 IEEE/ACM 5TH INTERNATIONAL WORKSHOP ON SOFTWARE ENGINEERING FOR
   SMART CYBER-PHYSICAL SYSTEMS (SESCPS 2019)}},
Year = {{2019}},
Pages = {{39-45}},
Note = {{5th IEEE/ACM International Workshop on Software Engineering for Smart
   Cyber-Physical Systems (SEsCPS), Montreal, CANADA, MAY 28, 2019}},
Organization = {{IEEE; Assoc Comp Machinery; IEEE Comp Soc}},
Abstract = {{The security of cyber physical systems such as autonomous vehicle
   platoons plays a vital role in ensuring passenger safety. An adversary
   in control of a single vehicle can degrade platoon efficiency or even
   cause collisions. In this paper, we focus on detecting an attack meant
   to destabilize a platoon, thereby causing collisions, and identifying
   the source of the attack (i.e., the vehicle under control of the
   adversary) using Fully Connected Deep Neural Networks (FCDNN) and
   Convolutional Neural Networks (CNN). The vehicles in the platoon are
   assumed to be equipped with sensors (LIDAR and RADAR) that measure the
   range and relative speed of their immediate neighbors. These sensor
   data, modelled with noise following a Gaussian distribution, are used to
   train a FCDNN and CNN for attack detection and identification. The
   effectiveness of these networks are tested for different scenarios based
   on local and global sensor information availability. The initial study
   show that for a ten vehicle platoon, CNN detects and identifies an
   attack with highest accuracy of 97.5\%, just by using the own local
   sensor information. We also show that the range measurements provide
   better accuracy in comparison to the velocity measurements. The platoon
   is modelled and simulated in MATLAB and neural networks are generated
   and tested using Tensorflow and Keras deep learning libraries.}},
Publisher = {{ASSOC COMPUTING MACHINERY}},
Address = {{1515 BROADWAY, NEW YORK, NY 10036-9998 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Khanapuri, E (Corresponding Author), Univ Cincinnati, Dept Aerosp Engn \& Engn Mech, Cincinnati, OH 45220 USA.
   Khanapuri, Eshaan; Kartik, Tarun; Sharma, Rajnikant, Univ Cincinnati, Dept Aerosp Engn \& Engn Mech, Cincinnati, OH 45220 USA.
   Gerdes, Ryan M., Virgina Tech, Bradley Dept Elect \& Comp Engn, Arlington, VA 22003 USA.}},
DOI = {{10.1109/SEsCPS.2019.00014}},
ISBN = {{978-1-7281-2282-3}},
Keywords = {{Deep Neural Network; Security; Cyber Physical Systems; autonomous
   platoon; intrusion detection}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Software Engineering}},
Author-Email = {{khanapem@mail.uc.edu
   chintavk@mail.uc.edu
   rajnikant.sharma@uc.edu
   rgerdes@vt.edu}},
Funding-Acknowledgement = {{National Science Foundation (NSF)National Science Foundation (NSF)
   {[}1014318]}},
Funding-Text = {{This project was funded by National Science Foundation (NSF) Grant
   No.1014318.}},
Number-of-Cited-References = {{28}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{7}},
Doc-Delivery-Number = {{BO2HG}},
Unique-ID = {{WOS:000505774700008}},
DA = {{2021-11-23}},
}

@article{ WOS:000645847900001,
Author = {Tang, Ziqiang and Lin, Yubin and Vosoogh, Mahdi and Parsa, Navid and
   Baziar, Aliasghar and Khan, Baseem},
Title = {{Securing Microgrid Optimal Energy Management Using Deep Generative Model}},
Journal = {{IEEE ACCESS}},
Year = {{2021}},
Volume = {{9}},
Pages = {{63377-63387}},
Abstract = {{This paper investigates the effect of data integrity attacks on the
   central control of the microgrids (MGs), which can lead to severe
   blackouts and load shedding. It assesses this cyber attack from the
   steady state and optimal scheduling point of view. In order to stop the
   cyber hacking, a new deep learning-based framework has been developed
   based on the generative adversarial networks (GANs). In this framework,
   two networks compete with each other, wherein the first network
   generates fake data, and the second one is responsible for the data
   classification. In order to get into the most optimal features, a new
   optimization method based on a modified teaching-learning based
   optimization (TLBO) algorithm is also devised to reinforce the GAN model
   and help a better matching training process. In addition, a new
   modification is introduced for TLBO to avoid premature convergence and
   provide high population diversity. To show the effectiveness of the
   proposed framework, a real dataset of several smart metering devices in
   a MG has been tested. Results illustrate the high performance of the
   proposed framework, comparing to the well-known conventional detection
   frameworks with hit rate of 93.11\%, miss rate of 6.89\%, false alarm
   rate of 7.76\% and correct reject rate of 92.24\%.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Tang, ZQ (Corresponding Author), State Grid Fujian Elect Power Co Ltd, Fuzhou 350003, Peoples R China.
   Khan, B (Corresponding Author), Hawassa Univ, Dept Elect \& Comp Engn, Hawassa 05, Ethiopia.
   Tang, Ziqiang, State Grid Fujian Elect Power Co Ltd, Fuzhou 350003, Peoples R China.
   Lin, Yubin, State Grid Fujian Power Econ Res Inst, Fuzhou 350012, Peoples R China.
   Vosoogh, Mahdi, Islamic Azad Univ, Sirjan Branch, Dept Elect Engn, Sirjan 201582, Iran.
   Parsa, Navid, Islamic Azad Univ, Marvdasht Branch, Dept Elect Engn, Marvdasht 15914, Iran.
   Baziar, Aliasghar, Sarvestan Univ, Dept Elect Engn, Sarvestan 71947, Iran.
   Khan, Baseem, Hawassa Univ, Dept Elect \& Comp Engn, Hawassa 05, Ethiopia.}},
DOI = {{10.1109/ACCESS.2021.3074460}},
ISSN = {{2169-3536}},
Keywords = {{Microgrids; Cyberattack; Smart meters; Data models; Gallium nitride;
   Data integrity; Decision making; Cyberattack; data injection; intrusion
   detection; prediction interval; smart meters}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{2568735717@qq.com
   baseem.khan04@gmail.com}},
ResearcherID-Numbers = {{Khan, Baseem/S-4862-2017}},
ORCID-Numbers = {{Khan, Baseem/0000-0002-5082-8311}},
Number-of-Cited-References = {{26}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{IEEE Access}},
Doc-Delivery-Number = {{RV5BM}},
Unique-ID = {{WOS:000645847900001}},
OA = {{gold}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000428311600186,
Author = {Aslan, Omer and Samet, Refik},
Book-Group-Author = {{IEEE}},
Title = {{Investigation of Possibilities to Detect Malware Using Existing Tools}},
Booktitle = {{2017 IEEE/ACS 14TH INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND
   APPLICATIONS (AICCSA)}},
Series = {{International Conference on Computer Systems and Applications}},
Year = {{2017}},
Pages = {{1277-1284}},
Note = {{14th IEEE/ACS International Conference on Computer Systems and
   Applications (AICCSA), Hammamet, TUNISIA, OCT 30-NOV 03, 2017}},
Organization = {{IEEE; ACS; IEEE Comp Soc; Arab Comp Soc; Univ Arizona; Univ Centrale;
   Wevioo Grp; ATIA Tunisia; Qatar Comp Res Inst; TUNISIE INNOVAT}},
Abstract = {{Malware stands for malicious software, which is installed on a computer
   system without the knowledge of the system owner. It performs malicious
   actions such as stealing confidential information and allowing remote
   code execution, and it can cause denial of service. Recently, malware
   creators started to publish new malware, which can bypass anti-malware
   software, intrusion detection systems (IDS) and sandbox execution. Due
   to this evasion, the protection of computer networks and computerized
   systems against these programs has become one of the biggest challenges
   in the information security realm. This paper proposes a methodology to
   learn the well-known malware analysis and detection tools, to implement
   these tools on well-known malware and benign programs and to compare the
   obtained results. Further, this research will suggest to users how to
   analyze and detect existing and unknown malware. In a test case, 100
   malware and 100 benign program samples were collected from different
   sources and analyzed under different versions of Windows machines. The
   test results indicated that it is almost impossible to detect malware by
   only using one tool. Using static and dynamic analysis tools together
   increased accuracy and the detection rate. The test results also showed
   that dynamic malware analysis tools outperformed static analysis tools.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Aslan, O (Corresponding Author), Univ Siirt, Dept Comp Engn, Siirt, Turkey.
   Aslan, Omer, Univ Siirt, Dept Comp Engn, Siirt, Turkey.
   Samet, Refik, Univ Ankara, Dept Comp Engn, Ankara, Turkey.}},
DOI = {{10.1109/AICCSA.2017.24}},
ISSN = {{2161-5322}},
ISBN = {{978-1-5386-3581-0}},
Keywords = {{Malware Analysis; Malware Detection; Static and Dynamic Analysis Tools;
   Malware Accuracy and Detection Rate}},
Research-Areas = {{Automation \& Control Systems; Computer Science}},
Web-of-Science-Categories  = {{Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Computer Science, Hardware \& Architecture; Computer
   Science, Interdisciplinary Applications; Computer Science, Theory \&
   Methods}},
Author-Email = {{omer.aslan@siirt.edu.tr
   samet@eng.ankara.edu.tr}},
ResearcherID-Numbers = {{Samet, Refik/AAG-4597-2019
   }},
ORCID-Numbers = {{Samet, Refik/0000-0001-8720-6834
   ASLAN, Omer/0000-0003-0737-1966}},
Number-of-Cited-References = {{20}},
Times-Cited = {{7}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BJ8IZ}},
Unique-ID = {{WOS:000428311600186}},
DA = {{2021-11-23}},
}

@article{ WOS:000614610000007,
Author = {Sewak, Mohit and Sahay, Sanjay K. and Rathore, Hemant},
Title = {{DRLDO: A Novel DRL based De-obfuscation System for Defence Against
   Metamorphic Malware}},
Journal = {{DEFENCE SCIENCE JOURNAL}},
Year = {{2021}},
Volume = {{71}},
Number = {{1}},
Pages = {{55-65}},
Month = {{JAN}},
Abstract = {{In this paper, we propose a novel mechanism to normalise metamorphic and
   obfuscated malware down at the opcode level and hence create an advanced
   metamorphic malware de-obfuscation and defence system. We name this
   system as DRLDO, for deep reinforcement learning based de-obfuscator.
   With the inclusion of the DRLDO as a sub-component, an existing
   intrusion detection system could be augmented with defensive
   capabilities against `zero-day' attack from obfuscated and metamorphic
   variants of existing malware. This gains importance, not only because
   there exists no system till date that use advance DRL to intelligently
   and automatically normalise obfuscation down even to the opcode level,
   but also because the DRLDO system does not mandate any changes to the
   existing IDS. The DRLDO system does not even mandate the IDS' classifier
   to be retrained with any new dataset containing obfuscated samples.
   Hence DRLDO could be easily retrofitted into any existing IDS
   deployment. We designed, developed, and conducted experiments on the
   system to evaluate the same against multiple-simultaneous attacks from
   obfuscations generated from malware samples from a standardised dataset
   that contain multiple generations of malware. Experimental results prove
   that DRLDO was able to successfully make the otherwise undetectable
   obfuscated variants of the malware detectable by an existing pre-trained
   malware classifier. The detection probability was raised well above the
   cut-off mark to 0.6 for the classifier to detect the obfuscated malware
   unambiguously. Further, the de-obfuscated variants generated by DRLDO
   achieved a very high correlation (of approximate to 0.99) with the base
   malware. This observation validates that the DRLDO system is actually
   learning to de-obfuscate and not exploiting a trivial trick.}},
Publisher = {{DEFENCE SCIENTIFIC INFORMATION DOCUMENTATION CENTRE}},
Address = {{METCALFE HOUSE, DELHI 110054, INDIA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Sewak, M (Corresponding Author), Microsoft, Secur \& Compliance Res, Hyderabad, India.
   Sewak, Mohit, Microsoft, Secur \& Compliance Res, Hyderabad, India.
   Sahay, Sanjay K.; Rathore, Hemant, BITS Pilani, Dept Comp Sci \& Informat, Goa Campus, Sancoale 403726, Goa, India.}},
DOI = {{10.14429/dsj.71.15780}},
ISSN = {{0011-748X}},
EISSN = {{0976-464X}},
Keywords = {{Adversarial artificial intelligence; Deep reinforcement learning;
   Metamorphic malware; De-obfuscation}},
Research-Areas = {{Science \& Technology - Other Topics}},
Web-of-Science-Categories  = {{Multidisciplinary Sciences}},
Author-Email = {{mohit.sewak@microsoft.com}},
ORCID-Numbers = {{Sahay, Sanjay/0000-0002-4640-2107
   SEWAK, MOHIT/0000-0001-8375-5713}},
Number-of-Cited-References = {{27}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{3}},
Journal-ISO = {{Def. Sci. J.}},
Doc-Delivery-Number = {{QC1QZ}},
Unique-ID = {{WOS:000614610000007}},
OA = {{Green Submitted, gold}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000674762400011,
Author = {Rigaki, Maria and Garcia, Sebastian},
Book-Group-Author = {{IEEE Comp Soc}},
Title = {{Bringing a GAN to a Knife-fight: Adapting Malware Communication to Avoid
   Detection}},
Booktitle = {{2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018)}},
Year = {{2018}},
Pages = {{70-75}},
Note = {{IEEE Symposium on Security and Privacy Workshops (SPW), San Francisco,
   CA, MAY 24, 2018}},
Organization = {{IEEE; IEEE Comp Soc}},
Abstract = {{Generative Adversarial Networks (GANs) have been successfully used in a
   large number of domains. This paper proposes the use of GANs for
   generating network traffic in order to mimic other types of traffic. In
   particular, our method modifies the network behavior of a real malware
   in order to mimic the traffic of a legitimate application, and therefore
   avoid detection. By modifying the source code of a malware to receive
   parameters from a GAN, it was possible to adapt the behavior of its
   Command and Control (C2) channel to mimic the behavior of Facebook chat
   network traffic. In this way, it was possible to avoid the detection of
   new-generation Intrusion Prevention Systems that use machine learning
   and behavioral characteristics. A real-life scenario was successfully
   implemented using the Stratosphere behavioral IPS in a router, while the
   malware and the GAN were deployed in the local network of our
   laboratory, and the C2 server was deployed in the cloud. Results show
   that a GAN can successfully modify the traffic of a malware to make it
   undetectable. The modified malware also tested if it was being blocked
   and used this information as a feedback to the GAN. This work envisions
   the possibility of self-adapting malware and self-adapting IPS.}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Rigaki, M (Corresponding Author), Czech Tech Univ, Fac Elect Engn, Prague, Czech Republic.
   Rigaki, Maria; Garcia, Sebastian, Czech Tech Univ, Fac Elect Engn, Prague, Czech Republic.}},
DOI = {{10.1109/SPW.2018.00019}},
ISBN = {{978-0-7695-6349-7}},
Keywords = {{GAN; malware; intrusion detection; intrusion prevention; network
   behavior; network traffic obfuscation}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Theory \&
   Methods}},
Author-Email = {{maria.rigaki@fel.cvut.cz
   sebastian.garcia@fel.cvut.cz}},
ORCID-Numbers = {{Rigaki, Maria/0000-0002-0688-7752}},
Funding-Acknowledgement = {{Czech TACR {[}TH02010990]}},
Funding-Text = {{The authors thank Ondrej Lukas for his implementation of the Slips
   system in the Turris Routers. This research was partially supported by
   the Czech TACR project no. TH02010990.}},
Number-of-Cited-References = {{20}},
Times-Cited = {{22}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{4}},
Doc-Delivery-Number = {{BR8ZO}},
Unique-ID = {{WOS:000674762400011}},
OA = {{Bronze}},
DA = {{2021-11-23}},
}

@article{ WOS:000597219500001,
Author = {Liu, Xu and Di, Xiaoqiang and Ding, Qiang and Liu, Weiyou and Qi, Hui
   and Li, Jinqing and Yang, Huamin},
Title = {{NADS-RA: Network Anomaly Detection Scheme Based on Feature
   Representation and Data Augmentation}},
Journal = {{IEEE ACCESS}},
Year = {{2020}},
Volume = {{8}},
Pages = {{214781-214800}},
Abstract = {{Network anomaly detection aims to identify network anomalies, and it has
   obtained many achievements using the supervised classification
   technique. Since the supervised classifier depends on the prior data, it
   is difficult to accurately classify the rare anomalies when they account
   less in the training set. Data augmentation can tackle the imbalanced
   training set problem through creating artificial rare anomaly samples.
   However, the existing data augmentation methods either ignore the data
   distribution or ignore the spatial knowledge between features.
   Therefore, this article addresses this issue by proposing a Network
   Anomaly Detection Scheme based on feature Representation and data
   Augmentation (NADS-RA). Re-circulation Pixel Permutation strategy is
   first designed as feature representation strategy to construct images,
   and it rotates each feature left by the times of feature number to
   maintain the spatial knowledge between original network traffic
   features. An image-based augmentation strategy is thus designed to
   produce augmented images according to the distribution characteristics
   of rare network anomaly images with the help of Least Squares Generative
   Adversarial Network, which alleviates the effect of imbalanced training
   set and avoids over-fitting. After that, NADS-RA is implemented on the
   Convolutional Neural Network classification model. We conduct
   experiments on five public benchmark datasets, including NSL-KDD and
   UNSW-NB15, and so on, and compare against 12 detection methods and 17
   data generation methods. The experimental results demonstrate the
   superior effectiveness of our work to state-of-the-art methods and the
   general applicability in different scenarios.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Di, XQ (Corresponding Author), Changchun Univ Sci \& Technol, Sch Comp Sci \& Technol, Changchun 130022, Peoples R China.
   Di, XQ (Corresponding Author), Changchun Univ Sci \& Technol, Jilin Prov Key Lab Network \& Informat Secur, Changchun 130022, Peoples R China.
   Di, XQ (Corresponding Author), Changchun Univ Sci \& Technol, Informat Ctr, Changchun 130022, Peoples R China.
   Liu, Xu; Di, Xiaoqiang; Liu, Weiyou; Qi, Hui; Li, Jinqing; Yang, Huamin, Changchun Univ Sci \& Technol, Sch Comp Sci \& Technol, Changchun 130022, Peoples R China.
   Liu, Xu; Di, Xiaoqiang; Qi, Hui; Li, Jinqing; Yang, Huamin, Changchun Univ Sci \& Technol, Jilin Prov Key Lab Network \& Informat Secur, Changchun 130022, Peoples R China.
   Di, Xiaoqiang; Ding, Qiang, Changchun Univ Sci \& Technol, Informat Ctr, Changchun 130022, Peoples R China.}},
DOI = {{10.1109/ACCESS.2020.3040510}},
ISSN = {{2169-3536}},
Keywords = {{Feature extraction; Training; Anomaly detection; Knowledge engineering;
   Payloads; Deep learning; Principal component analysis; Anomaly
   detection; rare anomalies; feature representation; data augmentation;
   network security}},
Keywords-Plus = {{DEEP LEARNING APPROACH; INTRUSION DETECTION; IMBALANCED DATA}},
Research-Areas = {{Computer Science; Engineering; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications}},
Author-Email = {{dixiaoqiang@cust.edu.cn}},
ORCID-Numbers = {{Liu, Xu/0000-0002-6766-5184
   liu, weiyou/0000-0002-5997-2889}},
Funding-Acknowledgement = {{Science and Technology Development Plan Project, Jilin, China
   {[}20190302070GX]; Education Department of Jilin Province
   {[}JJKH20190598KJ, JJKH20190546KJ, GH180148]}},
Funding-Text = {{This work was supported in part by the Science and Technology
   Development Plan Project, Jilin, China, under Grant 20190302070GX, and
   in part by the Education Department of Jilin Province under Grant
   JJKH20190598KJ, Grant JJKH20190546KJ, and Grant GH180148.}},
Number-of-Cited-References = {{56}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{9}},
Usage-Count-Since-2013 = {{10}},
Journal-ISO = {{IEEE Access}},
Doc-Delivery-Number = {{PC8BJ}},
Unique-ID = {{WOS:000597219500001}},
OA = {{gold}},
DA = {{2021-11-23}},
}

@article{ WOS:000426010500017,
Author = {Bedi, Amrit Singh and Sarma, Paban and Rajawat, Ketan},
Title = {{Tracking Moving Agents via Inexact Online Gradient Descent Algorithm}},
Journal = {{IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING}},
Year = {{2018}},
Volume = {{12}},
Number = {{1}},
Pages = {{202-217}},
Month = {{FEB}},
Note = {{IEEE International Conference on Acoustics, Speech and Signal Processing
   (ICASSP), Calgary, CANADA, APR 15-20, 2018}},
Organization = {{Inst Elect \& Elect Engineers; Inst Elect \& Elect Engineers Signal Proc
   Soc}},
Abstract = {{Multiagent systems are being increasingly deployed in challenging
   environments for performing complex tasks such as multitarget tracking,
   search-and-rescue, and intrusion detection. Not with standing the
   computational limitations of individual robots, such systems rely on
   collaboration to sense and react to the environment. This paper
   formulates the generic target tracking problem as a time-varying
   optimization problem and puts forth an inexact online gradient descent
   method for solving it sequentially. The performance of the proposed
   algorithm is studied by characterizing its dynamic regret, a notion
   common to the online learning literature. Building upon the existing
   results, we provide improved regret rates that not only allow
   nonstrongly convex costs but also explain the role of the cumulative
   gradient error. Two distinct classes of problems are considered: one in
   which the objective function adheres to a quadratic growth condition,
   and another where the objective function is convex but the variable
   belongs to a compact domain. For both cases, results are developed while
   allowing the error to be either adversarial or arising from a white
   noise process. Further, the generality of the proposed framework is
   demonstrated by developing online variants of existing stochastic
   gradient algorithms and interpreting them as special cases of the
   proposed inexact gradient method. The efficacy of the proposed inexact
   gradient framework is established on a multiagent multitarget tracking
   problem, while its flexibility is exemplified by generating online movie
   recommendations for Movielens 10M dataset.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article; Proceedings Paper}},
Language = {{English}},
Affiliation = {{Rajawat, K (Corresponding Author), Indian Inst Technol, Dept Elect Engn, Kanpur 208016, Uttar Pradesh, India.
   Bedi, Amrit Singh; Sarma, Paban; Rajawat, Ketan, Indian Inst Technol, Dept Elect Engn, Kanpur 208016, Uttar Pradesh, India.}},
DOI = {{10.1109/JSTSP.2018.2797423}},
ISSN = {{1932-4553}},
EISSN = {{1941-0484}},
Keywords = {{Time varying optimization; stochastic optimization; target tracking;
   gradient descent methods}},
Keywords-Plus = {{REAL-TIME; OPTIMIZATION; CONVERGENCE; SYSTEMS}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{amritbd@iitk.ac.in
   sarma.paban@gmail.com
   ketan@iitk.ac.in}},
Number-of-Cited-References = {{52}},
Times-Cited = {{9}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{11}},
Journal-ISO = {{IEEE J. Sel. Top. Signal Process.}},
Doc-Delivery-Number = {{FX3ZC}},
Unique-ID = {{WOS:000426010500017}},
OA = {{Green Submitted}},
DA = {{2021-11-23}},
}

@article{ WOS:000316836600005,
Author = {Shahzad, Farrukh and Shahzad, M. and Farooq, Muddassar},
Title = {{In-execution dynamic malware analysis and detection by mining
   information in process control blocks of Linux OS}},
Journal = {{INFORMATION SCIENCES}},
Year = {{2013}},
Volume = {{231}},
Pages = {{45-63}},
Month = {{MAY 10}},
Abstract = {{Run-time behavior of processes - running on an end-host - is being
   actively used to dynamically detect malware. Most of these detection
   schemes build model of run-time behavior of a process on the basis of
   its data flow and/or sequence of system calls. These novel techniques
   have shown promising results but an efficient and effective technique
   must meet the following performance metrics: (1) high detection
   accuracy, (2) low false alarm rate, (3) small detection time, and (4)
   the technique should be resilient to run-time evasion attempts.
   To meet these challenges, a novel concept of genetic footprint is
   proposed, by mining the information in the kernel process control blocks
   (PCB) of a process, that can be used to detect malicious processes at
   run time. The genetic footprint consists of selected parameters -
   maintained inside the PCB of a kernel for each running process - that
   define the semantics and behavior of an executing process. A systematic
   forensic study of the execution traces of benign and malware processes
   is performed to identify discriminatory parameters of a PCB
   (task\_struct is PCB in case of Linux OS). As a result, 16 out of 118
   task structure parameters are short listed using the time series
   analysis. A statistical analysis is done to corroborate the features of
   the genetic footprint and to select suitable machine learning
   classifiers to detect malware.
   The scheme has been evaluated on a dataset that consists of 105 benign
   processes and 114 recently collected malware processes for Linux. The
   results of experiments show that the presented scheme achieves a
   detection accuracy of 96\% with 0\% false alarm rate in less than 100 ms
   of the start of a malicious activity. Last but not least, the presented
   technique utilizes partial knowledge that is available at a given time
   while the process is still executing; as a result, the kernel of OS can
   devise mitigation strategies. It is also shown that the presented
   technique is robust to well known run-time evasion attempts. (C) 2011
   Elsevier Inc. All rights reserved.}},
Publisher = {{ELSEVIER SCIENCE INC}},
Address = {{STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Shahzad, F (Corresponding Author), FAST Natl Univ Comp \& Emerging Sci FAST NU, Next Generat Intelligent Networks Res Ctr nexGIN, Islamabad, Pakistan.
   Shahzad, Farrukh; Shahzad, M.; Farooq, Muddassar, FAST Natl Univ Comp \& Emerging Sci FAST NU, Next Generat Intelligent Networks Res Ctr nexGIN, Islamabad, Pakistan.}},
DOI = {{10.1016/j.ins.2011.09.016}},
ISSN = {{0020-0255}},
EISSN = {{1872-6291}},
Keywords = {{Intrusion detection system; Kernel task structure; Malware forensic;
   Operating system security; Malicious process detection}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems}},
Author-Email = {{farrukh.shahzad@nexginrc.org
   muhammad.shahzad@nexginrc.org
   muddassar.farooq@nexginrc.org}},
Funding-Acknowledgement = {{National ICT R\&D Fund, Ministry of Information Technology, Government
   of Pakistan}},
Funding-Text = {{The work presented in this paper is supported by the National ICT R\&D
   Fund, Ministry of Information Technology, Government of Pakistan. The
   information, data, comments, and views detailed herein may not
   necessarily reflect the endorsements of views of the National ICT R\&D
   Fund.}},
Number-of-Cited-References = {{55}},
Times-Cited = {{20}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{36}},
Journal-ISO = {{Inf. Sci.}},
Doc-Delivery-Number = {{115UE}},
Unique-ID = {{WOS:000316836600005}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000693425400018,
Author = {Lee, Jin-Ha and Astrid, Marcella and Zaheer, Muhammad Zaigham and Lee,
   Seung-Ik},
Editor = {{Jeong, H and Sumi, K}},
Title = {{Deep Visual Anomaly Detection with Negative Learning}},
Booktitle = {{FRONTIERS OF COMPUTER VISION, IW-FCV 2021}},
Series = {{Communications in Computer and Information Science}},
Year = {{2021}},
Volume = {{1405}},
Pages = {{218-232}},
Note = {{International Workshop on Frontiers of Computer Vision (IW-FCV), ELECTR
   NETWORK, FEB 22-23, 2021}},
Organization = {{Korean Comp Vis Soc; Daegu Convent \& Visitors Bur; Kyungpook Natl Univ}},
Abstract = {{With the increase in the learning capability of deep convolution-based
   architectures, various applications of such models have been proposed
   over time. In the field of anomaly detection, improvements in deep
   learning opened new prospects of exploration for the researchers whom
   tried to automate the labor-intensive features of data collection.
   First, in terms of data collection, it is impossible to anticipate all
   the anomalies that might exist in a given environment. Second, assuming
   we limit the possibilities of anomalies, it will still be hard to record
   all these scenarios for the sake of training a model Third, even if we
   manage to record a significant amount of abnormal data, it's laborious
   to annotate this data on pixel or even frame level. Various approaches
   address the problem by proposing one-class classification using
   generative models trained on only normal data. In such methods, only the
   normal data is used, which is abundantly available and doesn't require
   significant human input. However, such approaches have two drawbacks.
   First, these are trained with only normal data and at the test time,
   given abnormal data as input, still generate normal-looking output. This
   happens due to the hallucination characteristic of generative models,
   which is not desirable in anomaly detection systems because of their
   need to be accurate and reliable. Next, these systems are not capable of
   utilizing abnormal examples, however small in number, during the
   training. In this paper, we propose anomaly detection with negative
   learning (ADNL), which employs the negative learning concept for the
   enhancement of anomaly detection by utilizing a very small number of
   labeled anomaly data as compared with the normal data during training.
   The idea, which is fairly simple yet effective, is to limit the
   reconstruction capability of a generative model using the given anomaly
   examples. During the training, normal data is learned as would have been
   in a conventional method, but the abnormal data is utilized to maximize
   loss of the network on abnormality distribution. With this simple
   tweaking, the network not only learns to reconstruct normal data but
   also encloses the normal distribution far from the possible distribution
   of anomalies. In order to evaluate the efficiency of our proposed
   method, we defined the baseline using Adversarial Auto-Encoder (AAE).
   Our experiments show significant improvement in area under the curve
   (AUC) over conventional AAE. An extensive evaluation, which has been
   carried out on the MNIST dataset as well as a locally recorded
   pedestrian dataset, is reported in this paper.}},
Publisher = {{SPRINGER INTERNATIONAL PUBLISHING AG}},
Address = {{GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Lee, SI (Corresponding Author), Univ Sci \& Technol UST, 217 Gajeong Ro, Daejeon, South Korea.
   Lee, SI (Corresponding Author), Elect \& Telecommun Res Inst ETRI, 218 Gajeong Ro, Daejeon, South Korea.
   Lee, Jin-Ha; Astrid, Marcella; Zaheer, Muhammad Zaigham; Lee, Seung-Ik, Univ Sci \& Technol UST, 217 Gajeong Ro, Daejeon, South Korea.
   Lee, Jin-Ha; Astrid, Marcella; Zaheer, Muhammad Zaigham; Lee, Seung-Ik, Elect \& Telecommun Res Inst ETRI, 218 Gajeong Ro, Daejeon, South Korea.}},
DOI = {{10.1007/978-3-030-81638-4\_18}},
ISSN = {{1865-0929}},
EISSN = {{1865-0937}},
ISBN = {{978-3-030-81638-4; 978-3-030-81637-7}},
Keywords = {{Anomaly detection; Auto encoder; Limiting reconstruction capability}},
Keywords-Plus = {{INTRUSION DETECTION; NEURAL-NETWORKS}},
Research-Areas = {{Computer Science; Imaging Science \& Photographic Technology}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods; Imaging Science \& Photographic Technology}},
Author-Email = {{jhlee@ust.ac.kr
   marcella.astrid@ust.ac.kr
   mzz@ust.ac.kr
   the\_silee@etri.re.kr}},
Funding-Acknowledgement = {{ICT R\&D program of MSIT/IITP {[}2019-0-01309]}},
Funding-Text = {{This work was supported by the ICT R\&D program of MSIT/IITP.
   {[}2019-0-01309, Development of AI Technology for Guidance of a Mobile
   Robot to its Goal with Uncertain Maps in Indoor/Outdoor Environments].}},
Number-of-Cited-References = {{28}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BS1ND}},
Unique-ID = {{WOS:000693425400018}},
OA = {{Green Submitted}},
DA = {{2021-11-23}},
}

@inproceedings{ WOS:000482120400045,
Author = {Ding, Kaize and Li, Jundong and Liu, Huan},
Book-Group-Author = {{ACM}},
Title = {{Interactive Anomaly Detection on Attributed Networks}},
Booktitle = {{PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH
   AND DATA MINING (WSDM'19)}},
Year = {{2019}},
Pages = {{357-365}},
Note = {{12th ACM International Conference on Web Search and Data Mining (WSDM),
   Melbourne, AUSTRALIA, FEB 11-15, 2019}},
Organization = {{Assoc Comp Machinery; ACM Special Interest Grp Informat Retrieval; ACM
   SIGKDD; ACM SIGMOD; ACM SIGWEB}},
Abstract = {{Performing anomaly detection on attributed networks concerns with
   finding nodes whose patterns or behaviors deviate significantly from the
   majority of reference nodes. Its success can be easily found in many
   real-world applications such as network intrusion detection, opinion
   spam detection and system fault diagnosis, to name a few. Despite their
   empirical success, a vast majority of existing efforts are
   overwhelmingly performed in an unsupervised scenario due to the
   expensive labeling costs of ground truth anomalies. In fact, in many
   scenarios, a small amount of prior human knowledge of the data is often
   effortless to obtain, and getting it involved in the learning process
   has shown to be effective in advancing many important learning tasks.
   Additionally, since new types of anomalies may constantly arise over
   time especially in an adversarial environment, the interests of human
   expert could also change accordingly regarding to the detected anomaly
   types. It brings further challenges to conventional anomaly detection
   algorithms as they are often applied in a batch setting and are
   incapable to interact with the environment. To tackle the above issues,
   in this paper, we investigate the problem of anomaly detection on
   attributed networks in an interactive setting by allowing the system to
   proactively communicate with the human expert in making a limited number
   of queries about ground truth anomalies. Our objective is to maximize
   the true anomalies presented to the human expert after a given budget is
   used up. Along with this line, we formulate the problem through the
   principled multi-armed bandit framework and develop a novel
   collaborative contextual bandit algorithm, named GraphUCB. In
   particular, our developed algorithm: (1) explicitly models the nodal
   attributes and node dependencies seamlessly in a joint framework; and
   (2) handles the exploration-exploitation dilemma when querying anomalies
   of different types. Extensive experiments on real-world datasets show
   the improvement of the proposed algorithm over the state-of-the-art
   algorithms.}},
Publisher = {{ASSOC COMPUTING MACHINERY}},
Address = {{1515 BROADWAY, NEW YORK, NY 10036-9998 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Ding, KZ (Corresponding Author), Arizona State Univ, Tempe, AZ 85287 USA.
   Ding, Kaize; Li, Jundong; Liu, Huan, Arizona State Univ, Tempe, AZ 85287 USA.}},
DOI = {{10.1145/3289600.3290964}},
ISBN = {{978-1-4503-5940-5}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory \& Methods}},
Author-Email = {{kding9@asu.edu
   jundong@asu.edu
   huan.liu@asu.edu}},
Funding-Acknowledgement = {{NSFNational Science Foundation (NSF) {[}1614576]; ONROffice of Naval
   Research {[}N00014-16-1-2257]}},
Funding-Text = {{This material is based upon work supported by, or in part by, the NSF
   grant 1614576, and the ONR grant N00014-16-1-2257. The authors also wish
   to thank Qinghai Zhou for the help of the experiments.}},
Number-of-Cited-References = {{54}},
Times-Cited = {{8}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BN4KX}},
Unique-ID = {{WOS:000482120400045}},
OA = {{Bronze}},
DA = {{2021-11-23}},
}
